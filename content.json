[{"title":"AFFiNE后端开发环境搭建","date":"2025-04-28T04:25:49.000Z","path":"practice/AFFiNE后端开发环境搭建.html","tags":[{"name":"AFFiNE","slug":"AFFiNE","permalink":"https://congzhou09.github.io/tags/AFFiNE/"}],"text":"环境参数◇ 我是在 Windows 上搭建的，以下版本号信息供参考，非必须完全一致。 Name version Win11 24H2 Docker Desktop v4.40.0 rustc 1.86.0 node v20.19.0 PostgreSQL 17.4 Redis 7.4.3 AFFiNE canary: 7e4af90c0311e498f5119b034397b5ae8a7af9ec 操作步骤◆ 在 AFFiNE 项目根目录执行 yarn install 成功安装所有依赖。◆ 后端项目是其中的 @affine&#x2F;server 子项目。◆ 安装 Docker Desktop 与 Rust。◆ 使用 docker 运行 Redis，docker-compose.yaml 内容如下： 1234567services: affine-redis: image: redis:latest container_name: affine-redis restart: always ports: - &quot;6379:6379&quot; ◆ 使用 docker 运行 PostgreSQL，docker-compose.yaml 内容如下。（1）由于 Postgres 要求挂载目录支持硬链接（hard link），Windows 上不能使用本地磁盘目录。于是使用让 docker 创建的名为&quot;affine_pgdata&quot;的 volume 做数据持久化。 1234567891011services: affine-postgres: image: postgres:latest container_name: affine-postgres restart: always ports: - &quot;5432:5432&quot; volumes: - affine_pgdata:/var/lib/postgresql/datavolumes: affine_pgdata: ◆ 在数据库中创建项目所使用的用户名、密码与数据库实例。 123456789# 进入数据库容器的数据库命令行docker exec -it affine-postgres psql -U postgres# 创建项目用户CREATE USER affine WITH PASSWORD &#x27;affine&#x27;;ALTER USER affine WITH SUPERUSER;# 创建数据库CREATE DATABASE affine; ◆ 我使用开发环境下会自动创建的用户调试(packages\\backend\\server\\src\\core\\auth\\dev.ts\\createDevUsers())，所以未启动 mailhog 服务也未在下一步配置 mail 相关字段。 ◆ 项目数据库连接配置，进入项目 packages\\backend\\server 路径，参考&quot;.env.example&quot;创建配置文件&quot;.env&quot;，文件内容如下。 1DATABASE_URL=&quot;postgres://affine:affine@localhost:5432/affine&quot; ◆ 使用项目所依赖的 prisma 创建项目数据库表，在项目根目录执行： 1yarn workspace @affine/server prisma db push ◆ 如果上步执行报错：Could not open extension control file &quot;&#x2F;usr&#x2F;share&#x2F;postgresql&#x2F;17&#x2F;extension&#x2F;vector.control&quot;: No such file or directory。则执行以下步骤后重新执行上步命令。 12345678# 进入数据库容器的bash命令行docker exec -it affine-postgres /bin/bash# 更新apt-get工具apt-get update# 安装缺少的vector扩展，其中的&quot;17&quot;与报错信息里的一致apt-get install postgresql-17-pgvector ◆ 初始化数据库中的项目数据。在项目根目录执行下面命令，注意要带上&quot;run&quot;，不然所执行的&quot;yarn init&quot;就是 yarn 自带的 init 命令了。 1yarn workspace @affine/server run init ◆ 编译 @affine&#x2F;server 所依赖的 @affine&#x2F;server-native。执行下面命令，此时会用到 Rust 环境。 1yarn workspace @affine/server-native build:debug ◆ 如果上步执行报错：&#39;cargo&#39; 不是内部或外部命令，也不是可运行的程序。则执行以下步骤后重新执行上步命令。（1）确认 Rust 已安装，powershell 和 cmd 中 cargo --version 打印正常。（2）终端正常启动时会加载用户级+系统级的 PATH 变量，确认环境变量的 PATH 中存在&quot;C:\\Users\\用户名\\.cargo\\bin&quot;。（3）在报错位置&quot;node_modules\\@napi-rs\\cli\\dist\\utils\\metadata.js&quot;，增加 console.log(process.env.PATH)打印，看其中是否没有&quot;C:\\Users\\用户名\\.cargo\\bin&quot;。原因很可能是在安装完 Rust 后的广播 PATH 变更环节异常，重启电脑可解决。 ◆ 启动后端。在项目根目录执行 yarn dev，选择&quot;@affine&#x2F;server&quot;。 admin 管理页面△ 以 self-hosted 模式部署的 AFFiNE 可以通过 http://locahost:3010/admin 访问 admin 管理页面。本地开发环境需要做下面两步操作才可以。 self-hosted 模式□ 在.env 文件中追加 DEPLOYMENT_TYPE 字段。 1DEPLOYMENT_TYPE=&quot;selfhosted&quot; admin 页面资源○ 编译 @affine&#x2F;admin。项目根目录执行： 1yarn affine @affine/admin build ○ 拷贝 packages\\frontend\\admin\\dist 下的所有内容到 packages\\backend\\server\\static\\admin 参考文献●官方 Doc 网站-Node Dev Guide●self-hosted 模式 AFFiNE 的部署"},{"title":"基于verdaccio的npm私有仓库","date":"2024-11-25T13:03:36.000Z","path":"practice/基于verdaccio的npm私有仓库.html","tags":[{"name":"Node.js","slug":"Node-js","permalink":"https://congzhou09.github.io/tags/Node-js/"}],"text":"简介● Verdaccio 是个轻量的基于 Node.js 的 npm 私有仓库。● 支持 npm 主流客户端(yarn&#x2F;npm&#x2F;pnpm)，支持代理到其他 registry 地址及缓存加速。 docker-compose 方式运行(linux)◇ 参考官方文档对 docker 方式的说明。◇ 指定一个存放路径。此处以此路径为例：&#x2F;app&#x2F;deploy&#x2F;verdaccio。◇ 在路径下创建三个子文件夹：config、plugins、storage。◇ 由于 Verdaccio 在容器内使用的是 UID&#x3D;10001 且 GID&#x3D;65533 的非 root 用户，递归设置挂载目录的用户和用户组： 1sudo chown -R 10001:65533 /app/deploy/verdaccio ◇ 参考官方示例配置文件在 config 文件夹下准备 config.yaml，示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# path to a directory with all packagesstorage: /verdaccio/storage# path to a directory with plugins to include, the plugins folder has the higher priority for loading plugins# disable this folder to avoid warnings if is not used# plugins: ./pluginsweb: enable: true title: npm | example logo: https://static-production.npmjs.com/b0f1a8318363185cc2ea6a40ac23eeb2.png favicon: https://static-production.npmjs.com/b0f1a8318363185cc2ea6a40ac23eeb2.png primary_color: &#x27;#3990f6&#x27; showInfo: false showSettings: false showFooter: false showUplinks: false showDownloadTarball: false showRaw: falseurl_prefix: &#x27;/&#x27;max_body_size: 300mb # max package&#x27;s size 300Mauth: htpasswd: file: /verdaccio/storage/htpasswd # where to store login info # Maximum amount of users allowed to register, defaults to &quot;+inf&quot;. # Set to -1 to disable registration. max_users: -1uplinks: npmjs: url: https://registry.npmjs.org/packages: &#x27;**&#x27;: # you can specify usernames/groupnames (depending on your auth plugin) # and three keywords: &quot;$all&quot;, &quot;$anonymous&quot;, &quot;$authenticated&quot; access: $authenticated publish: $authenticated # if package is not available locally, proxy requests to &#x27;npmjs&#x27; registry proxy: npmjssecurity: web: sign: expiresIn: 30d # login expiration time, examples: 1h, 7dlog: - &#123; type: stdout, format: pretty, level: trace &#125; #- &#123;type: file, path: verdaccio.log, level: info&#125; ◇ 创建 docker-compose.yml 文件，内容示例如下。其中 VERDACCIO_PUBLIC_URL 不能为空，且需设置成域名网址而不能是相对路径(以 https://npm.my.cn 为例)，否则 Verdaccio 将使用默认的 http://localhost:4873/ 作为所生成所有资源链接(如包的访问链接)的基础 URL。 123456789101112131415name: verdaccioservices: verdaccio: image: verdaccio/verdaccio:6.0.2 container_name: &#x27;verdaccio&#x27; environment: - VERDACCIO_PUBLIC_URL=https://npm.my.cn - VERDACCIO_PORT=4873 ports: - &#x27;4873:4873&#x27; volumes: - &#x27;./storage:/verdaccio/storage&#x27; - &#x27;./config:/verdaccio/conf&#x27; - &#x27;./plugins:/verdaccio/plugins&#x27; ◇ 在 docker-compose.yml 文件同级目录下执行&quot;docker compose up -d&quot;命令启动。 私有仓库的使用■ 以下私有仓库地址以 https://npm.my.cn 为例。 用户管理■ 创建用户。在上述 config.yaml 配置中 max_users 不等于 -1 的情况下，执行：npm adduser --registry https://npm.my.cn。仓库连接成功会自动提示输入用户名密码等信息。■ 手动登录。执行：npm login --registry https://npm.my.cn。■ 自动登录。将登录信息保存到项目根目录的.npmrc 中可避免手动 login 的过程。示例如下。其中的&lt;passwordToBase64&gt;可通过执行&quot;echo -n &lt;password&gt; | base64&quot;得到。 12//npm.my.cn/:username=&lt;username&gt;//npm.my.cn/:_password=&lt;passwordToBase64&gt; 包的发布■ 将包发布到私有仓库，在 publish 命令上增加参数：--registry https://npm.my.cn■ registry 除了命令行参数方式之外，也支持添加到.npmrc 文件，以及 package.json 文件的 publishConfig 字段。三者优先级依次递减。示例如下： 123456789101112//.npmrc 文件registry=https://npm.my.cn// package.json文件&#123; ... ... &quot;publishConfig&quot;: &#123; &quot;registry&quot;: &quot;https://npm.my.cn&quot; &#125; ... ...&#125; ■ 包大小限制的调整：（1）nginx 默认消息体大小限制 1M，通过 nginx 指令“client_max_body_size 300M”调整。（2）verdiccio 默认包大小限制 10M，通过 config.yaml 中的“max_body_size: 300mb”调整。 包的安装■ 所有包都从私有仓库下载。通过上述 --registry 命令行参数或 .npmrc 中的 registry 字段可实现。■ 仅私有包从私有仓库下载。.npmrc 提供了为特定域或包名指定仓库地址的配置语法，但实践发现 pnpm 和 yarn 对这类语法的支持不完善或不统一，可通过将 package.json 的 dependencies 中包的版本号指定为带基础 URL 的完整下载地址实现，如：&quot;demo-pkg&quot;: &quot;https://npm.my.cn/demo-pkg/-/demo-pkg-0.0.11.tgz&quot;。"},{"title":"基于阿里云ACK Serverless搭建按量付费的gitlab-runner","date":"2024-07-28T13:42:01.000Z","path":"practice/基于阿里云ACK-Serverless搭建按量付费的gitlab-runner.html","tags":[{"name":"ACK Serverless","slug":"ACK-Serverless","permalink":"https://congzhou09.github.io/tags/ACK-Serverless/"},{"name":"gitlab","slug":"gitlab","permalink":"https://congzhou09.github.io/tags/gitlab/"}],"text":"方案说明◆ 由于 CI&#x2F;CD 的非持续运行而运行期间又需要较高系统资源的特性，符合 ACK Serverless 按资源使用时间计费的场景，降低 CI&#x2F;CD 成本的同时又能提高并行多任务的执行效率。◆ 方案的系统结构与流程如下面来自参考文档[1]的截图，当没有任务时仅 gitlab-runner 作为一个 pod 始终运行，以随时接受来自 gitlab 的任务分配。当有任务需要执行时，针对每个任务创建一个 kubernetes executor 类型的 pod 执行任务，且任务执行结束后，这些 kubernetes executor 类型的 pod 会自动销毁。 步骤准备 ACK Serverless 集群环境● 在阿里云工作台页面创建 ACK Serverless 类型的 kubernetes 集群。● 根据&quot;集群信息&quot;中的&quot;连接信息&quot;，配置本地 kubectl，使可以在本地 kubectl 上对集群做操作。 准备配置文件◇ 从 GitHub 上 clone 由参考文档[1]提供的配置文件样例到本地，使用其中&quot;eci-gitlab-runner&quot;文件夹里的配置文件。◇ 以下配置的内容最终将集中到 config-map.yml 并经由集群的 deployment 被 mount 到 config.toml 文件，以方便地应用到所部署的 gitlab-runner pod 中。◇ 未来由 gitlab-runner 拉起的 kubernetes executor 类型 pod 的配置也在这个 config.toml 文件里的，部分配置也会被 mount 成 pod 中的文件。◇ 以下配置内容和命令中的所有由&quot;${}&quot;包裹的变量都需要替换成实际值。 secret◆ 通过 secret 存放 kubernetes 集群、docker registry、git ssh 的鉴权信息。◆ 修改样例 secret.yaml 配置，其中的 ca.crt、tls.crt、tls.key 依次填写集群连接信息里的 certificate-authority-data、client-certificate-data、client-key-data。◆ 执行&quot;kubectl apply -f secret.yaml&quot;使生效。secret.yaml 完整内容如下： 123456789apiVersion: v1kind: Secretmetadata: name: gitlab-runner-secrettype: kubernetes.io/tlsdata: ca.crt: $&#123;ca.crt&#125; tls.crt: $&#123;tls.crt&#125; tls.key: $&#123;tls.key&#125; ◆ 如果 gitlab 的 pipeline 任务需要推送 docker 镜像到镜像仓库，则在集群创建名为&quot;registry-auth-secret&quot;的 secret，执行如下命令： 1kubectl create secret docker-registry registry-auth-secret --docker-server=$&#123;registry-server-hostname&#125; --docker-username=$&#123;username&#125; --docker-password=$&#123;password&#125; ◆ 如果 gitlab 的 pipeline 任务需要 clone 其他 git 仓库，则在集群创建名为&quot;gitlab-credentials&quot;的 secret，执行如下命令： 1kubectl create secret generic gitlab-credentials --from-file=id_rsa=$&#123;pathto_id_rsa&#125; --from-file=id_rsa.pub=$&#123;pathto_id_rsa.pub&#125; --from-file=known_hosts=$&#123;pathto_known_hosts&#125; ◆ secret 创建成功后可在&quot;阿里云工作台页面集群详情-&gt;配置管理-&gt;保密字典&quot;位置看到。 配置 cache● gitlab 的 cache 用于让 executor 缓存文件与文件夹以减少重复的下载、安装等工作。● executor 容器的 cache 存储到的默认路径是&quot;&#x2F;cache&quot;，样例已经在 config-map.yaml 中将 pvc 配置到了此路径。 ● 准备好 NAS(Network Attached Storage) 盘，将其地址与缓存文件夹根目录(此处定义为&#x2F;gitlab-runner-cache)填写到 nas-pv.yaml。nas-pv.yaml 完整内容如下： 1234567891011121314151617181920apiVersion: v1kind: PersistentVolumemetadata: name: gitlab-runner-cache-pvspec: accessModes: - ReadWriteOnce capacity: storage: 10Gi mountOptions: - nolock,noresvport,noacl,hard - vers=3 - rsize=1048576 - wsize=1048576 - proto=tcp - timeo=600 - retrans=2 nfs: path: /gitlab-runner-cache server: $&#123;nas-server&#125; ● 相应的 nas-pvc.yaml 直接使用样例的即可。nas-pvc.yaml 完整内容如下： 1234567891011apiVersion: v1kind: PersistentVolumeClaimmetadata: name: gitlab-runner-cache-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi volumeName: gitlab-runner-cache-pv ● 分别执行&quot;kubectl apply -f nas-pv.yaml&quot;和&quot;kubectl apply -f nas-pvc.yaml&quot;使生效。◆ pv 与 pvc 创建成功后可分别在&quot;阿里云工作台页面集群详情-&gt;存储-&gt;存储卷|存储声明&quot;位置看到。 配置 image-cache○ imagecache-crd(Custom Resource Definition，CRD)是用于实现镜像缓存的 kubernetes 控制器，样例在 config-map.yaml 和 gitlab-runner-deployment.yaml 中通过 k8s.aliyun.com&#x2F;eci-image-cache 这个自定义注解标识了对 imagecache 的启用。 ○ 通过&quot;kubectl get crd&quot;命令查看 imagecache-crd 是否已安装。如果未安装则通过&quot;kubectl apply -f imagecache-crd.yaml&quot;安装。直接使用样例的 imagecache-crd.yaml 即可，完整内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051apiVersion: apiextensions.k8s.io/v1beta1kind: CustomResourceDefinitionmetadata: name: imagecaches.eci.alibabacloud.comspec: group: eci.alibabacloud.com version: v1 names: kind: ImageCache plural: imagecaches shortNames: - ic categories: - all scope: Cluster subresources: status: &#123;&#125; validation: openAPIV3Schema: required: - spec properties: spec: type: object required: - images properties: imagePullSecrets: type: array items: type: string images: minItems: 1 type: array items: type: string imageCacheSize: type: integer additionalPrinterColumns: - name: Age type: date JSONPath: .metadata.creationTimestamp - name: CacheId type: string JSONPath: .status.imageCacheId - name: Phase type: string JSONPath: .status.phase - name: Progress type: string JSONPath: .status.progress ○ 根据实际需要将待缓存的 docker 镜像名填写到 imagecache.yaml 中，我使用的 imagecache.yaml 完整内容如下： 123456789101112apiVersion: eci.alibabacloud.com/v1kind: ImageCachemetadata: name: gitlab-runnerspec: images: - gitlab/gitlab-runner-helper:x86_64-latest - gitlab/gitlab-runner:latest - node:20-alpine - node:20 - mcr.microsoft.com/playwright:v1.44.0-jammy - gcr.io/kaniko-project/executor:v1.14.0-debug ○ 执行&quot;kubectl apply -f imagecache.yaml&quot;使生效。○ imagecache 创建成功后可在&quot;阿里云工作台页面集群详情-&gt;工作负载-&gt;自定义资源-&gt;资源对象浏览器&quot;位置看到。 配置 ConfigMap◇ gitlab-runner 的配置文件在容器虚拟机的默认位置是&quot;&#x2F;etc&#x2F;gitlab-runner&#x2F;config.toml&quot;，样例已经在 gitlab-runner-deployment.yaml 中将 configMap 的 mountPath 配置到了&#x2F;etc&#x2F;gitlab-runner。◇ 参照gitlab 文档得到 authentication token(注意不能是 registration token)填写到 config-map.yaml。◇ 将私有 gitlab 网站与 kubernetes 集群的连接信息填写到 config-map.yaml 文件样例。其中 concurrent 控制支持同时执行任务的数量，由于 Serverless 特性可以认为不受限制。然后 executor 的 cpu 与内存配置通过 cpu_limit、cpu_request、memory_limit、memory_request 控制。◇ config.toml 中有关 [runners.kubernetes] 配置项的说明也在gitlab 文档。◇ config-map.yaml 完整内容如下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647apiVersion: v1kind: ConfigMapmetadata: name: gitlab-runner-configdata: config.toml: | concurrent = 10 check_interval = 0 [[runners]] name = &quot;runner-on-k8s&quot; url = $&#123;gitlab-url&#125; token = $&#123;authentication token&#125; executor = &quot;kubernetes&quot; output_limit = 51200 [runners.kubernetes] host = $&#123;k8s-connect-url&#125; cert_file = &quot;/etc/gitlab-runner/tls.crt&quot; key_file = &quot;/etc/gitlab-runner/tls.key&quot; ca_file = &quot;/etc/gitlab-runner/ca.crt&quot; namespace = &quot;default&quot; pull_policy = &quot;if-not-present&quot; cpu_limit = &quot;2&quot; cpu_request = &quot;2&quot; memory_limit = &quot;4Gi&quot; memory_request = &quot;4Gi&quot; helper_cpu_limit = &quot;0.5&quot; helper_cpu_request = &quot;0.5&quot; helper_memory_limit = &quot;1Gi&quot; helper_memory_request = &quot;1Gi&quot; helper_image = &quot;gitlab/gitlab-runner-helper:x86_64-latest&quot; [runners.kubernetes.pod_annotations] &quot;k8s.aliyun.com/eci-image-cache&quot; = &quot;true&quot; [runners.kubernetes.volumes] [[runners.kubernetes.volumes.pvc]] name = &quot;gitlab-runner-cache-pvc&quot; mount_path = &quot;/cache&quot; readonly = false [[runners.kubernetes.volumes.secret]] name = &quot;registry-auth-secret&quot; mount_path = &quot;/kaniko/.docker&quot; read_only = true [runners.kubernetes.volumes.secret.items] &quot;.dockerconfigjson&quot; = &quot;config.json&quot; [[runners.kubernetes.volumes.secret]] name = &quot;gitlab-credentials&quot; mount_path = &quot;/root/gitlab-credentials&quot; read_only = true ◇ 执行&quot;kubectl apply -f config-map.yaml&quot;使生效。◇ ConfigMap 创建成功后可在&quot;阿里云工作台页面集群详情-&gt;配置管理-&gt;配置项&quot;位置看到。 使用 deployment 部署 gitlab-runner 集群◆ 用于部署集群的 deployment 直接使用样例的 gitlab-runner-deployment.yaml 即可，完整内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: apps/v1kind: Deploymentmetadata: name: gitlab-runnerspec: selector: matchLabels: app: gitlab-runner template: metadata: labels: app: gitlab-runner annotations: k8s.aliyun.com/eci-image-cache: &quot;true&quot; spec: containers: - image: gitlab/gitlab-runner:latest imagePullPolicy: IfNotPresent name: gitlab-runner volumeMounts: - mountPath: /etc/gitlab-runner name: config volumes: - name: config projected: defaultMode: 420 sources: - secret: items: - key: ca.crt path: ca.crt - key: tls.crt path: tls.crt - key: tls.key path: tls.key name: gitlab-runner-secret - configMap: items: - key: config.toml path: config.toml name: gitlab-runner-config ◆ 执行&quot;kubectl apply -f gitlab-runner-deployment.yaml&quot;完成 gitlab-runner 的部署。◆ 部署成功后可在&quot;阿里云工作台页面集群详情-&gt;工作负载-&gt;容器组&quot;位置看到 gitlab-runner 的 pod。接下来在私有 gitlab 网站配置好 runner，当有 pipeline 任务执行时也可以看到相应 executor 的 pod。 配置 gitlab pipeline 中的相关问题与处理artifacts 与 cache♂ artifacts 与 cache 的区别在 gitlab 文档(https://docs.gitlab.com/ee/ci/caching/#how-cache-is-different-from-artifacts)里有说明。♂ 当前 gitlab-runner 的方案中，考虑到 artifacts 存储位置是 gitlab 所在远程主机，而 cache 存储位置在每个 executor 的本地磁盘(通过将 NAS 挂载到每个 executor 上实现了 cache 内容的共享)，特别当需缓存内容比较大的时候，使用 cache 优于 artifacts。♂ cache 没有 artifacts 那样的自动过期删除机制，对于打包结果这种每次存储路径不同的 cache，可在 after_script 阶段增加脚本以针对 cache key 清理不再使用的 cache 内容。示例： 1234567891011121314151617181920212223242526272829303132.dist-cache: &amp;dist-cache key: $CI_PIPELINE_ID paths: - ./diststages: - build - deploybuild-job: stage: build script: - echo &#x27;build&#x27;; cache: - &lt;&lt;: *dist-cache policy: pull-push allow_failure: falsedeploy-job: stage: deploy image: name: gcr.io/kaniko-project/executor:v1.14.0-debug entrypoint: [&#x27;&#x27;] script: - echo &#x27;build and push docker image based on cache&#x27;; after_script: - rm -rf /cache/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME/$CI_PIPELINE_ID*; cache: - &lt;&lt;: *dist-cache policy: pull dependencies: [build-job] build docker 镜像♀ 对于 docker 镜像的构建与推送，采用配置更简单的 kaniko 方式，根据参考文档[3]，已经在之前 ConfigMap 中配置 docker 仓库 secret 的 mountPath 到&quot;&#x2F;kaniko&#x2F;.docker&#x2F;config.json&quot;。♀ kaniko 镜像是个特别精简的 linux，不适合在其中配置打包环境。于是将打包与 docker 操作拆分到不同 job，打包结果通过上步 cache 的方式共享到 kaniko 镜像对应的容器中。♀ 使用 kaniko 的 deploy-job 的示例： 123456789101112131415161718192021.echo-variables: &amp;echo-variables - echo &quot;CI_PIPELINE_ID:&quot; $CI_PIPELINE_ID;deploy-job: stage: deploy image: name: gcr.io/kaniko-project/executor:v1.14.0-debug entrypoint: [&#x27;&#x27;] script: - /kaniko/executor --context &quot;$&#123;CI_PROJECT_DIR&#125;&quot; --dockerfile &quot;./Dockerfile&quot; --destination &quot;$&#123;registry_dist&#125;&quot; before_script: - *echo-variables after_script: - rm -rf /cache/$CI_PROJECT_NAMESPACE/$CI_PROJECT_NAME/$CI_PIPELINE_ID*; cache: - &lt;&lt;: *dist-cache policy: pull dependencies: [build-job] git ssh 鉴权▲ git ssh 信息的 mountPath 直接指定到&quot;&#x2F;root&#x2F;.ssh&quot;的时候遇到了如下问题：（1）gitlab-runner 的 config.toml 配置中[runners.kubernetes.volumes.secret]不支持指定 mout 文件的 mode，使用 id_rsa 文件做 ssh 鉴权会报错：&quot;Permissions 0644 for &#39;&#x2F;root&#x2F;.ssh&#x2F;id_rsa&#39; are too open. This private key will be ignored&quot;。（2）即使将配置中[runners.kubernetes.volumes.secret]的 read_only 设置为 false，对 id_rsa 执行 chmod 操作也报错&quot;chmod: changing permissions of &#39;&#x2F;root&#x2F;.ssh&#x2F;id_rsa&#39;: Read-only file system&quot;。▲ 于是在 ConfigMap 中将 mountPath 指定到了&quot;&#x2F;root&#x2F;gitlab-credentials&quot;，之后在 pipeline 里再将文件从&quot;&#x2F;root&#x2F;gitlab-credentials&quot;拷贝到&quot;&#x2F;root&#x2F;.ssh&quot;并设置文件 mode。▲ 如下示例定义一个初始化 git 鉴权文件的锚点供需要时引用。 123456.prepare-git: &amp;prepare-git - set +e;cat /root/.ssh/known_hosts;if [[ $? -ne 0 ]]; then mkdir /root/.ssh;cat /root/gitlab-credentials/id_rsa &gt; /root/.ssh/id_rsa;chmod 400 /root/.ssh/id_rsa; cp /root/gitlab-credentials/id_rsa.pub /root/gitlab-credentials/known_hosts /root/.ssh/; fi;set -e; - ssh -T git@$&#123;git_domain&#125; 参考文档 从零入门 Serverless | 教你 7 步快速构建 GitLab 持续集成环境 gitlab 官方 doc kubernetes executor 上支持 docker 命令"},{"title":"<State of GPT>理解","date":"2024-05-08T11:00:57.000Z","path":"knowledge/State-of-GPT-理解.html","tags":[{"name":"GPT","slug":"GPT","permalink":"https://congzhou09.github.io/tags/GPT/"}],"text":"▲ 对 Microsoft Build 2023 上 Andrej Karpathy 演讲State of GPT的学习整理。▲ 演讲 PPT 地址。 GPT Assistant 是如何训练得到的◇ 训练过程按先后顺序分为自左至右的 4 个阶段：Pretraining、Supervised Finetuning、Reward Modeling、Reinforcement Learning。◇ 每个阶段都涉及 3 项内容：dataset、algorithm、model，其中 model 是通过 dataset+algorithm 训练得到的。 Pretraining◇ 预训练阶段几乎占了整个训练 99% 的运算性能与运算时间。长达数月，其他三种阶段都属于微调，训练仅消耗数天甚至数小时。◇ 预训练得到的模型称为 base model。base model 不同于 assistant model，用于内容预测生成而不是回答问题。◇ 预训练数据有多种来源，例如 Meta 公司的 LLaMA 模型的数据来源如下图。既有网络爬取数据，也有高质量数据集。 ◇ 数据集内容在使用前会通过 tokenization 被转换成整数序列。 ◇ LLaMA 相比 GPT-3 更擅长对大量文本数据做深入理解语义的任务（如阅读理解与问答），GPT 的优势是对写作、对话、翻译等各种通用任务都表现好。下图是 LLaMA 与 GPT-3 的训练参数的对比，其中 vocabulary size 表示训练数据包含的不重复词汇量，context length 表示训练的上下文长度，parameters 表示训练用到的参数数量，trained on tokens 表示训练数据转换成的 token 数量，可见 LLaMA 在 parameter 和 vocabulary 方面的数量更少但在 trained on tokens 方面的数量更多。模型表现受训练数据多个维度参数的影响。 ◇ 大致训练过程：训练数据被放到数组(B,T)，行数 B 表示输入分为多少批，列数 T 表示最大上下文长度。数组的每一行包含多条数据序列，各条序列之间有约定好的分隔符。训练目标是让 transformer 神经网络能够在任意单元格(以图中绿格为例)根据当前及其左侧所有单元格趋于准确地推断出红色单元格的内容。 ◇ 相较于传统的 NLP 模型，由于此处的 base model 在预训练过程中理解了大量文本结构与概念，针对特定任务对其进行微调时仅需较少的标注数据就能达到很好的性能。而从 GPT-2 开始，人们发现仅通过 prompt 而无需 finetuning 就能让 base model 较好完成某些特定任务，由此开启了“prompting over finetuning”的时代。 ◇ GPT-2 的 base model 公布在官方 GitHub 仓库，GPT-3 的 base model 可通过官方 api 使用模型&quot;Devanshi&quot;调用，GPT-4 的 base model 没有发布。当前最好的 base model 是 LLaMA，但目前未支持商用。 ◇ 下图是当前各模型信息。 SFT（Supervised finetuning）◆ 这一阶段的算法不变，只是数据集改成了 1-10 万数量的高质量&quot;prompt+response&quot;的问答示例，以向 assistant model 的方向训练。◆ 训练结果模型称为 SFT model。 RLHF（reinforcement learning from human feedback ）□ RLHF 由 Reward modeling 和 Reinforcement learning 两个阶段组成。□ Reward modeling 阶段的数据集量级在 10-100 万，内容是：上阶段 SFT model 对同一个 prompt 回答的多次 response+人为指定的效果分数排序。以此指导模型能针对一个 prompt 给相应的 response 打分。此阶段得到的模型称为 RM model。□ Reinforcement learning 阶段的数据集量级在 1-10 万，内容是：prompt+SFT model 的多次回答+RM model 对相应回答的打分。以此强化模型针对 prompt 给出分数更高的 response。□ 经过 RLHF 得到的模型称为 RLHF model。ChatGPT 就属于 RLHF model。□ RLHF 提高了模型的结果分数但也使其丧失了部分多样性(variation)，于是在已知 N 个目标输出样例并期望得到具有更多多样性输出的场景，可以考虑使用 base model。□ https://lmsys.org 网站提供了大语言模型(LLM)的竞技场(https://chat.lmsys.org/)，并会定期发布排名结果到blog(如：https://lmsys.org/blog/2023-12-07-leaderboard/)，目前排名靠前的模型都是RLHF model。 实践中如何有效使用 GPT assistant■ 不同于人类从问题到答案的思维过程，transformer 的&quot;think&quot;是 tokens 维度的，它得出答案的过程是不断得基于现有 token(s) 预测下个 token。因此，当问题的回答需要推理时，通过将问题拆分步骤(Chain-of-Thought)的方式减少问题中每个 token 需要推理的数量，能得到更好的答案。拆分方式有两种：（1）prompt 中按照拆分步骤的方式提供一组问答样例（2）prompt 中说明&quot;分步骤思考&quot;(“think step by step”) ■ 当生成答案期间如果有一个 token 偏离了问题，transformer 不会返回检查纠正而是继续基于已生成 token 继续生成后续内容。但可以通过带上历史问答内容重新提问上次回答是否满足提问需求使它对上次回答检查并返回纠正后的回答。目前有称为&quot;Tree of Thoughts&quot;方向的研究，目的是将许多 prompts 与树检索算法结合以动态得到最优的生成答案从而避免出现需要纠正的情况。 ■ LLM 的&quot;心理癖好&quot;：LLM 仅倾向于模仿所有相关训练数据生成完整答案而不会对训练数据中不同级别的答案做区分，比如对于一个物理问题，训练数据中通常既有专家级别的答案也有学生级别的答案甚至还有开玩笑的答案，LLM 默认会同时模仿所有级别的答案，这时可通过设置“Let&#39;s work this out in a step by step way to be sure we have the right answer.”、“You&#39;re a leading expert on this topic.”、“Pretend you have IQ 120.”这样的 prompt 来排除对低质量答案的模仿。■ 为 LLM 指定可以使用的 tools(or plugin) 的场景中，在 prompt 中告诉 LLM 不擅长对应 tool 的能力可以让 tool 的调用更准确，因为 LLM 并不知道它自己不擅长的方面。■ 检索增强(retrieval-augmented)的 LLM，LLM 只有从训练数据得来的知识记忆(memory)，如果将检索得到的提问相关信息放入 LLM 的上下文窗口(可称为 working memory)就可以同时发挥两者优势得到更好的答案。当前出现的方案是将信息分块后存入向量存储(如 LlamaIndex)，针对提问先检索得到相关信息再将其组织成 prompt。■ 在希望限制 LLM 按照固定模板格式输出结果的场景，可以使用guidance。■ finetuning 的本质是更新模型的参数权重，涉及更多专业技术，已知优化策略与相关工具：（1）Parameter Efficient Finetuning(PEFT)。PEFT 是深度学习领域的一种优化策略，目标是在微调过程中尽可能减少需要更新的参数数量，而让模型的大部分参数权重固定，从而大幅降低 finetuning 成本。工具如：LoRA。（2）Low-precision inference(低精度推理)。低精度推理是深度学习领域的一种优化策略，通过降低模型权重和激活的精度，减少模型的内存占用和计算需求而提高运行速度，在模型训练&#x2F;微调完成后使用。结合前面 PEFT 只针对微调部分做低精度推理也可降低计算成本。工具如：bitsandbytes。■ 目前的 LLM 适合应用在与人为监督相结合的低风险领域，如灵感、建议、copilot。 来自 GPT-4 的激励"},{"title":"AFFiNE纯前端调试环境搭建","date":"2024-04-29T10:10:17.000Z","path":"practice/AFFiNE纯前端调试环境搭建.html","tags":[{"name":"AFFiNE","slug":"AFFiNE","permalink":"https://congzhou09.github.io/tags/AFFiNE/"}],"text":"场景◇ AFFiNE 项目包含了前端和后端的代码。想要在本地仅调试 web 前端代码(包括 Cloud Workspace 的内容)，而无需配置与启动其中的后端部分。 实现方式● 项目 package.json 文件提供的 dev 脚本已经提供了交互式命令行界面来启动本地 web 开发服务，其默认连接的后端是 http://localhost:3010，将连接目标改为官方网址(https://app.affine.pro/)对应的后端。 操作步骤修改本地 web 开发服务的配置◆ 项目 dev 脚本运行的是项目内的 @affine&#x2F;cli 包，它的配置文件位于：&quot;tools\\cli\\src\\webpack\\config.ts&quot;。◆ 将配置文件内容中所有的&quot;target: &#39;http://localhost:3010&#39;&quot;改为&quot;target: &#39;https://app.affine.pro/&#39;&quot;，并添加&quot;changeOrigin: true&quot;和&quot;secure: false&quot;。◆ 例如其中的{context: &#39;&#x2F;socket.io&#39;, ...}这条，修改后如下。 1234567&#123; context: &#x27;/socket.io&#x27;, target: &#x27;https://app.affine.pro/&#x27;, changeOrigin: true, secure: false, ws: true,&#125;, 启动本地 web 开发服务■ 运行&quot;yarn dev&quot;启动本地 web 开发服务。■ 浏览器进入本地开发页面：http://localhost:8080。 在官方网站上登录● 要使用&quot;Cloud Workspace&quot;涉及到第三方网站的登录鉴权，由于官方网站后端 API 登录成功后的重定向地址是官方网站的地址，所以登录流程无法在本地开发环境完成。手动在官方网站(https://app.affine.pro/)上完成登录。● 登录成功并进入&quot;Cloud Workspace&quot;之后，拷贝当前网址中的路径，如：&quot;https://app.affine.pro/workspace/xx-xx-xx/all&quot;对应的路径是&quot;/workspace/xx-xx-xx/all&quot;。● 浏览器开发者工具中查看已登录官方网站下的 cookie 字段：affine_session。 拷贝官网身份信息到本地▲ 将上节中 affine_session 字段及值创建与拷贝到本地 cookie，其中的 domain 值使用与本地开发页面相同的&quot;localhost&quot;。 ▲ 在本地环境访问上节路径，如：&quot;http://localhost:8080/workspace/xx-xx-xx/all&quot;，就可以看到与官网相同的内容并调试前端代码了。"},{"title":"GitHub的workflow中clone私有仓库","date":"2024-04-18T11:44:40.000Z","path":"practice/GitHub的workflow中clone私有仓库.html","tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://congzhou09.github.io/tags/GitHub/"},{"name":"workflow","slug":"workflow","permalink":"https://congzhou09.github.io/tags/workflow/"}],"text":"场景◇ GitHub 的项目 A 中，某个子文件夹需从另一个私有项目 B 通过 git clone 得到，有了这个子文件夹，项目 A 的 workflow 中某 step 才能正确执行。 实现方式◆ 使用 workflow 提供的 actions&#x2F;checkout@v4 来 clone 代码，为其指定鉴权 token 以实现对私有仓库的访问。 操作步骤鉴权 token 的获取■ 进入对项目 B 有访问权限的 GitHub 用户的 Settings 页面。■ 进入 Developer Settings-&gt;Presonal access tokens-&gt;Tokens(classic)菜单，创建一个&quot;personal access token (classic)&quot;，期间指定有效期，以及勾选 clone 项目 B 所需权限相关的 scopes。 配置 token 到项目 A■ 进入项目 A 的 Settings 页面。■ 进入 Security-&gt;Secrets and variables-&gt;Actions 菜单，通过&quot;New repository secret&quot;按钮创建一个 secret，期间的 Secret 内容填写上一步的 token 值。 workflow 配置 clone 项目 B■ 相应 workflow 的 yaml 配置文件中，在依赖于子文件夹的 step 之前增加一个 clone 项目 B 代码到子文件夹的 step，示例如下，将其中的&lt;&gt;值替换为真实值。 1234567891011- ...other steps ...- name: Clone private repository uses: actions/checkout@v4 with: repository: &lt;organization or personal space&gt;/&lt;repository name&gt; ref: &lt;branch name&gt; token: $&#123;&#123;secrets.&lt;secret name&gt;&#125;&#125; path: &lt;destination folder name of the git clone&gt;- ...other steps ..."},{"title":"从技术角度看emoji表情","date":"2023-07-13T01:09:23.000Z","path":"knowledge/从技术角度看emoji表情.html","tags":[{"name":"web","slug":"web","permalink":"https://congzhou09.github.io/tags/web/"}],"text":"概览○ emoji 是个形状图形，通常以彩色卡通方式展现，内容涵盖表情、天气、食物、动植物、交通建筑等多种类别。emoji 能内嵌在文字段落中，拓宽了文字表达的界限。○ emoji 最早于 1999 年出现在日本移动电话中，“emoji”这个词源自日语：絵 (え ≅ picture) 文字 (もじ ≅ written character)。○ emoji 的内部表示方式有以下两种。使用字体字形方式时与其他字符一样通过编码让字体去解析与展示，此时的 emoji 更确切得称为&quot;emoji 字符&quot;。（1）内置图形&lt;graphics&gt;方式。每个 emoji 对应一个图像数据。（2）字体字形&lt;glyphs&gt;方式。每个 emoji 对应一种编码。○ 随着 emoji 在世界范围内的流行，不同平台厂商的 emoji 无法互通的问题涌现，使得统一 emoji 集合与字符编码的需求不断增加，Unicode 联盟于 2007 年通过了在 Unicode 字符集里扩展 emoji 字符的提案，2009 年发布的 Unicode 5.2 首次明确添加了第一批作为 emoji 字符的 Unicode 字符，之后不断有新批次的 emoji 字符随着 Unicode 的新版本被添加进去。○ 从 2018 年的&quot;Emoji 11.0&quot;开始，emoji 字符集版本号与 Unicode Standard 使用相同版本号同步发布。 ○ 这个表格详细列出了每个版本分别新增了哪些 emoji。○ 通常说的字符编码是字符在 Unicode 字符集内被分配的一个唯一的编码数值，这个数值称为代码点（code point）。代码点通常用 16 进制表示，如 emoji 笑脸的代码点是 U+1F600 。○ 这个网站 emojipedia 可用于查看 emoji 表情的代码点组成。○ emoji 字符涉及如下图中 6 个相关属性。 ○ 上述相关属性，一个 emoji 字符可能同时有多个属性值为 Yes ，相应字符也有对应的名称，列举如下：（1）emoji character。具有“Emoji”属性的字符，这类字符通常直接展示 emoji 内容。（2）emoji presentation。具有“Emoji_Presentation”属性的字符，默认以多彩图形的 emoji 方式展示而不是文本方式。与此属性相关有两个变体选择器字符 VARIATION SELECTOR-15(U+FE0E) 和 VARIATION SELECTOR-16(U+FE0F) 分别用于显式指定前面字符的呈现方式为文本或多彩图形。两种展示方式的最大差别是：文本方式展示为单色且可由字体颜色控制变色，而多彩图形方式色彩多样且不受字体颜色控制。（3）emoji modifier。具有“Emoji_Modifier”属性的字符，用于修改前面的 emoji 字符的外观或语义(如肤色、性别)。（4）emoji modifier base。具有“Emoji_Modifier_Base”属性的字符，只有这些字符才支持被随后的 emoji modifier 修改。（5）extended pictographic character。具有“Extended_Pictographic”属性的字符，该属性提供了字符分割的规则信息，确保 emoji 序列 ↓ 这种被多个代码点组成的 emoji 表情能在分词时被正确分割。（6）emoji component。具有“Emoji_Component”属性的字符，用于组成 emoji 序列，这类字符可能是 emoji character 也可能自身不独立展示 emoji 内容甚至只是个普通基础字符。例如键帽表情符号 1️⃣ 的序列组成是 U+31 和 U+FE0F 和 U+20E3，对照 emoji-data 可知三个字符都是 emoji component，而其中 U+31 对应的数字 1 是个基础字符。再如中国国旗 🇨🇳 的序列组成是 U+1F1E8 和 U+1F1F3，两个地区标志(Regional Indicator)字符同属于 emoji component 和 emoji character 和 emoji presentation。再如女科学家 👩‍🔬 的序列组成是 U+1F469 和 U+200D 和 U+1F52C，其中第一第三个字符同时是 emoji character 和 extended pictographic character，而第二个字符仅是 emoji component。○ emoji 字符集版本号有三个特殊值：E0.0 和 E0.6 和 E0.7。其中 E0.0 包含了所有版本的 emoji 字符集里的 emoji component 和非 emoji character 字符。E0.6 和 E0.7 分别包含了当初添加到 Unicode 6.0 和 Unicode 7.0 的 emoji 字符，当时的 emoji 字符集没有自己的版本号。 显示外观■ Unicode 字符集里定义的原始 emoji 是下图这种黑白朴素样式（需将链接指向的 *.txt 文件下载到本地，再使用纯文本编辑器打开）。 ■ 与其他 Unicode 字符一样，同一个 emoji 由于所用字体不同可以展示为不同的样式。emoji 的样式分为&quot;text presentation&quot;和&quot;emoji presentation&quot;两大类，这在前面 emoji 字符的 emoji presentation 属性部分有陈述。■ 平时更经常看到的各种多彩图形样式是各平台厂商设计与提供的，从这里可以看到同一个 emoji 在不同平台厂商的外观。■ 显示异常情况：当展示 emoji 的平台所支持 Unicode 版本低于某个 emoji 字符所在版本，这个字符将无法正常显示。 emoji 序列（emoji Sequences）♂ emoji 标准中存在多种序列，这些序列由两个或多个字符组成，每个序列展示为一个新的单独的表情符。♂ emoji 字符与变体选择器字符(见上文)组成的序列称为呈现序列(emoji presentation sequence)。♂ emoji modifier base 与 emoji modifier 组成的序列称为修饰序列(emoji modifier sequence)。♂ 由两个 regional indicator character 组成的序列称为旗帜序列(emoji flag sequence)。♂ 由表情字符和标签字符组成的序列称为标签序列(emoji tag sequence)。可用于组成标签序列的字符在这里定义。♂ 由[0-9#*]字符和键帽字符(U+FE0F 和 U+20E3)组成的序列称为键帽序列(emoji keycap sequence)。♂ 通过 ZWJ 组合成的序列称为 ZWJ 序列。ZWJ 是 Zero Width Joiner（零宽连接器）的缩写。它是个特殊的 Unicode 不可见字符，编码为 U+200D。♂ emoji ZWJ 序列就是通过 ZWJ 字符连接已有 emoji 字符形成的，用于表示一个合成的 emoji 字符。♂ 举例：👩‍🔬（女科学家）是由女性符号（👩）和实验室设备符号（🔬）通过 ZWJ 连接而成。♂ 这里列出了当前所有 emoji ZWJ 序列。♂ 因此我们看到的一个 emoji 图像的背后可能包含了多个 Unicode 字符。♂ emoji 序列的存在使得统计 emoji 数量变得不容易，近期字符集版本都提供了 emoji counts 表格，以15.0 版本的 emoji counts 表格为例，其从表情分类与实现结构两个维度做了数量统计，实现结构维度的术语解释在这里。 肤色的实现♀ 对于展示人物和身体部位的 emoji，最初计划是像笑脸那样使用一致的非现实肤色(黄色或橙色)。随着肤色需求的增加，2015 年发布的 Unicode Version 8.0 中增加了如下 5 个修饰字符(symbol modifier character)。 ♀ 其中的样例颜色是基于名为 Fitzpatrick scale（菲茨帕特里克肤色分类法）的皮肤学标准制定的，而且提供了相应的灰度色用于适应黑白色环境。♀ 这几个 modifier 字符可独立显示，此时展示内容是样例颜色方块。当放在特定的 emoji 字符之后时，则组成一个修饰序列(emoji modifier sequence)，展示对应肤色的 emoji 内容。♀ 常见支持换肤色的 emoji 种类有人物、身体部位、职业、运动，从字符属性上看是前面提到的 emoji modifier base 字符，标准规范中将它们统称为&quot;human emoji&quot;(非正式术语)。当 human emoji 后面没有 emoji modifier 时则展示与笑脸一样的非现实肤色。♀ 实际应用中的带肤色 emoji 通常是直接选择的，而无需先选 human emoji 再选 emoji modifier。 分类与顺序△ emoji 字符默认的分类和顺序定义在 Unicode 的 CLDR 中。CLDR(Common Locale Data Repository)是用于提供全球化和本地化数据的开放标准。△ 分类和顺序详情提供在这里。 名称与检索关键词♥ 与其他 Unicode 字符一样，每个 emoji 字符都有个正式名称(formal Unicode name)，这个名称是字符集内唯一的且不会随版本变更，即使随着发展最新含义与最初名称出现了偏差，比如 💃(U+1F483)的正式名称是 DANCER，现在的含义 woman dancing 是随着 🕺(man dancing)的加入而变化的。正式名称通常书写为全大写字母。♥ 每个 emoji 字符有个 CLDR 短名称(CLDR short name)，通过单词或短语描述 emoji 的含义或特征。CLDR 短名称会随着新版本做必要的变更。♥ emoji 序列由于其实现原理是多个字符的组合，因此就只有 CLDR 短名称而没有正式名称。♥ CLDR 短名称在 CLDR 中也被称为 TTS 名(text-to-speech name)。♥ CLDR 是多语言的，内容维护在 GitHub 且提供了多种数据格式，如 xml 和 json，短名称与检索关键词(keywords)位于其中的 &quot;annotations&quot; 文件夹，以语言名缩写作为子路径或文件名，如中文的 json 文件路径是：&quot;cldr-json&#x2F;cldr-annotations-full&#x2F;annotations&#x2F;zh&#x2F;annotations.json&quot;。♥ CLDR 也提供了在线工具survey-tool，在页面左侧先选择语言再选择 Characters-&gt;分类就可以看到分类下各个 emoji 表情的短名称和搜索关键词了。 推荐项目▲ GitHub 上的 emoji-mart 实现了 emoji 表情选择器，支持图片与 Unicode 字符两种方式，适合作为开发 emoji 表情相关内容的参考。 参考文献◇Unicode® Technical Standard - Unicode Emoji"},{"title":"动态import引起的打包体积增大","date":"2023-03-21T07:24:23.000Z","path":"problem/动态import引起的打包体积增大.html","tags":[{"name":"webpack","slug":"webpack","permalink":"https://congzhou09.github.io/tags/webpack/"}],"text":"背景◆ 正常情况下 webpack 的编译是从入口文件开始按照模块依赖关系仅对被依赖的文件做编译的。今天在某项目里增加了个模块文件写到一半保存而还没对其做 import ，但此时 webpackDevServer 就已经报出这个模块内的语法错误了。 解决与总结◇ 根据堆栈信息追到再上一级的报错位置，来到下面这个函数，由于把动态 import 封装到函数，传入函数的值是个变量。 12345... ...function importFromPath(pathName) &#123; ... ... return import(`$&#123;pathName&#125;`);&#125; ◇ 根据webpack 文档的说明并结合试验发现，此种情况下，该文件同层级及以下层级中的所有文件会被纳入 webpack 的编译与打包范围，从而导致了上述问题。 ◇ 随着项目量级增加，当有更多不在依赖关系树上的文件通过此机制被引入后就会引起整体打包速度变慢和打包体积增大。所幸 webpack 针对 import()默认会创建一个新的 chunk 将其分离到单独的 bundle ，不会在打包结果部署后还影响其他模块的载入速度。 ◇ webpack 提供了magic-comments用于配置处理动态 import()的行为。其中的&quot;webpackInclude&quot;能限定搜索动态模块的范围，可以解决我的问题。 ◇ 因此在 webapck 中使用&quot;import(变量)&quot;时最好增加&quot;webpackInclude&quot;注释，以防止无关文件对打包的影响。"},{"title":"Base64编码与DataUrl","date":"2022-12-31T13:58:56.000Z","path":"knowledge/Base64编码与DataUrl.html","tags":[{"name":"Base64","slug":"Base64","permalink":"https://congzhou09.github.io/tags/Base64/"},{"name":"DataUrl","slug":"DataUrl","permalink":"https://congzhou09.github.io/tags/DataUrl/"}],"text":"Base64 编码◇ Base64 是个二进制转文本的编码方案，它将每 3 个 8bit 数据表示为 4 个使用 6bit 编码的 Base64 字符。◇ Base64 是 Base 编码的一种，其他 Base 编码如：Base16、Base32，&quot;Base&quot;后的数字越小，用来编码的字符数量越少。◇ Base 编码的使用场景是在某些仅支持文本(甚至仅支持有限数量的文本字符)的环境中存储或传输数据。◇ Base 编码规则详细定义在 RFC4648。◇ Base64 编码的 6 个 bit 位，二进制值从 000000 到 111111 分别编码为字符“A-Z”，“a-z”，“0-9”，“+”，“&#x2F;” 。另外有个 padding 字符“&#x3D;”，当末尾 bit 组长度不够 24bit 的时候，用一个或两个“&#x3D;”标识编码前缺少几个 8bit 才够 24bit，从而在解码时能正确解码“&#x3D;”前的那个字符。◇ 综上可得 Base64 编码结果有如下特性：（0）Base64 编码结果中最多有 65 种字符。（1）“&#x3D;”字符只可能出现在编码结果末尾，数量不会超过两个。（2）编码结果的字符数量是 4 的倍数。（3）编码后的结果字符如果使用 ASCII 编码存储或展示，由于每个 ASCII 字符占用 8bit 空间，也就是用每 8bit 存储原来数据的 6bit，所以占用存储空间大约是原数据的 8&#x2F;6&#x3D;4&#x2F;3 倍。 Base64 示例示例 1☆ 待编码数据是用 ASCII 编码的“Man”对应的二进制数据 ● 编码前数据的二进制内容如下图。 ● 将每 24bit 分成 6bit 组，每个 6bit 组使用 Base64 字符表示如下，可得“TWFu”。 示例 2☆ 待编码数据是用 ASCII 编码的“Mana”对应的二进制数据 ● 编码前二进制数据是示例 1 二进制内容后接“01100001”。● 将每 24bit 分成 6bit 组，第 1 个 24bit 组与示例 1 一致。第 2 个 24bit 组中第 1 个 6bit 组是“011000”对应字符“Y”，第 2 个 6bit 组是“01”末尾填充 0 得到“010000”对应字符“Q”。由于第 2 个 24bit 组只有 8bit，还差两个 8bit 才够 24bit，所以使用两个 padding 字符标识。最终编码就是“TWFuYQ&#x3D;&#x3D;”。 JS 中的 Base64 编码○ JS 提供了 btoa() 函数用于将二进制字符串转为 Base64 字符串。例如调用 btoa(&quot;Mana&quot;)可得到&quot;TWFuYQ&#x3D;&#x3D;&quot;，即上述示例 2 的结果。另外有 atob()函数执行相反操作。○ btoa() 函数将输入字符串中每个字符当做 1 字节二进制数据处理，如果输入字符串中包含有效长度超过 1 字节的字符，就会报异常错误。○ JS 的字符是通过 UTF-16 编码的，每个字符占 2 字节空间，其中的 ASCII 字符虽然也占 2 字节，但仅第 1 个字节内是有效内容，第二个字节全零，所以 btoa()处理 ASCII 字符不会报异常。○ 可以通过以下表达式取值长度是否大于 2 判断某字符有效长度是否超过 1 字节。 1&lt;string&gt;.charCodeAt(0).toString(16) DataUrl♂ Base64 编码的一个应用场景是在 HTML 或 CSS 文件中内嵌图片、SourceMap 等二进制资源，内嵌通过 DataUrl 实现。♂ DataUrl 是种特殊的 url，它将数据内容直接嵌入在 url 里而不需要额外的外部文件。它以&quot;data:&quot;开头，包含如下 4 个部分。 1data:[&lt;mediatype&gt;][;base64],&lt;data&gt; ♂ 其中 &lt;mediatype&gt; 是一个 MIME 类型字符串，标识 data 内容的格式，取值如“image&#x2F;jpeg”，“application&#x2F;x-www-form-urlencoded”，如果省略则按照“text&#x2F;plain;charset&#x3D;US-ASCII”处理。♂ 当有“;base64”时表示 data 是经过 Base64 编码的。 DataUrl 示例示例 1☆ webpack 的 devtool 配置项 ■ devtool 配置项的“inline-”和“eval-”两个前缀的含义是将 SourceMap 嵌入在打包文件中。■ “inline-”方式，以“inline-source-map”为例，每个 bundle 对应一个 SourceMap，附加到整个 bundle 文件的末尾。■ “eval-”方式，以“eval-source-map”为例，每个模块对应一个 SourceMap，附加到每个模块 eval 包裹内部的末尾。此种情况下，二次编译时能做到模块级 SourceMap 的单独替换，因此在 webpack dev rebuild 时更有速度优势。 示例 2☆ webpack 的 url-loader ■ url-loader 的 “options” 提供了一个 “limit” 配置项，当文件大于这个配置项值时执行 file-loader 的行为，否则便将资源转换成 DataUrl 嵌入到引入位置。■ url-loader 和 file-loader 自 webpack5 起被“module.rules.type”配置项替代。 示例 3☆ 占用空间最小的 base64 图片的 DataUrl ■ web 页面中有时需要一个有效的 元素占位，通常将其 src 属性设置为如下 DataUrl 内容。 1data:image/gif;base64,R0lGODlhAQABAIAAAAAAAAAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw== ■ 这个字符串中的 Base64 编码内容是一个 1x1 像素的透明 GIF 图片的数据。 参考文献◆ Base64 wiki◆ MDN Data URLs◆ webpack devtool"},{"title":"阿里低代码开源项目学习-项目初识","date":"2022-06-27T13:05:08.000Z","path":"knowledge/阿里低代码开源项目学习-项目初识.html","tags":[{"name":"低代码","slug":"低代码","permalink":"https://congzhou09.github.io/tags/%E4%BD%8E%E4%BB%A3%E7%A0%81/"}],"text":"概念共识◻︎ 低代码平台的组成部分：物料体系、低代码设计器、工程化体系(如配置的存取、版本的管理、产物的打包发布)。◻︎ 低代码设计器：低代码平台提供的用于可视化搭建页面或模块的地方，通常就在平台的&quot;&#x2F;edit&quot;页面。是低代码平台的核心。◻︎ 低代码引擎：用于研发低代码设计器的框架，作用是帮助低代码平台开发者快速产出自定义的低代码设计器。总结为两点,（1）实现了低代码设计器基础功能;（2）提供了定制扩展能力。◻︎ 阿里低代码引擎提供的定制扩展能力体现在如下几个方面：物料、插件、设置器。 ◻︎ 低代码设计器插件是设计器中的自定义按钮和图标，支持两种形式：（1）PanelDock，展示图标，内容在展开面板中展示（2）Widget，内容直接展示。 涉及到的仓库●build-scripts。项目使用的工程构建脚手架工具，基于 webpack，包名自 1.x 版本起从&quot;@alib&#x2F;build-scripts&quot;更名为&quot;build-scripts&quot;。● lowcode-engine。低代码引擎，遵循低代码引擎白皮书介绍的设计思路。●lowcode-demo。将引擎、设置器、插件、物料等组合起来的示例工程。●lowcode-materials。包含 Demo 中使用的物料库(antd, fusion)。●lowcode-engine-ext。包含 Demo 中使用的设置器。●lowcode-plugins。包含 Demo 中使用的插件。 build-scripts■ 通过 build-scripts 组织的项目本质还是使用 webpack 生态(API 函数、loader、plugin、webpack-dev-server)。■ 设计思路，将调试&amp;构建&amp;测试流程做了如下三个层级的抽象：（1）将通用流程化的内容封装到 build-scripts 命令行(start-开发调试 &amp; build-打包 &amp; test-测试)。（2）将针对特定场景及特性的通用配置与处理逻辑封装到 build-scripts 插件。（3）通过本地自定义插件提供项目特有的个性化配置。■ 以上(2)(3)体现在 build.json 文件内容中。 1234567891011121314&#123; &quot;entry&quot;: &#123; &quot;preview&quot;: &quot;./src/preview.tsx&quot; &#125;, ... ... &quot;plugins&quot;: [ [ &quot;build-plugin-react-app&quot; ], ... ... &quot;./build.plugin.js&quot; ]&#125; ■ 以下是官方提供的 build-scripts 插件。支持发布自己的 build-scripts 插件。 ■ build-scripts 使用 webpack-chain 管理 webpack 配置，最终通过 webpack-chain 的 toConfig()方法转为符合格式规则的配置内容传入内部 webpack 使用。本地自定义插件中修改配置也通过编写 webpack-chain 的过程化语句实现。例如： 123456789101112131415161718192021222324252627module.exports = (&#123; onGetWebpackConfig, context &#125;) =&gt; &#123; onGetWebpackConfig((config) =&gt; &#123; ... ... // 设置alias config.resolve.alias.set(&#x27;@&#x27;, path.resolve(__dirname, &#x27;./src&#x27;)); // 修改publicPath config.output.publicPath((process.env.PUBLIC_PATH || &#x27;&#x27;) + &#x27;/&#x27;); // 定义常量 config.plugin(&#x27;define&#x27;).use(context.webpack.DefinePlugin, [ &#123; &#x27;process.env.DEPLOY_ENV&#x27;: process.env.DEPLOY_ENV, &#125;, ]); // 设置webpackDevServer的代理 config.devServer.proxy(&#123; &#x27;/api&#x27;: &#123; target: &#x27;https://api.service.com&#x27;, changeOrigin: true, &#125;, &#125;); ... ... &#125;);&#125; lowcode-engine○ 项目通过 lerna 管理，功能模块以 npm 包的形式组织，各个 npm 包使用 build-scripts 管理。○ 项目主要输出的包有三个：@alilc&#x2F;lowcode-engine、@alilc&#x2F;lowcode-react-renderer、@alilc&#x2F;lowcode-react-simulator-renderer。○ @alilc&#x2F;lowcode-engine 是低代码引擎的核心包，也会依赖项目中的其他包，如@alilc&#x2F;lowcode-designer、@alilc&#x2F;lowcode-editor-core、@alilc&#x2F;lowcode-editor-skeleton。模块依赖与所属包的关系如下图。 ○ 各模块作用的简要说明： 模块 作用 pulgins 用于设计器定制内容(插件、设置器、物料)的动态引入 skeleton 注册管理插件 setters 注册管理设置器 material 注册管理物料 hotkey 绑定管理快捷键 event 自定义事件处理 project 管理编排功能相关的模型系统 config 负责配置的读写 ○ @alilc&#x2F;lowcode-react-renderer 是低代码设计器产物的渲染组件。○ @alilc&#x2F;lowcode-react-simulator-renderer 是低代码设计器中的画布组件。 lowcode-demo■ 项目主要输出两类页面：（1）可视化编辑页面（2）可视化编辑页面产物的预览页面。■ 项目入口如下，除了 “build.json” 中的 preview 之外，还有在“build.plugin.js”中动态写入的 scenarios 文件夹中各子文件夹。 123456789101112131415161718&#123; preview: [ &quot;src/preview.tsx&quot;, // 预览页面入口 ], &quot;antd-pro-with-formily&quot;: [ &quot;src/scenarios/antd-pro-with-formily/index.ts&quot;, ], &quot;basic-antd&quot;: [ &quot;src/scenarios/basic-antd/index.ts&quot;, ], &quot;basic-formily&quot;: [ &quot;src/scenarios/basic-formily/index.ts&quot;, ], ... ... // scenarios文件夹中各个子文件夹，对应各场景的编辑页面 index: [ &quot;src/scenarios/index/index.ts&quot;, // 综合编辑页面，提供了场景切换功能 ],&#125; 编辑页面● 编辑页面首先使用官方提供的插件、设置器、物料库对引擎做了定制。其中动态异步加载的地方都通过 plugins.register() 实现。 123456789101112131415161718192021222324252627282930/** src/universal/plugin.tsx **/import AliLowCodeEngineExt from &#x27;@alilc/lowcode-engine-ext&#x27;; // 官方设置器import CodeGenPlugin from &#x27;@alilc/lowcode-plugin-code-generator&#x27;;... &#x27;@alilc/lowcode-plugin-xxxx&#x27;;import DataSourcePanePlugin from &#x27;@alilc/lowcode-plugin-datasource-pane&#x27;; // ...官方插件...const &#123; setterMap, pluginMap &#125; = AliLowCodeEngineExt;setters.registerSetter(setterMap); // 注册设置器...// 注册插件skeleton.add(&#123; name: &#x27;saveSample&#x27;, area: &#x27;topArea&#x27;, type: &#x27;Widget&#x27;, props: &#123; align: &#x27;right&#x27;, &#125;, content: &lt;Button onClick=&#123;() =&gt; saveSchema()&#125;&gt;保存到本地&lt;/Button&gt;,&#125;);...// 以资产包的方式注册物料库await material.setAssets(await injectAssets(assets));... ● 其中的 assets 是使用&quot;资产包&quot;的形式描述的物料库，格式遵循低代码引擎物料规范，示例： 12345678910111213141516171819202122232425262728293031&#123; &quot;packages&quot;: [ &#123; &quot;package&quot;: &quot;moment&quot;, &quot;version&quot;: &quot;2.24.0&quot;, &quot;urls&quot;: [ &quot;https://g.alicdn.com/mylib/moment/2.24.0/min/moment.min.js&quot; ], &quot;library&quot;: &quot;moment&quot; &#125;, ... ], &quot;components&quot;: [ &#123; &quot;exportName&quot;: &quot;AlilcLowcodeMaterialsMeta&quot;, &quot;npm&quot;: &#123; &quot;package&quot;: &quot;@alilc/lowcode-materials&quot; &#125;, &quot;url&quot;: &quot;https://alifd.alicdn.com/npm/@alilc/lowcode-materials@1.0.2/build/lowcode/meta.js&quot;, &quot;urls&quot;: &#123; &quot;default&quot;: &quot;https://alifd.alicdn.com/npm/@alilc/lowcode-materials@1.0.2/build/lowcode/meta.js&quot;, &quot;design&quot;: &quot;https://alifd.alicdn.com/npm/@alilc/lowcode-materials@1.0.2/build/lowcode/meta.design.js&quot; &#125; &#125;, ... ], &quot;sort&quot;: &#123; &quot;groupList&quot;: [] &#125;, ...&#125; ● 最终通过@alilc&#x2F;lowcode-engine 提供的 init()函数完成渲染，基本语法如下。 123456import &#123; init &#125; from &#x27;@alilc/lowcode-engine&#x27;;init(document.getElementById(&#x27;lce-container&#x27;), &#123; ...options,&#125;, preference); 预览页面○ 预览页面将&quot;schema+物料库描述&quot;渲染成页面。其中物料库描述就是&quot;资产包&quot;中的“packages”内容，schema 包含了组件树结构及相关配置信息，内容格式遵循低代码引擎搭建协议规范，示例： 1234567891011121314151617181920212223242526272829303132333435&#123; &quot;version&quot;: &quot;1.0.0&quot;, &quot;componentsMap&quot;: [ &#123; &quot;package&quot;: &quot;@alifd/pro-layout&quot;, &quot;version&quot;: &quot;1.0.1-beta.6&quot;, &quot;exportName&quot;: &quot;Col&quot;, &quot;main&quot;: &quot;lib/index.js&quot;, &quot;destructuring&quot;: true, &quot;subName&quot;: &quot;&quot;, &quot;componentName&quot;: &quot;NextCol&quot; &#125;, ... ], &quot;componentsTree&quot;: [ &#123; &quot;componentName&quot;: &quot;Page&quot;, &quot;id&quot;: &quot;node_dockcviv8fo1&quot;, &quot;props&quot;: &#123; &quot;ref&quot;: &quot;outerView&quot;, &quot;style&quot;: &#123; &quot;height&quot;: &quot;100%&quot; &#125; &#125;, &quot;fileName&quot;: &quot;/&quot;, ... &quot;children&quot;: [ &#123; &quot;componentName&quot;: &quot;NextPage&quot;, &quot;id&quot;: &quot;node_ockzs2vw431&quot;, &quot;props&quot;: &#123; ... &#125;, &quot;children&quot;: ... &#125; ] &#125; ], &quot;i18n&quot;: &#123;&#125;&#125; ○ 最终是通过@alilc&#x2F;lowcode-react-renderer 完成渲染，基本语法如下。 123456789import ReactRenderer from &#x27;@alilc/lowcode-react-renderer&#x27;;import ReactDOM from &#x27;react-dom&#x27;;ReactDOM.render(( &lt;ReactRenderer schema=&#123;schema&#125; components=&#123;components&#125; /&gt;), document.getElementById(&#x27;root&#x27;)); 关于设计器的定制实践▲ API 文档▲ starter 项目，见白皮书中“定制插件”、“定制设置器”“定制物料”章节。"},{"title":"TypeScript使用小贴士","date":"2022-04-25T12:49:46.000Z","path":"handbook/TypeScript使用小贴士.html","tags":[{"name":"TypeScript","slug":"TypeScript","permalink":"https://congzhou09.github.io/tags/TypeScript/"}],"text":"环境配置相关■ 在还未手动安装 TypeScript 的情况下，操作系统或 IDE 很可能已经自带了 TypeScript。此时在手动安装了 TypeScript 之后如果不做相应的配置，系统命令行及 IDE 可能依旧使用原有的 TypeScript。 系统命令行的配置▲Windows 系统默认在“C:\\Program Files (x86)\\Microsoft SDKs\\TypeScript\\1.0”目录下安装了 Typescript，且将此路径配置到了系统 path。导致问题：（1）即使 npm -g 全局安装了最新 Typescript，运行“tsc --version”返回的仍然是老旧版本号。（2）tsc 命令误报：&quot;error TS1005: &#39;;&#39; expected&quot;▲ 解决办法是将上述目录文件和系统 path 里配置的路径都删掉。 IDE 的配置● 在任何一个&quot;*.ts&quot;文件中查看与跳转到某个原生 JS 对象成员函数定义所在的文件，如 Array 的 find()函数。默认跳转到的类型定义文件位于 VSCode 的安装目录下。(MacOS 环境是&quot;&#x2F;Applications&#x2F;Visual Studio Code.app&#x2F;Contents&#x2F;Resources&#x2F;app&#x2F;extensions&#x2F;node_modules&#x2F;typescript&#x2F;lib&#x2F;lib.es2015.core.d.ts&quot;) ● 因为通常我们在各项目范围内安装与使用特定版本的 TypeScript，所以需要指定上述 TypeScript 目录到当前项目的 node_modules 文件夹。通过为 VSCode 添加如下配置实现，保存 Reload 下窗口再次查看跳转函数定义所在文件跳转的就是当前项目的 node_modules 文件夹了，且在 VSCode 打开 ts 文件窗口的右下方状态栏可以看到当前 TypeScript 的版本号。 1&quot;typescript.tsdk&quot;: &quot;node_modules/typescript/lib&quot;, 项目配置相关Node 项目○ tsconfig.json 内容样例。 1234567891011121314&#123; &quot;compilerOptions&quot;: &#123; &quot;target&quot;: &quot;es5&quot;, /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */ &quot;module&quot;: &quot;commonjs&quot;, /* Specify what module code is generated. */ &quot;rootDir&quot;: &quot;./src&quot;, /* Specify the root folder within your source files. */ &quot;declaration&quot;: true, /* Generate .d.ts files from TypeScript and JavaScript files in your project. */ &quot;sourceMap&quot;: true, /* Create source map files for emitted JavaScript files. */ &quot;outDir&quot;: &quot;./lib&quot;, /* Specify an output folder for all emitted files. */ &quot;esModuleInterop&quot;: true, /* Emit additional JavaScript to ease support for importing CommonJS modules. This enables `allowSyntheticDefaultImports` for type compatibility. */ &quot;forceConsistentCasingInFileNames&quot;: true, /* Ensure that casing is correct in imports. */ &quot;strict&quot;: true, /* Enable all strict type-checking options. */ &quot;skipLibCheck&quot;: true /* Skip type checking all .d.ts files. */ &#125;&#125; ○ 安装@types&#x2F;node 以支持 Node 的 ts 类型定义。 Web 项目○ tsconfig.json 内容样例。 123456789101112&#123; &quot;compilerOptions&quot;: &#123; &quot;target&quot;: &quot;es5&quot;, /* Set the JavaScript language version for emitted JavaScript and include compatible library declarations. */ &quot;module&quot;: &quot;commonjs&quot;, /* Specify what module code is generated. */ &quot;lib&quot;: [&quot;dom&quot;, &quot;esnext&quot;] /* Specify library files to be included in the compilation. */, &quot;jsx&quot;: &quot;react&quot; /* Specify JSX code generation: &#x27;preserve&#x27;, &#x27;react-native&#x27;, &#x27;react&#x27;, &#x27;react-jsx&#x27; or &#x27;react-jsxdev&#x27;. */, &quot;declaration&quot;: true, /* Generate .d.ts files from TypeScript and JavaScript files in your project. */ &quot;strict&quot;: true, /* Enable all strict type-checking options. */ &quot;forceConsistentCasingInFileNames&quot;: true, /* Ensure that casing is correct in imports. */ &quot;skipLibCheck&quot;: true /* Skip type checking all .d.ts files. */ &#125;&#125; ○ react 项目安装@types&#x2F;react 和@types&#x2F;react-dom。○ ts 书写格式参考。○ react 各场景的 ts 书写格式参考（react-typescript-cheatsheet） webpack 项目的配置◻︎ 支持 ts 语法的两种方式。方式一：通过&quot;ts-loader&quot;实现对 ts 文件的类型检查与编译。方式二：&quot;babel-loader&quot;通过配置“@babel&#x2F;preset-typescript”presets 也可以解析与编译 ts 语法。 ◻︎ 两种方式的区别是：第二种方式，由于 babel 仅做解析和编译，不会做 ts 类型检查，进而不会在 webpack 命令行输出中报出类型检查错误。官方详细说明。 第三方库的引入▲ 第三方库的 ts 类型定义通常在名为“@types&#x2F;库名”的 npm 包中，可通过命令&quot;npm view @types&#x2F;库名&quot;查看该 npm 包是否存在。这种方式无需额外配置，TypeScript 会自动读取“node_modules&#x2F;@types”目录下的声明文件。 ▲ 当没有对应第三方库的类型声明 npm 包的时候，需要手动书写*.d.ts 文件。然后有两种配置方式。（1）在 tsconfig.json 配置中的 &quot;include&quot; 字段数组中增加文件完整路径。注意这里添加的路径不能是&quot;node_modules&quot;目录下的，会被 TypeScript 忽略。（2）通过三斜线语句引入类型定义文件，示例如下。这种方式的配置与上一种不同，它仅对当前文件有效，当别的文件缺少这个声明时也需要书写引入语句。 12345678910// 类型定义文件 &quot;./types/one.d.ts&quot;declare module &#x27;Module_Name&#x27; &#123; export default (...)=&gt;any; export class ...;&#125;// 引入类型定义文件/// &lt;reference path=&quot;./types/one.d.ts&quot; /&gt;"},{"title":"特定项目下自动切换node到指定版本","date":"2022-04-12T13:20:42.000Z","path":"practice/特定项目下自动切换node到指定版本.html","tags":[{"name":"Node.js","slug":"Node-js","permalink":"https://congzhou09.github.io/tags/Node-js/"}],"text":"场景○ 使用 nvm 管理本地多版本 Node.js，默认使用版本 14。某个项目当前仅支持版本 10，每次执行&quot;nvm use&quot;手动切换太麻烦了。○ 想到&quot;.npmrc&quot;文件可以指定仅对项目生效的配置，对应在网上找&quot;.nvmrc&quot;找到了解决办法。 操作步骤(MacOS环境)以场景需求为例的操作步骤如下： ■ 命令行进入需指定 node 版本的项目下，先使用&quot;nvm use v10.17.0&quot;切换到目标版本，再执行&quot;node -v &gt; .nvmrc&quot;将 node 版本号保存到&quot;.nvmrc&quot;文件，如果只限制第一级版本号可将文件内容改为&quot;v10&quot;。■ 添加命令行初始化脚本。如果使用的是 zsh 命令行，通过&quot;vim $HOME&#x2F;.zshrc&quot;追加如下脚本内容到文件。其他类型命令行脚本参考nvm 的 README.md 中说明。 12345678910111213141516171819202122232425262728293031323334# nvm check when zsh initializingautoload -U add-zsh-hookload-nvmrc() &#123; local node_version=&quot;$(nvm version)&quot; local nvmrc_path=&quot;$(nvm_find_nvmrc)&quot; if [ -n &quot;$nvmrc_path&quot; ]; then local nvmrc_node_version=$(nvm version &quot;$(cat &quot;$&#123;nvmrc_path&#125;&quot;)&quot;) if [ &quot;$nvmrc_node_version&quot; = &quot;N/A&quot; ]; then nvm install elif [ &quot;$nvmrc_node_version&quot; != &quot;$node_version&quot; ]; then nvm use fi elif [ &quot;$node_version&quot; != &quot;$(nvm version default)&quot; ]; then echo &quot;Reverting to nvm default version&quot; nvm use default fi&#125;add-zsh-hook chpwd load-nvmrcload-nvmrc# nvm check when running cd commandcd-nvm() &#123; builtin cd &quot;$@&quot; if [[ -f .nvmrc ]]; then load-nvmrc fi&#125;alias cd=&#x27;cd-nvm&#x27;# changes take effectsource ~/.bash_profile ■ 以上脚本实现了&quot;从项目目录直接打开命令行&quot;和&quot;通过 cd 命令进入项目目录&quot;两种情况下自动切换 node 到 nvm 默认版本或&quot;.nvmrc&quot;文件指定版本。 参考文献▲How to write a .nvmrc file which automatically change node version▲Automatically switch to correct version of Node based on project▲nvm README.md"},{"title":"浏览器新开Tab读不到sessionStorage的问题","date":"2021-12-24T12:32:56.000Z","path":"practice/浏览器新开Tab读不到sessionStorage的问题.html","tags":[{"name":"HTML规范","slug":"HTML规范","permalink":"https://congzhou09.github.io/tags/HTML%E8%A7%84%E8%8C%83/"}],"text":"背景▲ 上半年解决&quot;url 传参方式, 因参数过长导致 url 过长&quot;问题时想到使用 sessionStorage 缓存参数，今天突然发现这个办法在新项目里不管用：虽然新开的 Tab 与源页面在相同的域，但源页面设置的 sessionStorage 在新开 Tab 中读取不到。 ▲ 网上查找如何在 Tab 之间共享 sessionStorage 的方案，排名第一的搜索结果居然是通过 localStorage 做中转。 分析与解决■ 印象里 sessionStorage 与 localStorage 的区别只有生命周期不同，查看MDN 中对 sessionStorage 的说明才发现自己认知的漏洞，从以下截图描述（特别是红框位置）可见 sessionStorage 还有以下特性：（1）浏览器打开新 Tab 的时候会为其单独创建一份新的 sessionStorage。（2）相同域下不同 Tab 的 sessionStorage 是相互独立的。 ■ 但为何自己当时可以在新开的 Tab 读取到源页面的 sessionStorage 呢，从截图中蓝框位置描述看到了线索：当前页面的 sessionStorage 是有办法拷贝到新开 Tab 中的。 ■ 查找拷贝 sessionStorage 的方法看到了设置 rel&#x3D;&quot;opener&quot;的方法，将其中提问者给出的demo修改如下就可以在新开 Tab 读到 sessionStorage 啦。 12345678910function openPageInNewTab() &#123; const link = document.createElement(&#x27;a&#x27;); link.target = &#x27;_blank&#x27;; link.href = &#x27;/&#x27;; link.setAttribute(&#x27;visibility&#x27;, &#x27;hidden&#x27;); link.setAttribute(&#x27;rel&#x27;, &#x27;opener&#x27;); // 增加此行 document.body.appendChild(link); link.click(); link.remove();&#125; 额外信息○ Chrome 从版本 89 开始，打开新 Tab 时不再默认将当前 sessionStorage 拷贝到新开 Tab，详见：Chrome Feature: Stop cloning sessionStorage for windows opened with noopener ○ 查了之前项目代码，那时候是使用 window.open()函数实现的新开 Tab。经测试依然有效，也就是当前通过 window.open()函数打开新 Tab 时，仍然会将当前 sessionStorage 拷贝到新开 Tab。 ○ 携带 rel&#x3D;&quot;opener&quot;要注意使用场景，防止安全类问题。"},{"title":"Ant Design的Upload组件定制","date":"2021-11-15T06:37:29.000Z","path":"handbook/Ant-Design的Upload组件定制.html","tags":[{"name":"antd","slug":"antd","permalink":"https://congzhou09.github.io/tags/antd/"}],"text":"背景■Ant Design 官方文档中对于限制数量、上传接口请求与响应、下载等功能的自定义实现方法描述得不详细，在此做下记录。■ 实现功能如下：（1）上传接口报错时弹出错误信息(由于后端接口统一将错误信息与错误码封装在 http 码为 200 的 body 中，所以需要上传接口请求与响应的自定义)；（2）限制上传文件数量 10 个；（3）选择文件对话框中可选多个文件；（4）限制每个文件大小不超过 20M；（5）上传成功后展示的文件列表项可点击下载；（6）onChange 传出值格式:[{fileName: string, fileUrl: string}] 代码实例□ 代码实例如下，经调试发现无论 onSuccess 传入怎样的参数格式，下载功能都需要自己实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127import React, &#123; useCallback, useEffect, useRef, useState &#125; from &#x27;react&#x27;;import &#123; Upload, message, Button &#125; from &#x27;antd&#x27;;import axios from &#x27;axios&#x27;;const FileUpload = (&#123; maxFileSize = 20, maxFileCount = 10, onChange,&#125;) =&gt; &#123; // 文件大小限制 const maxFileSizeRef = useRef(); useEffect(() =&gt; &#123; // M转byte maxFileSizeRef.current = maxFileSize * 1024 * 1024; &#125;, [maxFileSize]); // 文件数量记录 const [fileListCount, setFileListCount] = useState(0); const [isDisabled, setIsDisabled] = useState(false); useEffect(() =&gt; &#123; if (fileListCount &gt;= maxFileCount) &#123; setIsDisabled(true); &#125; else &#123; setIsDisabled(false); &#125; &#125;, [fileListCount, maxFileCount]); // &quot;文件uid-下载url&quot;映射记录 const [downloadUrls, setDownloadUrls] = useState(&#123;&#125;); // onChange格式转换 const customOnChange = useCallback( (&#123; fileList &#125;) =&gt; &#123; const outputValue = []; fileList.forEach((one) =&gt; &#123; if (one.status === &#x27;done&#x27;) &#123; outputValue.push(&#123; fileName: one.name, fileUrl: downloadUrls[one.uid], &#125;); &#125; &#125;); // console.log(&#x27;onChange: &#x27;, outputValue); onChange &amp;&amp; onChange(outputValue); &#125;, [onChange, downloadUrls] ); return ( &lt;Upload onChange=&#123;customOnChange&#125; showUploadList=&#123;&#123; showDownloadIcon: true, &#125;&#125; beforeUpload=&#123;(file, fileList) =&gt; &#123; const newCount = fileListCount + fileList.length; if (file.size &gt; maxFileSizeRef.current) &#123; message.warn(`文件&#x27;$&#123;file.name&#125;&#x27;超过文件大小限制: $&#123;maxFileSize&#125;M`); return Upload.LIST_IGNORE; &#125; else if (newCount &gt; maxFileCount) &#123; message.warn(`超过最大上传数量: $&#123;maxFileCount&#125;`); return Upload.LIST_IGNORE; &#125; else if (newCount === maxFileCount) &#123; setIsDisabled(true); &#125; &#125;&#125; customRequest=&#123;(allData) =&gt; &#123; setFileListCount(fileListCount + 1); const &#123; onProgress, onSuccess, onError &#125; = allData; const reqFormData = new FormData(); // 通过组件的data属性传入的额外请求参数，根据接口要求定制 Object.keys(allData.data).forEach((oneKey) =&gt; &#123; reqFormData.append(oneKey, allData.data[oneKey]); &#125;); reqFormData.append(&#x27;file&#x27;, allData.file); axios(&#123; method: &#x27;post&#x27;, url: &#x27;/common/file/upload&#x27;, data: reqFormData, onUploadProgress: (progress) =&gt; &#123; // 上传进度条 const progNum = progress.loaded / progress.total; onProgress(&#123; percent: progNum &#125;); &#125;, &#125;) .then((resData) =&gt; &#123; setDownloadUrls((prevState) =&gt; &#123; return &#123; ...prevState, [allData.file.uid]: resData.url, &#125;; &#125;); onSuccess(&#123; url: resData.url &#125;); &#125;) .catch((error) =&gt; &#123; onError(error); &#125;); &#125;&#125; multiple=&#123;true&#125; data=&#123;(file) =&gt; &#123; return &#123; typeId: 2, fileName: file.name, &#125;; &#125;&#125; onRemove=&#123;() =&gt; &#123; setFileListCount(fileListCount - 1); &#125;&#125; openFileDialogOnClick=&#123;!isDisabled&#125; onDownload=&#123;(file) =&gt; &#123; window.open(downloadUrls[file.uid]); &#125;&#125; &gt; &#123;isDisabled ? ( &lt;span style=&#123;&#123; color: &#x27;#ff7700&#x27; &#125;&#125;&gt; 已达到最大上传数量: &#123;maxFileCount&#125;个 &lt;/span&gt; ) : ( &lt;Button&gt;上传&lt;/Button&gt;; )&#125; &lt;/Upload&gt; );&#125;;... ... 参考文献●rc-upload文档●前端通过 axios 和 FormData 实现文件上传功能遇到的坑"},{"title":"git合并分支两种方式:rebase与merge","date":"2021-02-16T03:55:15.000Z","path":"practice/git合并分支两种方式-rebase与merge.html","tags":[{"name":"git","slug":"git","permalink":"https://congzhou09.github.io/tags/git/"}],"text":"场景○ 当前 git 分支状态如下示意图，本地 dev 分支从 master 分支的 C2 版本切出并经过 2 次提交到达 C4 版本，远程 master 分支经过 1 次提交到达 C5 版本。○ 此时要在本地将 dev 分支合并到 master。 merge 方式♂ 直接使用 merge 命令合并 dev 分支到 master 分支，由于 C2 不是 master 最新版本，将把 C2 到 C4 的修改合并到 master 最新版本 C5 并自动生成一条 commit。♂ 两个分支上的 commit 记录在 log 中的顺序与 pull 与 merge 操作先后有关。先 pull 再 merge 是先合并远程修改再合并本地修改，先 merge 再 pull 是先合并本地修改再合并远程修改，从思路上都说得通。♂ 本地切到 master 分支后，先 pull master 分支，再 merge dev 分支的 log 结果如下图，其中的 parent1 是 C5。 ♂ 本地切到 master 分支后，先 merge dev 分支，再 pull master 分支的 log 结果如下图，远程 master 上的新提交 C5 被显示为被合并分支，其中的 parent1 是 C4。 ♂ merge 方式自动生成的那条 commit 记录了合并结果分别与两个分支最新版本的差异。♂ 使用 merge 方式合并分支，merge 与 pull 顺序只影响两分支 commit 记录的顺序，不影响合并完的代码结果。 rebase 方式♀ rebase 思路是将 dev 分支上的原先基于的 C2 更新为基于 C5，将对原基准版本后的每个 commit(C3 和 C4)执行更新基准过程，每个 commit 可能都要解决一次冲突，rebase 完成之后分支状态示意图如下，此时再将 dev 分支合并到 master 由于基准版本就是 master 最新版本就只是简单的同步了。 ♀ “git rebase master”和“git rebase --continue”命令对应在 TortoiseGit 的操作界面如下，其中 Branch 是执行 rebase 的分支，Upstream 是 base 所在分支。 ♀ rebase 的 log 结果如下图，经过 rebase 之后，C3 与 C4 的 commit log 记录的修改内容将变成基于 C5 的修改，相应 SHA 码也会更改。 rebase 方式与 merge 方式区别□ 执行 rebase 期间可能需要解决多次冲突。□ rebase 的 log 结果中没有单独生成一条记录合并的 commit，log graph 是线性没有分叉的。□ rebase 的 log 结果中 commit 记录固定按照合并到 master 分支的先后顺序排列。 参考文献● 你真的懂 git rebase 吗-简书● git 官方 Reference 手册"},{"title":"本地自签名HTTPS环境搭建","date":"2021-02-13T02:23:50.000Z","path":"practice/本地自签名HTTPS环境搭建.html","tags":[{"name":"HTTPS","slug":"HTTPS","permalink":"https://congzhou09.github.io/tags/HTTPS/"}],"text":"前置知道○OpenSSL是为实现SSL和TLS提供支持的工具包；○HTTPS证书只能绑定域名而不能绑定某个IP；○1.1.1版本OpenSSL命令用法的官方文档；○操作环境： 123Windows 10openssl 1.1.1(通过&quot;openssl version&quot;命令查看)；nginx 1.17.1 操作步骤添加本地域名●定义本地域名以&quot;blog.congzhou.com&quot;为例，将域名解析添加到“Windows\\System32\\drivers\\etc”下的hosts文件，hosts文件中的域名不支持通配符； 1127.0.0.1 blog.congzhou.com 生成HTTPS所需私钥与证书●执行如下命令创建本地模拟CA的私钥与CA根证书，分别生成&quot;RootCA.key&quot;和&quot;RootCA.pem&quot;两个文件，其中用到的国家编码在这里 12345678910111213openssl req -x509 -nodes -new -days 365 -newkey rsa:2048 -keyout RootCA.key -out RootCA.pem -subj &quot;/C=CN/CN=YCZ-Root-CA&quot;/****** * 命令解读 * openssl-req主要用于创建与处理证书请求(CSR, certificate signing request)，也用于创建自签名方式的根证书 * 参数解读 * -x509: 输出证书而不是CSR * -nodes: 生成的私钥不做加密 * -new: 当没有-key参数时将使用-newkey和-pkeyopt参数生成私钥 * -days: 证书有效天数，默认30天 * -newkey rsa:2048 : 生成2048bit长度的rsa格式私钥 * -subj: 设置证书涉及到的字段(称为证书的subject)值，/C是CountryName编码，/CN是CommonName即CA机构名称****/ ●执行如下命令生成上一步pem证书的对应crt格式的证书文件&quot;RootCA.crt&quot;，Windows中crt扩展名的证书文件右键菜单才有&quot;安装&quot;选项； 123456789openssl x509 -inform pem -in RootCA.pem -out RootCA.crt/****** * 命令解读 * openssl-x509用途较多，可用于转换证书格式和为CSR签名 * 参数解读 * -inform 输入证书的格式，取值为pem或der，默认值pem，pem是base64编码的文本格式，der是DER(Distinguished Encoding Rules)编码的二进制格式 * -outform 输出证书的格式，默认与输入整数的格式一致****/ ●执行如下命令创建本地域名网站私钥与网站证书req，分别生成&quot;congzhou.key&quot;和&quot;congzhou.csr&quot;两个文件，这里将证书签到域名&quot;*.congzhou.com&quot;方便以后也可以给其他二级子域名使用； 12345678910openssl req -new -nodes -newkey rsa:2048 -keyout congzhou.key -out congzhou.csr -subj &quot;/C=CN/ST=Beijing/L=Beijing/O=Example Company Limited/CN=*.congzhou.com&quot;/****** * 参数解读 * -new: 生成一个新的CSR * -subj参数使用到的subject含义：/ST是StateOrProvinceName，/L是Locality，/O是Organization。/CN用于网站时就是网站的域名，支持&quot;*.example.com&quot;形式的通配符，但只能填写一条 * * * Subject Alternative Name（简称SAN，也称&quot;使用者备用名称&quot;）用于弥补CN数量的限制，并会在将来逐渐替代Common Name，而且Chrome版本58及以上已经将SAN作为证书校验项，缺少SAN报“Subject Alternative Name Missing”错误****/ ●创建包含SAN等证书扩展信息的congzhou.ext文件，文件内容如下； 12345678authorityKeyIdentifier=keyid,issuerbasicConstraints=CA:FALSEkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEnciphermentsubjectAltName = @alt_names[alt_names]DNS.1 = *.congzhou.comDNS.2 = localhost ●使用CA证书&quot;RootCA.pem&quot;文件及证书扩展信息&quot;congzhou.ext&quot;文件给网站证书签名生成证书到&quot;congzhou.crt&quot;文件； 12345678910openssl x509 -req -days 1024 -in congzhou.csr -CA RootCA.pem -CAkey RootCA.key -CAcreateserial -extfile congzhou.ext -out congzhou.crt/****** * 命令解读 * openssl-x509用途较多，此处用于为CSR签名 * 参数解读 * -req 指明此处x509命令用于为CSR签名 * -CAserial 无须通过-set_serial手动指定serial number * -extfile 指定CA扩展信息所在文件****/ 添加对CA证书的信任♂方式1：在&quot;RootCA.crt&quot;文件的右键菜单选&quot;安装证书&quot;，&quot;证书存储&quot;选择&quot;受信任的根证书颁发机构&quot;；♂方式2：运行&quot;certmgr.msc&quot;，在左侧“受信任的根证书颁发机构-&gt;证书”上右键菜单“所有任务-&gt;导入”选择RootCA.crt文件安装；♂安装成功后在&quot;certmgr.msc&quot;证书管理程序中可以看到刚刚创建的本地模拟CA信息； 本地网站使用证书♀使用证书，以nginx为例，server段添加如下内容： 123456server_name blog.congzhou.com;listen 443 ssl; # ssl指定使用httpsssl_certificate &quot;/certificate_path/congzhou.crt&quot;; # 网站证书ssl_certificate_key &quot;/certificate_path/congzhou.key&quot;; # 网站证书对应私钥... ... 结果验证▲验证1：访问本地https网站，浏览器校验通过； ▲验证2：浏览器中点开证书详情，可以看到颁发者、使用者信息，其中的SAN在&quot;使用者可选名称&quot;字段； 参考文献●How to Create Trusted Self-Signed SSL Certificates and Local Domains for Testing●How to create an HTTPS certificate for localhost domains●Solve Errors: &quot;Subject Alternative Name Missing&quot; “NET::ERR_CERT_COMMON_NAME_INVALID” ●What is the SSL Certificate Common Name"},{"title":"Fiddler抓取HTTPS包与手机包","date":"2021-01-11T09:50:23.000Z","path":"practice/Fiddler抓取HTTPS包与手机包.html","tags":[{"name":"Fiddler","slug":"Fiddler","permalink":"https://congzhou09.github.io/tags/Fiddler/"},{"name":"HTTPS","slug":"HTTPS","permalink":"https://congzhou09.github.io/tags/HTTPS/"}],"text":"基本原理◇Fiddler抓包基于注册成HTTP(S)协议数据的收发代理；◇只要支持配置http代理的环境，就可以使用Fiddler抓包，据此可以抓取经过手机的HTTP(S)包；◇HTTPS比HTTP多了非对称加密机制，包含一对互相解密的公钥和私钥，发起HTTPS过程如下图，抓取HTTPS内容除了作为代理拿到客户端与服务器之间传输的数据还需要能对数据解密； ◇Fiddler抓取HTTPS包借鉴中间人攻击(Man-in-the-MiddleAttack，简称MITM攻击)原理，代理服务器与客户端之间使用中间人的公钥私钥，与服务器之间使用服务器的公钥； ◇服务器公钥包含在服务器提供的SSL证书中，除了公钥还包含:证书颁发机构(即CA)、有效期、公钥、证书持有者、CA指纹和指纹算法等。真实CA的数字证书(即根证书)由于拿不到私钥是无法伪造的，中间人需要伪造一个CA，并能随时颁发要访问任何网站的SSL证书，同时需要在系统根证书管理中添加对伪造CA根证书的信任否则浏览器会跳出安全提示； 抓取HTTPS包的方法◇伪造一个CA并能随时颁发要访问任何服务器的SSL证书的机制Fiddler已经提供，打开Fiddler设置：Tools-&gt;Options-&gt;HTTPS-&gt;Capture HTTPS CONNECTs-&gt;Decrypt HTTPS traffic，根据提示生成名为&quot;DO_NOT_TRUST_FiddlerRoot&quot;的根证书并添加到系统信任根证书列表； ◇windows下运行&quot;certmgr.msc&quot;可以查看系统当前信任的根证书列表； ◇打开Fiddler抓包开关，访问HTTPS目标网址，点开地址栏锁图标查看证书信息，可以看到其中的证书颁发组织都变成了&quot;DO_NOT_TRUST&quot;，Fiddler中此时也可查看HTTPS包内容； 抓取手机包(包括HTTPS)的方法■如已经按上一段步骤生成根证书则直接进入下一步；■设置Fiddler作为局域网代理服务器：Tools-&gt;Options-&gt;Connections ■手机连入与运行Fiddler的PC端相同的局域网，配置手机的局域网代理为PC局域网IP及Fiddler设置的端口；■手机端安装信任证书（1）手机访问网址http:&#x2F;&#x2F;PC局域网IP:fiddler设置的端口，页面内下载&quot;FiddlerRoot Certificate&quot;安装并设置系统信任；（2）iOS版本高于10.3需额外操作手机：设置-&gt;通用-&gt;关于本机-&gt;证书信任设置；"},{"title":"浏览器内核列举","date":"2020-12-25T06:48:39.000Z","path":"knowledge/浏览器内核列举.html","tags":[{"name":"浏览器","slug":"浏览器","permalink":"https://congzhou09.github.io/tags/%E6%B5%8F%E8%A7%88%E5%99%A8/"}],"text":"简介● 浏览器内核包含两种引擎：排版引擎、JS 引擎。由于 JS 引擎越来越独立，浏览器内核倾向于单指排版引擎。● 排版引擎也称&quot;渲染引擎（Rendering Engine）&quot;，负责渲染网页内容的总体控制。● 所有网页浏览器、电子邮件客户端以及其它需要编辑显示 HTML 内容的应用程序都需要排版引擎。 排版引擎● Trident（&#x2F;`traidnt&#x2F; 又称为 MSHTML），是 Windows 操作系统曾经搭载的 IE 浏览器所使用的排版引擎，它的第一个版本诞生于 1997 年 10 月的 Internet Explorer 第四版，2015 年微软推出的 Edge 浏览器使用的是 EdgeHTML 排版引擎，2019 年改用谷歌的 Blink。● Gecko（&#x2F;`gekəʊ&#x2F;）是以 C++编写的开源排版引擎，能在 Windows、Linux 和 Mac 等主要操作系统上跨平台运行，由网景通讯公司开发，现在由 Mozilla 基金会维护，被 Mozilla 系列产品(如 Firefox 浏览器)所使用。● KHTML 是自由软件项目 KDE(K Desktop Environment，基于 Qt 开发)中实现的排版引擎，最初用于 Linux 开源操作系统，苹果将 KHTML 项目 fork 到自己的 WebKit 项目并在其基础上开发并命名为 WebCore，用于 Safari 浏览器，后来 WebKit 项目也开源了，Chrome 最初的排版引擎也使用 WebCore。● Presto（&#x2F;ˈprestəʊ&#x2F;）是由 Opera Software 开发的浏览器排版引擎，应用于 Opera 浏览器，Opera 后来放弃了自有排版引擎跟随 Chromium。● Blink，Chrome 后来从 WebCore fork 出分支并命名为 Blink。 JS 引擎◇ JScript，老版本 IE 使用，2011 年发布的 IE9 以及之后 Edge 浏览器使用 Chakra，2019 年改用谷歌的 V8。◇ Monkey 系列，Firefox 使用。◇ SquirrelFish 系列，Safari 使用。◇ Carakan，Opera 使用。◇ V8，Chrome 从第一个版本起就使用的 JS 引擎，以 C++编写的谷歌开源项目。 浏览器内核（也称为浏览器引擎，包含了排版引擎和 JS 引擎）● WebKit（1）WebKit 是苹果的浏览器内核，始于 2001 年，于 2005 年开源，它所包含的 WebCore 排版引擎和 JavaScriptCore JS 引擎分别是从 KDE 的 KHTML 和 KJS 衍生而来。（2）2008 年 WebKit 团队重写了 JS 引擎命名为 SquirrelFish，并在 Chrome 发布的两个星期后发布。（3）由于宽松的协议、轻量级的设计和便捷的应用程序内嵌 API，WebKit 变得流行，除了 Google Chrome&#x2F;Chromium 和 Safari，它在移动终端（ Symbian S60，Android，iOS，Kindle）到 Toolkit 集成(GTK+, Qt4) 都有不错的收获，被统称为 WebKit。● Blink（1）&quot;Blink&quot;有时也作为包含 Blink 排版引擎和 V8 JS 引擎的浏览器内核的名字。（2）Chrome 浏览器最初使用 WebKit 的排版引擎（即 WebCore）是 Android 团队的建议，由于谷歌与苹果的竞争关系使开源的合作无法维系，于是诞生了 Blink。（3）Google 自 2013 年起在 Google Chrome&#x2F;Chromium 中使用 Blink，iOS 中的 Chrome 仍然使用的 WebCore。"},{"title":"网页渲染过程","date":"2020-12-16T02:03:54.000Z","path":"knowledge/网页渲染过程.html","tags":[{"name":"浏览器","slug":"浏览器","permalink":"https://congzhou09.github.io/tags/%E6%B5%8F%E8%A7%88%E5%99%A8/"}],"text":"总览● 从 Web 内容到屏幕像素的大致过程如下图：首先 Render 进程主线程(Render 线程)上的浏览器内核实例将 HTML 及关联的 CSS 信息转换为绘制信息，然后将绘制信息交给 Compositor 线程并由 GPU 进程协助完成到屏幕像素的转换(此过程称为光栅化&lt;rasterize&gt;)； ● Render 线程和 Compositor 线程都位于浏览器的 Render 进程中。浏览器中进程与线程相关整理在这篇浏览器中的进程与线程；● Compositor 线程的&quot;合成&quot;名字源自现代浏览器实现光栅化使用的合成技术，Render 线程会将页面拆分为多个 layer ，各个 layer 将分别光栅化再合成为最终结果，这样做的优点是当页面滚动或实现动画时某些图层的上次光栅化结果可以直接使用；● 渲染涉及初次渲染与更新渲染两种情况，更新渲染只有在必要的时候才进行（如 JS 操作 DOM&#x2F;CSS、用户输入、异步加载、页面滚动与缩放、动画），更新渲染时会尽可能重用上一次渲染的结果； 初次渲染过程（以 Chrome 为例）○ 构建 DOM树，Render 线程解析 HTML 生成 DOM 树，期间遇到的图片、CSS、JS 等外部资源文件会通知 Browser 进程从网络或缓存获取过来，当解析到 HTML 中的 JS 或者非延迟的 JS 文件加载完成时就暂停 DOM 解析先去执行完 JS 再返回；○ 构建 CSSOM树，Render 线程再一次解析 HTML 收集各个来源(style 标签、css 文件、浏览器默认规则)的 style 规则构建成方便查找的 CSSOM 树结构；○ 构建 render 树，render 树来自 DOM 树与 CSSOM 树信息的合并，Render 线程遍历 DOM 树同时针对每个元素查找 CSSOM 树确定其最终 style(ComputedStyle)及当前元素是否渲染，构建出的 render 树中不包含 DOM 树中的不可见元素（如 script、meta），也不会包含 display 属性值为 none 的节点，但会包含伪元素，render 树的节点称为 RenderObject； ○ layout，Render 线程遍历 render 树构建 layout 树，layout 树的节点是 LayoutObject，LayoutObject 节点包含了对应 render 树节点的引用，以及经计算得出的该元素的 layout 信息（主要是 xy 坐标、所占页面空间大小等几何信息）；○ layer，Render 线程遍历 layout 树，将页面拆分成多个 layer 子树；○ prepaint，Render 线程创建 property 树集合记录各 layer 子树的图形图像变换属性（transform、clip、effect、scroll），每个 layer 分别进入之后的 paint 阶段； ○ paint，Render 线程遍历 layer 子树创建描述其绘制过程的操作记录(称为 paint records)列表，由于操作记录的顺序会影响到元素重叠区域的前后遮挡关系，绘制过程会大致按照如下阶段创建绘制对象，于是每个元素通常对应多个绘制对象； ○ commit，Render 线程同步地将 layer 绘制对象列表及 property 树集合传输到 Compositor 线程，之后的步骤不再占用 Render 线程；○ tiling，Compositor 线程将 layer 拆分为多个 tile，layer 所占区域可能比较大且距离当前视口较远，tile 按照优先级顺序进入 raster 阶段；○ raster，GPU 进程中的 Raster 线程(Rasterizer Thread)们将各个绘制对象通过 Skia 库转换成 GL 函数的调用序列，GL 函数的调用序列执行后生成存储于 GPU 内存中的由像素颜色值组成的 bitmap；○ draw，Compositor 线程收集当前视口区域内的所有 tile 的 GPU 内存地址和屏幕位置等信息(这些信息称为 draw quads)封装成一个 CompositorFrame 提交给 Browser 进程，除了 Render 进程之外，Browser 进程也同时收集来自 UI 线程、插件进程的 CompositorFrame，将它们一并交给 GPU 进程做聚合之后绘制到屏幕； 更新渲染过程（以 Chrome 中的 input 事件为例）☆ 这里的 input 事件包括针对网页区域的所有点击、输入、滚轮、鼠标移动、鼠标悬停、触摸、缩放等鼠标键盘触摸事件；☆input 事件首先被 Browser 进程捕捉到，Browser 进程判断事件的坐标及所在页面，将事件及坐标信息发送给对应的 Render 进程，事件先被 Compositor 线程处理，Compositor 线程判断事件是否位于事件监听区域，如果在监听区域之外则不经过 Render 线程而由 Compositor 线程直接生成新的 CompositorFrame，否则将事件交给 Render 线程，Render 线程处理事件流及事件监听回调，之后由 Event Loop 触发 Compositor 线程生成新 CompositorFrame 的过程； 要点补充◇ 渲染流程中的每一步结果都是基于上一步结果的，所以当上游内容有变化时，下游步骤都需要重新执行一遍；◇ reflow 与 repaint（1）reflow 指浏览器需要重新计算元素的几何特性，从 layout 阶段重新生成一次 CompositorFrame，引起 reflow 的操作如：改变元素的 display 属性、DOM 树增减元素、改变元素的大小或位置，详细属性如下图； （2）repaint 需要重新绘制元素，从 paint 阶段重新生成一次 CompositorFrame，引起 Repaint 的操作如：改变元素的背景色或 box-shadow； （3）reflow 过程包含 repaint；（4）repaint 会 repaint 变化元素及与其属于同一个 layer 的其他元素，不会 repaint 其他 layer；◇ Compositor 线程里会维护当前帧与下一帧的绘制信息，当前帧(active tree)在 draw 阶段时可以同时进行下一帧(pending tree)的 raster 阶段； 网页渲染详细过程图 Chrome 相关工具◇ 通过 Chrome 的 Layers 工具可以查看页面被分成了哪些 layer，以及每个 layer 的拆分原因和 paint 阶段的绘制对象； ◇ 通过 Chrome 的 Performance 工具可以查看渲染过程中 Render 线程、Raster 工作线程、GPU 进程、Compositor 线程的 timeline 及与浏览器各帧的对应关系； ◇ 目前的拆分 layer 过程及图形图像变换属性在 paint 阶段之前由 Render 线程完成，这从目前的 Performance 里可以看到，官方计划之后将把这部分工作放到 paint 阶段后面； 相关编程技巧◆ 当页面元素变化时，通过避免 reflow 甚至同时避免 repaint 而只通过 Compositor 线程完成更新渲染，可以提高页面的性能，不仅因为总体运算量少，也因为 paint 之后的阶段都不在 Render 线程上进行；◆ 当下主流浏览器（Chrome、Firefox、Safari、Opera）都实现了仅通过 compositing 完成 transform 与 opacity 两种 CSS 属性，极大提高了基于二者所实现页面动画(称为 compositing only animations)的流畅度，操作步骤如下：（1）将动画元素提升到单独一层 layer，实现此目的的专用 CSS 属性&quot;will-change&quot;还在实验阶段，下图各方式可以更兼容地将元素提升为单独的 layer，例如：&quot;transform: translateZ(0)&quot;，这一步是下一步替代 CSS 属性的前提，即使下一步无法替代，layer 的提升也可以减少 reflow 与 repaint 的波及范围； （2）尽可能使用 transform 代替 left、top 等属性以及使用 opacity 属性代替 rgba 颜色值来实现等价的 CSS 动画； 参考文献●life of a pixel●Inside look at modern web browser 系列●Constructing the Object Model●Render-tree Construction, Layout, and Paint●Chromium Source Code README.md●Eliminate content repaints with the new Layers panel in Chrome●High Performance Animations●Stick to Compositor-Only Properties and Manage Layer Count●GPU Accelerated Compositing in Chrome"},{"title":"浏览器中的进程与线程","date":"2020-12-11T09:08:00.000Z","path":"knowledge/浏览器中的进程与线程.html","tags":[{"name":"浏览器","slug":"浏览器","permalink":"https://congzhou09.github.io/tags/%E6%B5%8F%E8%A7%88%E5%99%A8/"}],"text":"浏览器中的进程◆ 现代浏览器都是多进程的，不过目前没有标准规范约定浏览器具体要分为哪些进程或线程，所以各浏览器厂商实现细节会有不同且随着发展在不断调整中，本文以 Chrome 浏览器为例，Chrome 的浏览器内核是 Blink；◆ Chrome 主要包括如下进程：（1）Browser 进程，浏览器主进程，只有一个，负责浏览器基本界面和功能（如地址栏、书签、前进后退按钮）的展示与交互、操作系统特权功能如网络请求和文件访问，以及各子进程的管理；（2）Render 进程，也称为“Renderer”，通常有多个，负责网页内容相关的事务，通常说的“浏览器内核”运行在 Render 进程，默认每个 tab 页对应一个 Render 进程，当满足某些条件如 tab 页超过一定数量或系统资源紧缺时会做合并优化（比如相同网站 tab 共用一个 Render 进程甚至不同网站 tab 共用一个 Render 进程）；（3）Utility 进程，有多个，用于网络、存储、音频播放等通用功能；（4）GPU 进程，只有一个，集中处理 GPU 任务；（5）Plugin 进程，有多个，负责在后台运行浏览器插件； ◆ 通过“Shift+Esc”打开浏览器的“任务管理器”可以看到当前运行的所有浏览器进程；◆ 上述进程都是多线程的，而且所有进程都有两个基础线程：Main 线程和 I&#x2F;O 线程，另外可能有些做特定工作的线程，以及做通用工作的线程池；◆ Browser 进程中的 Main 线程也称为 UI 线程，主要负责 UI 相关，Browser 进程中的 I&#x2F;O 线程处理 IPC（Inter-process communication 进程间通信）与网络请求；◆ Render 进程中的 Main 线程也称为 Render 线程(有时也按照浏览器内核名命名如 Blink 主线程)，同样有 I&#x2F;O 线程处理 IPC；◆ 几乎每个线程都有一个不断从任务队列获取要执行任务的 loop，多个线程可能共享同一个任务队列； Render 进程中的线程◆ Render 线程会创建了一个浏览器内核实例，用于处理接收到的网页内容，它会针对每个网页建立一个 RenderView 实例，每个 RenderView 实例又会被关联到 Browser 进程中的一个 RenderViewHost 实例以便 Browser 进程的统一管理；◆ Browser 进程与 Render 进程及各自主要线程的关系如下图，其中 Render 进程的线程在第一张图中不准确，以第二张图为准； ◆ 浏览器内核实例包含如下功能：（1）排版引擎，负责将从网络获取到的网页内容数据可视化地展示到屏幕。排版引擎中包含了负责解析编译与运行 JS 代码的 JS 引擎；（2）对HTML Living Standard的实现，包括：事件循环(Event Loop)、任务队列（Task Queue）、各种 Worker、垃圾回收，以及 HTMLElement、setTimeout、XMLHttpRequest 等各种接口与 API；◆ 浏览器内核实例为完成功能会再开启新线程，如 worker 线程(Web Workers、ServiceWorker 与 Worklets)与 internal 线程(webaudio、database、GC 等)，以及辅助页面渲染的 Compositor 线程；◆ JS 引擎是内嵌在排版引擎被被动调用的，二者都在 Render 线程上执行，从而产生平时看到的“排版引擎与 JS 引擎的执行是互斥的，同一时间只能执行其中一个”的结果；◆ 对于 Blink ， Event Loop 机制由 Scheduler 完成。Scheduler 实例存在于 Render 线程的上下文但又有自己的独立线程，它维护了多个按任务类型划分的任务队列，所有希望 post 给 Render 线程处理的任务(如解析 Html )都先通过调用 Scheduler 提供的 API 将任务放入对应类型的任务队列， Scheduler 会根据优先级策略及 Render 线程当前状态确定要执行哪一个任务之后再将其 post 给 Render 线程的 message loop，下图自上而下展示了此过程； ◆ 默认情况下 input 类任务优先级最高，其次是 Compositor 类的任务，具体优先级权重会根据策略做动态调整；◆ Compositor 线程等网页渲染相关的线程在这篇网页渲染过程；◆ JS 引擎与 Event Loop 相关整理在这篇浏览器组成与 JS 运行时环境； 参考文献●How Web Browsers Use Process &amp; Threads●How Mozilla Firefox and Google Chrome Use Process &amp; Threads●Google Developers: Inside Look At Modern Web Browser 系列●How Blink Works●The Chromium Projects: Multi-process Architecture●The Chromium Projects: How Chromium Displays Web Pages●Chromium Source Code And Code Comments And Readme.md ●Threading and Tasks in Chrome●Blink Scheduler●JavaScript: How Is Callback Execution Strategy For Promises Different Than DOM Events Callback?"},{"title":"钉钉微应用与小程序的免登流程","date":"2020-10-21T08:41:46.000Z","path":"handbook/钉钉微应用与小程序的免登流程.html","tags":[{"name":"钉钉","slug":"钉钉","permalink":"https://congzhou09.github.io/tags/%E9%92%89%E9%92%89/"}],"text":"正文♂钉钉官方开发文档中对微应用免密码登录流程的说明在此页面，总体分三步：（1）获取免登授权码；（2）获取access_token；（3）获取userid；♂画了这个过程的时序图如下，方便对其更直观的了解，小程序的免登流程基本一致，也含在其中； 画这个图的工具♀之前画图用ProcessOn，虽然画图功能好用又可以多人协作但免费版只能保存为图片格式而且有数量限制；♀昨天发现一个超级好的在线画图工具：diagrams.net，支持UML类图、时序图、ER图等，我这张图就是用它画的，最大的优点有两个：（1）可以保存文件到本地及下次打开文件（png图片格式同样支持二次编辑），也可以把图保存到线上代码仓库如GitLab，通过配置代码仓库member及git工作流也能实现多人协作，当然也就免费和没有数量限制咧；（2）使用代码仓库的Pages静态资源功能可以将图作为公网资源用url访问，这样每次改图就可以自动同步修改咧；"},{"title":"Babel相关内容串联","date":"2020-10-07T14:51:48.000Z","path":"knowledge/Babel相关内容串联.html","tags":[{"name":"Babel","slug":"Babel","permalink":"https://congzhou09.github.io/tags/Babel/"}],"text":"基本概念● Babel 是个 JS 编译器，与大多数编译器一样，包含“parsing”、“transforming”、“generation”三个处理阶段。如下图所示，代码首先经由 @babel&#x2F;parser(曾用名 Babylon) 解析成抽象语法树(AST)，然后对 AST 做遍历(@babel&#x2F;traverse)和转换(各种@babel&#x2F;plugin-..)，最后根据转换后的 AST 生成新的常规 JS 代码(@babel&#x2F;generator)。 ● Babel 本身可看作是个流水线空盒子，每个阶段具体处理过程是通过各种插件(plugin)实现的，通过配置不同的插件组合达到不同的处理目的。● Babel 的 plugin 有两类：（1）Syntax Plugins(语法插件)，用于使 babel 支持对特定语法的 parse。（2）Transform Plugins(转译插件)，用于 transforming 阶段的插件，此类插件包含了 parse 阶段相关的 Syntax Plugin 并会在代码转译为目标等级代码期间自动使用它们。● 如果仅编译小范围内容，可以通过仅引入对应的 plugin 实现。更常见的方式是使用 presets(预设)，它是为特定目的预置的一组 plugin 的集合。● 根据不同转换目的，常见的 presets 如下，本文主要面向转换 ES 语法的场景。（1）用于转换 ES 语法的 @babel&#x2F;preset-env。（2）用于转换 React 语法的 @babel&#x2F;preset-react。这个 preset 中包含的最著名插件是用于转换 JSX 语法的 @babel&#x2F;plugin-transform-react-jsx。（3）用于转换 TypeScript 语法的@babel&#x2F;preset-typescript。● preset 及 plugin 的使用，除了 npm 安装，还需要通过 Babel 配置文件(如“.babelrc”)配置，配置内容是个对象，对象格式示例如下，对象属性字段 &quot;presets&quot; 和 &quot;plugins&quot; 的取值分别是个数组，数组内容是具体 preset 或 plugin 名称的字符串，而当 preset 或 plugin 也要有自己的 options 时就使用数组表示，数组第一个元素是 preset 或 plugin 名称的字符串，第二个元素是对应的 options 对象。 12345678910111213141516&#123; &quot;presets&quot;: [ [ &quot;@babel/preset-env&quot;, &#123; &quot;modules&quot;: false, &quot;useBuiltIns&quot;: &quot;usage&quot;, &quot;corejs&quot;: 3, &quot;targets&quot;: &#123; &quot;safari&quot;: &quot;6&quot; &#125; &#125; ] ], &quot;plugins&quot;: [&quot;@babel/plugin-external-helpers&quot;]&#125; ● 配置多个 preset 与 plugin 情况下的执行顺序： 123（1）总体先执行 Plugin 再执行 Preset ，与二者声明次序无关。（2）多个Plugin 按照声明次序顺序执行。（3）多个Preset 按照声明次序逆序执行。 ● ES 的转换通常指从 ES 高版本转换到低版本，从而让新的 ES 代码能在老版本的 ES 环境中运行。这里要转换的内容包含两类：新语法和新特性。新语法指的是 class、import&#x2F;export、箭头函数、const、对象解构这类原有特性的新写法。新特性指的是原来版本不存在的特性，如 Promise、async&#x2F;await、Array.prototype.includes()。对新语法支持在 @babel&#x2F;preset-env 里，对新特性的支持在统称为 polyfill 的库中(具体是 @babel&#x2F;runtime 等，详见下文)。通过合理配置，@babel&#x2F;preset-env 会在解析转换过程中引入 polyfill 的内容。 ● TypeScript 通过配置 target 字段也支持 ES 的语法转换，但不支持 polyfill 的自动添加。 使用 Babel 的方式◇ 可以通过以下三种方式使用 Babel 做编译处理（1）通过 @babel&#x2F;cli(曾用名 babel-cli)使用&quot;babel&quot;命令执行。（2）通过 webpack(babel-loader)和 rollup(@rollup&#x2F;plugin-babel)等打包或编译工具调用。（3）通过 @babel&#x2F;register(曾用名 babel-register)为 Node.js 的 require 函数增加钩子，以在运行时调用 require 加载.es6, .es, .jsx 和.js 类型文件的时候先用 babel 进行转码处理，由于是实时转码更适合在 Node.js 开发环境使用。◇ 无论使用哪种方式，都要先安装@babel&#x2F;core 和提供 Babel 配置文件。 @babel&#x2F;preset-env◆ Babel 官方推荐使用 @babel&#x2F;preset-env(曾用名 babel-preset-env，曾经的 babel-preset-es2015 和 babel-preset-es2016 以及 babel-preset-es2017 等特定版本的 preset 都已经被它取代)。◆ @babel&#x2F;preset-env 包含 es 所有版本的 preset，会根据所配置的目标环境自动选择特定版本 preset 及相关 plugin，这里的自动选择机制的实现基于 browserslist、compat-table、electron-to-chromium 等开源项目维护的浏览器与 es 新特性及 plugin 的映射关系。◆ 配置 Babel 目标环境的方式有如下两种：（1）browserslist：在没有配置&quot;ignoreBrowserslistConfig&quot;且&quot;targets&quot;没有配置 browserslist 相关选项时被使用，示例如下，browserslist 会根据配置生成一个目标浏览器的列表，这个列表可以通过 npx browserslist &quot;配置字符串&quot; 命令查看。另外有网站提供了目标浏览器列表的图形化展示。 1&quot;browserslist&quot;: &quot;&gt; 0.25%, not dead&quot; // 市场占有率大于0.25%的浏览器（不包括IE10和BlackBerry等停止升级的浏览器） （2）targets：&quot;targets&quot;配置支持更多的语法及其他可配置项：string | Array | { [string]: string }，详细，如： 12345678910&#123; &quot;targets&quot;: &quot;&gt; 0.25%, not dead&quot; // 与上一条browserslist等价&#125;&#123; &quot;targets&quot;: &#123; // 指定特定具体目标环境 &quot;chrome&quot;: &quot;58&quot;, &quot;ie&quot;: &quot;11&quot; &#125;&#125; ◆ browserslist 和 targets 的书写位置可选以下任一种：（1）babel 配置文件中 全局 或 preset 或 plugin 的 option。（2）package.json 文件中的字段。（3）对于 browserslist，官方推荐写在.browserslistrc 文件，以适用于“ browserslist 同时提供给 babel 之外的库使用”的场景。 ◆ 如果未配置目标运行平台，@babel&#x2F;preset-env 会转换所有 ECMAScript 2015+ 的代码，这样就失去了面向各平台定制的意义，不推荐。 @babel&#x2F;preset-env 的常用配置项◆ modules（1）是否将 ES6 的 module 语法统一转换为指定的另一种 module 形式。（2）取值：&quot;amd&quot; | &quot;umd&quot; | &quot;systemjs&quot; | &quot;commonjs&quot; | &quot;cjs&quot;（commonjs 的简写） | &quot;auto&quot; | false，默认值为&quot;auto&quot;，表示根据 caller 配置项判断，使用打包工具调用 Babel 情况下打包工具会自动提供 caller 配置项的值。◆ targets.esmodules（1）默认值是 false，即认为目标平台不支持 ES 模块的定义与导入导出方式。（2）支持标签的浏览器是支持 ES 模块的。（3）设置 esmodules 之后其他 targets 设置将被忽略。◆ useBuiltIns（1）标识如何处理全局垫片(polyfill，详见下一节)，取值：&quot;usage&quot; | &quot;entry&quot; | false。（2）默认值为 false 不做处理，此时 Babel 只转换新语法，不会转换 polyfill 所包含的 Promise 和 Symbol 等新的内置类型、Array.from 和 Object.assign 等新的静态方法、Array.prototype.includes 等新的实例方法、generator 方法。（3）取值&quot;usage&quot;或&quot;entry&quot;时都需要安装@babel&#x2F;polyfill(官方推荐按需安装 core-js 或 regenerator-runtime，详见下一节)配合使用，并设置与&quot;useBuiltIns&quot;并列的&quot;corejs&quot;配置项指明所使用的 core-js 版本。（4）取值“entry”，需要在项目代码中手动引入 core-js 或 regenerator-runtime，且当仅 import 某个单独特性时支持模糊写法(如：import &quot;core-js&#x2F;es&#x2F;array&quot;)，@babel&#x2F;preset-env 会根据目标环境引入与特性关联的各具体文件（如在目标 safari 6 配置下会引入 core-js&#x2F;modules&#x2F;es.array.from、core-js&#x2F;modules&#x2F;es.array.for-each、core-js&#x2F;modules&#x2F;es.array.last-index-of、core-js&#x2F;modules&#x2F;es.array.copy-within 等文件的内容）;（5）取值“usage”，无需在项目代码中手动引入任何 core-js 或 regenerator-runtime，@babel&#x2F;preset-env 会根据代码实际使用了哪些新特性并结合目标环境引入具体文件内容。◆ corejs取值 string 或{ version: string, proposals: boolean }，与&quot;useBuiltIns&quot;配合使用，见&quot;useBuiltIns&quot;（3）的说明。 polyfill@babel&#x2F;polyfill■ @babel&#x2F;polyfill(曾用名 babel-polyfill)包含 core-js(polyfill ES features)和 regenerator-runtime(to use transpiled generator functions)两部分，用于模拟一个完整的 ES2015+目标环境。■ 官方推荐按需分别安装 core-js 或 regenerator-runtime 替代 @babel&#x2F;polyfill（20230219 更新：@babel&#x2F;polyfill 这个包已被弃用），并且不要直接整体引入，而推荐通过上节描述的 @babel&#x2F;preset-env 的 UseBuiltins 选项选择性地引入所需特性，从而避免不必要的输出包体积增加。■ @babel&#x2F;polyfill 垫片通过在全局作用域增加类和函数定义、以及为内置类型和内置对象增加静态方法和增加 prototype 属性等修改全局环境的方式实现的，在不希望产生副作用的场景下，特别是项目定位是 tool&#x2F;library 而不是 application 的时候，这种实现方式不适合。■ polyfill 方式的配置：（1）babel 配置文件中配置 @babel&#x2F;preset-env 的&quot;useBuiltIns&quot;和&quot;corejs&quot;项，例如： 123456789...&quot;presets&quot;: [ ... [&quot;@babel/preset-env&quot;,&#123; &quot;useBuiltIns&quot;: &quot;usage&quot;, &quot;corejs&quot;: &quot;3.28&quot;, ... &#125;], ...]... （2）如果使用 rollup，还需配置 @rollup&#x2F;plugin-babel 的&quot;babelHelpers&quot;值为“bundled”。 @babel&#x2F;runtime○ @babel&#x2F;runtime(曾用名 babel-runtime)作用同@babel&#x2F;polyfill，区别是它通过注入模块化 helper(modular runtime helpers)的方式实现 core-js 和 regenerator-runtime 两部分垫片。○ runtime 相关包目前有三个：（1）@babel&#x2F;runtime（仅包含 regenerator-runtime ）。（2）@babel&#x2F;runtime-corejs2（包含 regenerator-runtime 和 core-js）。（3）@babel&#x2F;runtime-corejs3（包含 regenerator-runtime 和 core-js-pure），它与@babel&#x2F;runtime-corejs2 的区别是除了支持全局类型与类型新的静态方法垫片之外，也支持类型新的实例方法垫片。所以通常安装这个 runtime 包。○ 除了安装 @babel&#x2F;runtime-corejs3 之外，也需要安装@babel&#x2F;plugin-transform-runtime 插件用于处理重复 helper 代码的复用。○ runtime 方式的配置：（1）@babel&#x2F;plugin-transform-runtime 插件没有像 polyfill 方式那样的“useBuiltIns: &#39;usage&#39;”选项，自身也没有“browserslist”或“targets”选项，会对代码中出现的所有垫片特性注入 helper（相关 issue：7330， 10250）。20230221 更新：实践发现 babel 配置的全局 targets 项 ↓ 和全局“.browserslistrc”文件方式可使 @babel&#x2F;plugin-transform-runtime 插件按需注入 helper。（2）babel 配置中增加 @babel&#x2F;plugin-transform-runtime 的如下配置： 123456789...&quot;targets&quot;: &quot;&gt; 0.25%, not dead&quot;, // ↑ 使 @babel/plugin-transform-runtime 插件按需注入 helper&quot;plugins&quot;: [ ... [&quot;@babel/plugin-transform-runtime&quot;,&#123; &quot;corejs&quot;: 3, &#125;], ...]... （3）如果使用 rollup，还需配置@rollup&#x2F;plugin-babel 的&quot;babelHelpers&quot;值为“runtime”。 从打包内容看 polyfill 方式与 runtime 方式区别◆ 以 webpack 打包目标环境不支持 Array.from 和 Array.prototype.includes 的以下原始内容为例。 12Array.from(&quot;how are you&quot;);[&quot;a&quot;,&quot;b&quot;,&quot;c&quot;].includes(&quot;a&quot;); ◆ 使用的 polyfill 方式的相应输出大致如下(已简化) 1234567891011.../* 38 */ /*Array.from的实现与全局注册*/.../* 39 */ /*Array.prototype.includes的实现与全局注册*/...var core_js_modules_es_array_from__IMPORTED_MODULE = __webpack_require__(38);var core_js_modules_es_array_includes__IMPORTED_MODULE = __webpack_require__(39);Array.from(&quot;how are you&quot;);[&quot;a&quot;,&quot;b&quot;,&quot;c&quot;].includes(&quot;a&quot;);... ◆ 使用的 runtime 方式的相应输出大致如下(已简化) 1234567891011.../* 38 */ /*Array.from的模块化实现*/.../* 39 */ /*Array.prototype.includes的模块化实现*/...var _babel_runtime_array_from__IMPORTED_MODULE = __webpack_require__(38);var _babel_runtime_instance_includes__IMPORTED_MODULE = __webpack_require__(39);_babel_runtime_array_from__IMPORTED_MODULE()(&quot;how are you&quot;);_babel_runtime_instance_includes__IMPORTED_MODULE().call( [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], &quot;a&quot;));... ◆ 最大区别在于 polyfill 方式由于修改了全局环境，原始代码写法被保留而不会被改写。◆ 20230221 更新：polyfill 方式当前已支持通过polyfill provider RFC实现非全局垫片，issue 说明与 babel-plugin-polyfill-corejs3 的使用。 Babel 配置文件○ Babel 有两种配置文件，可以同时使用或单独使用。（1）项目配置（Project-wide configuration），对整个项目生效，包含项目下的 node_modules（除非通过&quot;exclude&quot;排除），适合项目范围内广泛生效的配置，有&quot;babel.config.js 文件&quot;和&quot;babel.config.json 文件&quot;两种具体形式。（2）文件关联配置（File-relative configuration），有&quot;.babelrc(同.babelrc.js)文件&quot;和&quot;项目 package.json 文件中的 babel 字段&quot;两种具体形式。○ 关于 Project-wide 配置：（1）root 属性指明当前项目的根目录，Babel 默认以当前路径为 root 属性值，并在 root 路径下查找与应用&quot;babel.config.js&quot;文件配置。○ 关于 File-relative 配置：（1）适合为项目的子部分做配置。（2）Babel 从被编译文件向上逐级查找与应用 File-relative 配置，未查找到则终止于 package.json 文件。（3）查找 File-relative 配置的范围仅限通过 babelrcRoots 属性包含的路径，默认与 root 属性值一致，查找范围之外的文件关联配置 Babel 不会处理。（4）Babel 7 新增特性： File-relative 配置的作用范围仅限 package 自己，不包含文件层级下面的 node_modules，也不会检测 node_modules 内的.babelrc，即使通过“include”包含了 node_modules。"},{"title":"Java web 技术与架构演进历史","date":"2020-09-30T06:46:35.000Z","path":"knowledge/Java-web-技术与架构演进历史.html","tags":[{"name":"Java","slug":"Java","permalink":"https://congzhou09.github.io/tags/Java/"},{"name":"服务器","slug":"服务器","permalink":"https://congzhou09.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"}],"text":"梳理 Java web 相关的技术与架构演进历史，附带可运行 demo，以期从历史发展角度看到各个技术点产生的背景与目的，加深对服务端技术栈的了解。各小节按时间先后顺序排列。 Servlet○ Servlet 技术诞生用于使 web 服务器能够提供静态资源之外的动态内容，是扩展了 Web 服务器能力的 Java 软件组件。○ Servlet 的运行依赖于 Servlet 容器（如 Tomcat、Jetty）。○ Servlet 容器提供了遵循 Servlet 规范的接口，开发者实现自 Servlet 接口的 Java 类就称为一个 Servlet，在 Servlet 中定义用于响应请求的具体动态内容。○ 在 Servlet 容器的配置中指定请求 URL 与处理请求的 Servlet 的映射关系，如 Tomcat 配置文件位于&quot;&#x2F;WEB-INF&#x2F;web.xml&quot;，映射关系内容示例： 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; ...&gt;&lt;web-app ...&gt; ... &lt;servlet&gt; &lt;servlet-name&gt;servlet1&lt;/servlet-name&gt; &lt;servlet-class&gt;servletClass1&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet&gt; &lt;servlet-name&gt;servlet2&lt;/servlet-name&gt; &lt;servlet-class&gt;servletClass2&lt;/servlet-class&gt; &lt;/servlet&gt; ... &lt;servlet-mapping&gt; &lt;servlet-name&gt;servlet1&lt;/servlet-name&gt; &lt;url-pattern&gt;/url1&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;servlet2&lt;/servlet-name&gt; &lt;url-pattern&gt;/url2&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; ...&lt;/web-app&gt; ○ Servlet 处理客户端请求流程：（1）客户端请求到达 Servlet 容器，Servlet 容器解析请求信息创建相应的&quot;HttpServletRequest&quot;和&quot;HttpServletResponse&quot;对象。（2）Servlet 容器根据请求 URL 映射配置创建或找到对应的 Servlet 实例，创建一个线程并传入“HttpServletRequest”与“HttpServletResponse”对象，再调用 Servlet 实例的 service()方法。（3）Servlet 对象的 doGet()、doPost()等方法处理请求，返回内容交由 Servlet 容器组装成 HTTP 格式返回给客户端。○demo 地址：servlet_maven_demo JSP(Java Server Pages)○ 由于 Servlet 编写前端内容太繁琐，sun 公司又推出了 JSP。○ JSP 文件放到 Servlet 容器的 web 目录下。○ 客户端可直接请求 JSP 文件，得到的内容不是 JSP 原文件而是其中 Java 代码被执行后的内容。○ Servlet 处理请求的返回内容也可以是一个 JSP 文件。○ demo 地址同上：servlet_maven_demo JSP Model1 第一代○ JavaWeb 早期的模型，它适合小型 Web 项目，开发成本低。服务器端只有 JSP 页面，所有的操作都在 JSP 页面中，连访问数据库的 API 也在 JSP 页面中完成。 JSP Model1 第二代○ 将业务逻辑内容放到 JavaBean，JSP 页面负责显示以及请求调度。虽然第二代比第一代好了些，但 JSP 仍然做了过多的工作，它耦合了视图工作和请求调度（控制器）的工作。 JSP Model2○ Servlet 与 JSP 之间可以共享数据，JSP Model2 模式将 Servlet 与 JSP 结合使用，做了初级的 MVC 分层：（1）JSP：视图层，用来与用户打交道。负责接收用户的数据，以及显示数据给用户。（2）Servlet：控制层，负责找到合适的模型对象来处理业务逻辑，根据处理结果找到合适的 JSP 页面对用户进行响应。（3）JavaBean：模型层，完成具体的业务数据处理工作。 Struts 框架（以 Struts2 为准）◇ Struts 目的是使视图和业务逻辑清晰的分离，提高开发效率，显著特点如下：（1）提供 Action 机制来处理业务逻辑。（2）提供了一套可在 JSP 中使用的标签，方便在 Action 与 JSP 之间共享数据。◇ Struts 提供的 action 机制的实现基于 Servlet 的 Filter，相当于扩展了的 Filter，也就是 Filter 是 Struts 框架的入口，Struts 根据客户端请求及映射配置(struts-config.xml)实例化对应的 action 和调用其方法处理业务与数据，根据方法返回值及映射配置跳转到对应 JSP 页面或其他网络资源或另一个 action。 ◇ action 相对于 Servlet 的优点：（1）action 不再继承于 Servlet 从而使业务处理与 Servlet API 解耦更易于测试。（2）每个请求对应一个 action 实例，相比 Servlet 的同一个 URL 的多个请求共用一个 Servlet 对象是线程安全的。◇ 互联网曾经出现很多*.do 网址的 JSP 网站而不是*.jsp，这通常由于每个.do 对应一个 action，当 action 处理完一系列的业务逻辑后，即使 forward 到 JSP 页面返回给浏览器，浏览器的地址栏中显示的仍然是最初请求的*.do 的 action 地址。◇ demo 地址：struts2_maven_demo Javaweb 经典三层架构◇ Struts 项目中为避免所有的运算逻辑都放在 Action 导致 Action 类复用度低和逻辑混乱，通常让 action（仍属于 Servlet 范畴）只负责显示，与 JSP 共同组成表现层（web 层），独立出一层业务层（service 层）负责具体业务运算逻辑供 Action 调用，然后通过 JDBC 调用持久层完成数据库的读写的部分独立成数据访问层（dao 层）供业务层使用，由此形成了经典三层架构。○ 业务层中不包含 JavaWeb API 而只关心业务逻辑，数据层只关心对数据库的访问细节而不涉及具体业务逻辑，提高了代码的可重用性。○ MVC 定位为表现层的设计模式。 Hibernate 框架◆ Hibernate 是个 ORM（Object Relational Mapping，即对象关系映射）框架，通过创建持久化类来对应数据库中表属性及关联关系，然后通过操作持久化对象就能达到操作数据库的目的，而不需要与 SQL 语句打交道，大大降低了原 JDBC 方式的编程量。◆ Hibernate 原理是对 JDBC 进行了封装，并能自动生成 SQL 语句。 Spring 框架■ Spring 框架（Spring framwork，简称 Spring）是一个 JavaSE&#x2F;EE 全栈开源框架，它从设计上就是分层分模块的架构，可以将对应模块功能的子框架整合到体系中。■ Spring 带来的最显著改变：在 Spring 之前，web 层调用业务层、业务层调用持久层都是通过调用者 new 出被调用者的方式，之间强耦合、复用率低，Spring 通过其核心特性 IoC 实现强依赖的解耦，由 Spring 完成被调用者的 new 实例化并将其注入给依赖者。● demo 地址：spring_maven_demo SSH(Spring-Struts-Hibernate)框架● Spring 框架整合了 Struts 和 Hibernate，形成了 SSH 这个合成框架。● SSH 框架中，Struts 负责表示层，Hibernate 负责持久层，Spring 通过 IoC 特性实现对业务层 JavaBean 的管理，以及对表示层与持久层的黏合。 SpringMVC● Spring 开发者逐渐发现 Struts 存在设计缺陷，会导致性能、安全、减少配置复杂度、开发效率等方面的不足，遂开发了自己的 MVC 框架：SpringMVC。● SpringMVC 接受请求的入口是 DispatcherServlet ，不同于 Struts 基于 Servlet 的 Filter，它是派生自 HttpServlet 的一个 Servlet，请求会交付给对应的 Controller 做处理。● SpringMVC 的因其更清晰的层级分离、更强大直接的配置等优势逐渐成为 Spring Web 模块的主流子框架。● demo 地址：spring_maven_demo SSM(Spring-SpringMVC-MyBatis)框架△ SSM 框架分别用 SpringMVC 和 MyBatis 替代 SSH 框架中的 Struts 和 Hibernate，MyBatis 适用于数据源复杂度较低的场景。 SpringBoot● Spring Boot 是对 Spring 工作流层面的演进，实现基于 Spring 的更便捷的生产级别应用。● Spring Boot 的优点：（1）内嵌 Servlet 容器，独立运行的 Spring 项目，Spring Boot 可以内嵌 Tomcat，以 java -jar xx.jar 包的形式来运行一个 Spring Boot 应用，省略了 war 包部署的繁琐。（2）提供 starter 机制简化 Maven 依赖管理与 Spring 配置，如仅需要引入“spring-boot-starter-web”就可以包含 Spring 和 SpringMVC 相关的依赖和配置。● demo 地址：springboot_maven_demo"},{"title":"进程、线程、纤程、协程","date":"2020-08-05T14:11:16.000Z","path":"knowledge/进程、线程、纤程、协程.html","tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://congzhou09.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"协程","slug":"协程","permalink":"https://congzhou09.github.io/tags/%E5%8D%8F%E7%A8%8B/"}],"text":"基本概念◇ 进程是应用程序启动的实例，拥有自己的代码段、内存空间、所打开文件等系统资源。◇ 线程从属于进程，是程序的实际执行者，拥有自己的执行栈空间、程序计数器、寄存器状态，这些常被称为&quot;线程上下文&quot;，其余进程资源是进程内所有线程共享的。◇ 进程是资源分配的最小单位，线程是 CPU 调度的最小单位。◇ CPU 调度线程时涉及到线程上下文的保存与恢复，上下文信息存储在系统内核的&quot;线程控制块(Thread Control Block, TCB)&quot;中，其中的程序计数器、寄存器状态直接保存值，执行栈则保存的是地址指针。线程执行栈原始内容保存在所属进程的内存空间中。◇ 线程的五种状态及转换如下图： ◇ 多线程间的协作涉及到如下性能问题：（1）同步锁。（2）线程上下文的切换。◇ 纤程(fiber)是在用户空间模仿出的线程。（1）纤程与线程的相同点：纤程有独立于创建它代码的生命周期，有调度器(scheduler)控制谁是下一个运行的纤程，有纤程间同步机制。（2）纤程与线程的区别：纤程采用非抢占式上下文切换，即当前执行的任务会一直执行到主动放弃时间片。（3）多个纤程可运行在同一个或不同的线程上，当不同线程上的纤程有队列任务等共享数据时，也会涉及 mutex 等同步问题，只是纤程挂起时，属于同一线程的其他纤程仍然可以运行。（4）同一线程上多个纤程不会同时运行，避免了互相竞争资源。（5）同一线程上多个纤程不会运行于多个 CPU 核上。◇ 协程(coroutine &#x2F;,kəʊruː&#39;tiːn&#x2F;)是支持挂起和恢复的子程序，用于执行非抢占式多任务（non-preemptive multitasking, cooperative multitasking）。（1）协程与调用它的代码处在同一个生命周期。（2）协程在行为上更像函数而不是线程：协程将调用和恢复的控制权交由调用者管理，被调用后代码执行的控制权立即转移到协程，直到协程主动挂起，代码执行控制权会自动回到调用者。（3）互相协作的多个协程只能运行在同一个线程上，这些协程不会同时运行，不存在竞争资源的同步问题。（4）协程切换与函数调用的最大区别在于切换入口点数量，普通函数只有一个入口点，协程则有多个。◇ 纤程与协程的参考文档：StackOverflow 问答链接，问答中提到的论文。◇ 线程的调度是操作系统完成的。纤程和协程的调度则由应用程序或运行时库完成，所以被称为&quot;用户空间的线程&quot;。◇ 纤程与协程有时被视为同一概念，特别是当纤程运行在同一个线程上的时候，具体看语境。 JS 中的协程◇ ES6 提供的 Generator 可实现协程，以下使用 Generator 方式实现的生产者-消费者示例，主程序是生产者视角，由生产者驱动消费者消费产品。 123456789101112131415161718192021222324252627function* consume() &#123; console.log(&#x27;consume start&#x27;); while (true) &#123; var product = yield; // 结束标识 if (typeof product == &#x27;symbol&#x27; &amp;&amp; Symbol.keyFor(product) === &#x27;END&#x27;) &#123; break; &#125; console.log(`consume $&#123;product&#125;`); &#125; console.log(&#x27;consume exit&#x27;);&#125;const consumeIterator = consume();function produce() &#123; consumeIterator.next(); // 启动消费者 let count = 1; while (count &lt;= 5) &#123; console.log(`produce $&#123;count&#125;`); consumeIterator.next(count); count++; &#125; consumeIterator.next(Symbol.for(&#x27;END&#x27;));&#125;produce(); ◇ Generator 机制由相应的 JS 引擎实现，对于 Generator 函数，解释器会在 yield 位置适时停止，并在记录执行上下文时候额外带上当前执行到函数体的具体位置，用于再次调用 next()方法的时候恢复到上次暂停的函数体内位置继续执行。"},{"title":"二进制浮点数的存储:IEEE-754","date":"2020-06-13T08:32:31.000Z","path":"knowledge/二进制浮点数的存储IEEE-754.html","tags":[{"name":"计算机基础","slug":"计算机基础","permalink":"https://congzhou09.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"text":"数字的二进制表示●数字的二进制表示数字13.125示例如下图，规则如下：（1）整数部分不断除以2记录余数直到商为0，将余数逆序排列作为结果；（2）小数部分不断乘以2记录去掉整数部分直到乘积小数部分结果为0，将整数部分正序排列作为结果； IEEE-754的64位浮点数●JavaScript默认采用IEEE-754的64位浮点格式存储数字；●IEEE-754的64位浮点数存储方式使用64位存储浮点数，并将64位划分为1位符号位、11位指数位、52位尾数位三部分，具体如下。（1）符号位(sign)：0表示正数，1表示负数，这也是为什么会出现+0和-0的原因；（2）指数位(exponent)：表示次方数，由于指数分正负，约定中间数(二进制011 1111 1111，即2^10-1&#x3D;1023)对应的真值是0，于是“真值&#x3D;存储值-1023”（所以最高位是1时是正数，最高位是0时是负数或零），约定存储值的最小值000 0000 0000(真值-1023)与最大值111 1111 1111(真值1024)作特殊用途，所以指数位真值取值的范围是[-1022, 1023]，这个范围内的数字称为normal number；（3）尾数位(fraction)：表示尾数，尾数位超出部分采用进1舍0； ●数字存储前先将其转为二进制下的科学计数法的形式，为了最大限度使用存储空间，存储normal number时将科学计数法中“1.”前缀省略，从而可以让精度多一位变成53位，按照“(−1)^sign×(1.fraction)×2^(exponent−1023)”计算真值；●存储绝对值小于normal number范围的数字（称为subnormal number）时，不再限制先转换为1.0前缀的科学计数法从而可表示更小的数字（小至2^(-(1022+52))&#x3D;2^(-1074)），存储submormal number的标识是指数位存储值为全0，此时按照&quot;(−1)^sign×0.fraction×2^(−1022)&quot;计算真值（指数位取值-1022而不是按照&quot;exponent-1023&quot;计算，因为subnormal number相比normal number不省略&quot;1.0&quot;前缀相当于小数点多左移了一位，即0.10×2^(-1022)&#x3D;&#x3D;&#x3D;1.0×2^(-1023)）；●指数位存储值为全1对应的特殊值：（1）尾数位为全0时，表示值为Infinity；（2）尾数位非0时，表示NaN，尾数位存储空间被称为NaN的payload，可用于存储相关信息比如何原因导致的NaN；●数字13.125按照IEEE-754标准存储到64位空间的过程：（1）数字转为二进制形式，即1101.001；（2）转为二进制下的科学计数法，即1.101001×2^3，存储0.101001小数点后部分到尾数位，指数位存储3+1023&#x3D;1026转二进制&#x3D;10000000010；（3）于是64位空间所存储内容为0 10000000010 1010010000000000000000000000000000000000000000000000●双精度下的安全整数范围是[-2^53, 2^53]，因为只能存储53位有效数字位，超过53位的有效数字位将丢失，超出安全整数范围的值只要有效数字位不超过53位还是可以正确存储的，如2^54、2^100； IEEE-754的32位浮点数●IEEE-754存储浮点数都是将存储空间划分为符号位、指数位、尾数位，以下是单精度32位浮点数各区域的划分位数，存储方式与64位同理； IEEE-754在线数字转换工具网址"},{"title":"从0.1+0.2不等于0.3想到的","date":"2020-06-12T05:57:05.000Z","path":"knowledge/从0-1-0-2不等于0-3想到的.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://congzhou09.github.io/tags/javascript/"},{"name":"计算机基础","slug":"计算机基础","permalink":"https://congzhou09.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"}],"text":"二进制无法精确存储0.1♂十进制下一个简单的小数0.1，在二进制下却变成无限循环小数0.0 0011 0011 0011...进而无法精确的存储，是不是说明二进制有缺陷？♂答案是否定的：（1）小数分为有限小数、无限循环小数、无限不循环小数，其中有限小数和无限循环小数都可以转换成有理数范围内的分数形式，十进制下的0.1也就是分数1&#x2F;10；（2）无论用多少进制表示小数，小数的值都是通过∑m*n^k计算得到(n为进制数、m为底数、k为指数)，十进制下的1&#x2F;3(0.3…)、1&#x2F;7(0.142857…)是无限循环小数，但它们分别和七进制下却都表示为有限小数0.1；（3）因此分数在所有进制下都存在无限循环小数，只是各进制下哪些分数属于无限循环小数的这个范围是不一样的； 0.1+0.2不等于0.3♀在JavaScript环境和Java的System.out.println打印0.1+0.2的结果都是 &quot;0.30000000000000004&quot;，在C&#x2F;C++语言环境下printf打印的结果是&quot;0.300000&quot;，是不是说明C&#x2F;C++表示小数的精度更高？♀答案是否定的：（1）自1985年起，包括C、C++、Java、JavaScript在内的所有编程语言都采用IEEE-754标准实现浮点数的存储；（2）Java和JavaScript环境下打印值默认保留了小数点后17位，而在C&#x2F;C++环境下打印值默认保留了6位是产生上述差异现象的原因；（3）C&#x2F;C++环境下通过以下语句显式得设置打印小数点后17位同样会打印&quot;0.30000000000000004&quot;； 1printf(&quot;0.1+0.2== %.17f\\n&quot;, 0.1+0.2); 0.1+0.1等于0.2▲在各环境下&quot;0.1+0.2&#x3D;&#x3D;0.3&quot;结果是false，&quot;0.1+0.1&#x3D;&#x3D;0.2&quot;结果却是true，而且在JavaScript环境和Java的System.out.println打印&quot;0.1+0.1&quot;的结果都是&quot;0.2&quot;，为什么？▲原因是：（1）按照IEEE-754存储，0.1和0.1的存储值相加结果存储后的值与0.2直接存储的值一致；（2）按照IEEE-754存储，0.1和0.2的存储值相加结果存储后的值与0.3直接存储的值不一致；"},{"title":"webpack项目优雅使用ServiceWorker","date":"2020-05-07T10:50:14.000Z","path":"practice/webpack项目优雅使用ServiceWorker.html","tags":[{"name":"ServiceWorker","slug":"ServiceWorker","permalink":"https://congzhou09.github.io/tags/ServiceWorker/"},{"name":"webpack","slug":"webpack","permalink":"https://congzhou09.github.io/tags/webpack/"},{"name":"按需加载","slug":"按需加载","permalink":"https://congzhou09.github.io/tags/%E6%8C%89%E9%9C%80%E5%8A%A0%E8%BD%BD/"}],"text":"简介●此处将“优雅”的含义定义为两个方面：（1）应用webpack生态简化ServiceWorker的配置；（2）ServiceWorker的开关控制与相关库的按需加载；●第一方面具体是offline-plugin插件的应用；●第二方面是动态获取前端配置与webpack的Code Spliting机制的应用； offline-plugin插件的应用○webpack生态提供了offline-plugin用于方便地使用ServiceWorker，首先在项目内安装此依赖；○然后对offline-plugin进行配置与引入，分为以下两部分：（1）作为webpack插件在项目webpack配置文件中增加此plugins的配置；（2）作为js库在main.js中引入与实例化运行时对象；○在ServiceWorker更新安装完成后强制生效通过在以上（1）部分配置&quot;events:true&quot;和在以上（2）部分中处理onUpdateReady和onUpdated两个事件回调实现； 动态获取前端配置■为方便线上环境下必要时候关闭ServiceWorker机制，将ServiceWorker的开关配置在服务端，当前是否启用由从服务器获取到的开关取值决定；■当获取到的开关值为false则进行ServiceWorker的注销以保证ServiceWorker的彻底关闭； Code Spliting机制的应用▲通过splitChunks将offline-plugin显式拆分为独立的chunk；▲main.js中使用动态import的方式引入offline-plugin的运行时class；▲如此实现了对offline-plugin的按需加载； 代码实例◆webpack配置文件增加如下内容： 12345678910111213141516171819202122232425262728293031323334var OfflinePlugin = require(&#x27;offline-plugin&#x27;);module.exports = &#123; …… optimization: &#123; …… splitChunks: &#123; minSize: 0, // 关掉独立chunk最小大小的限制 cacheGroups: &#123; offline: &#123; // 将offline-plugin显式拆分成独立的chunk test: /offline-plugin/, name: &#x27;offline&#x27;, chunks: &#x27;all&#x27;, priority: 3 &#125;, …… &#125; …… plugins: [ …… new OfflinePlugin(&#123; AppCache: false, //`offline-plugin`默认支持`AppCache`，但是`AppCache`草案已经被web标准所废弃，不建议使用。但是由于仍然有部分浏览器支持，所以插件默认提供这个功能。 safeToUseOptionalCaches: true, // 去除`additional | optional`路径检查不确定时打印的警告 ServiceWorker: &#123; events: true //用于当前控制页面的sw的强制更新 &#125;, caches: &#123; //缓存内容的精细控制 main: [&#x27;index.html&#x27;, &#x27;*/vconsole.min.js&#x27;], additional: [&#x27;*/js/common.*.js&#x27;, &#x27;*/js/app.*.js&#x27;, &#x27;*/js/vendor.*.js&#x27;], optional: [&#x27;:rest:&#x27;] &#125; &#125;) ]&#125;; ◆main.js文件增加如下内容： 1234567891011121314151617181920212223242526272829303132// Service Workerif (&#x27;serviceWorker&#x27; in navigator) &#123; if (config.serviceWorker) &#123;// 从服务器获取到的ServiceWorker开关值 setTimeout(() =&gt; &#123;// 防止干扰主程序初始化速度，将ServiceWorker的初始化放到主线程执行队列的队尾 console.log(&#x27;serviceWorker init&#x27;); import(&#x27;offline-plugin/runtime&#x27;).then(swRuntime =&gt;&#123; swRuntime.install(&#123; onUpdateReady: () =&gt; &#123; console.log(&#x27;sw onUpdateReady&#x27;); swRuntime.applyUpdate(); // 作用相当于原生ServiceWorker的self.skipWaiting() &#125;, onUpdated: () =&gt; &#123; // 作用相当于原生ServiceWorker的监听 controllerchange 事件 console.log(&#x27;sw onUpdated&#x27;); window.location.reload(); &#125; &#125;); &#125;, 0); &#125; else &#123; // 注销Service Worker时，使用如下片段： navigator.serviceWorker.getRegistration().then(registration =&gt; &#123; registration &amp;&amp; registration .unregister() .then(boolean =&gt; &#123; boolean ? console.log(&#x27;Service Worker注销成功&#x27;) : console.log(&#x27;Service Worker注销失败&#x27;); &#125;) .catch(error =&gt; &#123; console.log(`Service Worker注销异常:$&#123;error&#125;`); &#125;); &#125;); &#125;&#125;"},{"title":"微服务基本理解","date":"2020-02-17T03:18:41.000Z","path":"knowledge/微服务基本理解.html","tags":[{"name":"微服务","slug":"微服务","permalink":"https://congzhou09.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}],"text":"简介◇微服务是一种架构风格，由Martin Fowler与James Lewis于2014年提出；◇微服务方式是使用一套小服务来开发单个应用，每个服务运行在自己的进程中（每个服务可看作一个小的应用），并使用轻量级机制通信，通常是HTTP API，这些服务能够通过独立的自动化部署，可以分别使用不同的编程语言实现，以及不同数据存储技术，并保持最低限度的集中式管理；◇微服务理念：有效拆分服务，提供一套统一基础架构使得各个微服务能独立的部署、运行、升级，具有轻量级的通信机制进行通信，在结构上松耦合而在功能上表现为一个整体，实现应用的敏捷开发与部署；◇服务拆分原则：当一块业务不依赖或极少依赖其它服务，有独立的业务语义，为超过2个的其他服务或客户端提供数据，那么它就应该被拆分成一个独立的服务模块；◇微服务相关开发工具：（1）Spring Cloud为开发者提供了在分布式系统的配置管理、服务发现、断路器、智能路由、微代理、控制总线等开发工具包；（2）Dubbo（3）Dropwizard（关注单个微服务的开发）◇服务间通信方式：（1）REST，同步方式（2）RPC，同步方式（3）消息队列，异步方式 单体架构相对微服务架构的缺点●代码与模块越多，逻辑复杂性越高越难理解，越难解决遇到的问题；●项目部署与启动速度逐渐变慢，修复局部模块问题需要重启整个项目使问题处理速度变慢；●新技术重构与升级项目的成本逐渐变高，新加模块使用新技术受限制，加入数据分析与监控容易出现性能瓶颈；●不利于按各模块需求伸缩资源（CPU&#x2F;内存&#x2F;数据库）；微服务架构相对单体架构的缺点△维护项目变多，处理分布式的场景变多，需要更强的故障处理机制机制； 重要部件●API网关（1）后台服务的聚合，在前端与后台之间提供统一的服务入口，让微服务对前端透明；（2）提供安全、过滤、流量控制等API管理功能；●服务发现，分布式管理各服务链接信息的注册与更新（例：Zookeeper、Eureka、Consul、Etcd）；●故障处理a.减少故障机率（1）监控，各服务设置监控指标与提供状态，采集器采集，UI呈现（例：RedisExporter、MySQLExporter、Prometheus、Grafana）；b.降低故障对整体的影响（1）降级，当某服务的下游非核心服务停止工作，则暂时将其关闭，保证核心业务不中断；（2）熔断，为了避免每次请求都等待超时导致链路资源长时占用进而导致请求堆积，每个服务对其下游服务使用熔断机制快速返回失败并通过定时健康检查自动恢复； （3）限流，服务面对瞬时流量过大情况的自我保护，推荐区分服务的限流策略，可应对某个服务由于代码问题发起的大量请求； c.提供故障排查效率 （1）链路跟踪（例：Dapper、Zipkin），查看请求经过哪些服务节点及各自的响应时长 （2）日志分析，各服务日志采集与检索支持，通常用ELK实现； ### 应用实例 ■配置管理服务 （1）配置管理服务集中管理其他各微服务在各运行环境下的配置，配置支持实时动态修改与自动更新到其他各微服务，支持版本控制与内容审计； （2）每个从配置管理服务请求自己的配置并缓存本地； （3）经典案例：Apollo、Spring Cloud默认使用Git存储配置内容；"},{"title":"配置公司GitLab和个人GitHub使用不同的Name和Email","date":"2020-02-04T06:55:04.000Z","path":"handbook/配置公司GitLab和个人GitHub使用不同的Name和Email.html","tags":[{"name":"git","slug":"git","permalink":"https://congzhou09.github.io/tags/git/"}],"text":"◇Git v2.13及之后的版本支持条件配置include（conditional configuration includes），首先进行必要的git版本升级；◇配置全局默认的name和email为公司的Name和Email，使用如下命令： 12git config set --global user.name yuancongzhougit config set --global user.email yuancongzhou@company.com ◇配置完成后，在当前用户文件夹下的&quot;.gitconfig&quot;可以看到已配置的信息如下，其实也可直接编辑这个&quot;.gitconfig&quot;文件； 123[user] name = yuancongzhou email = yuancongzhou@company.com ◇同目录下再创建一个git配置文件，文件名例如&quot;.gitconfig_github&quot;，文件内容如下 123[user] name = congzhou09 email = yuancongzhou@yeah.net ◇&quot;.gitconfig&quot;文件增加如下内容，其中的gitdir关键字用于模式匹配（可使用gitdir&#x2F;i表示不区分大小写），当某git目录的.git路径匹配这个模式的时候，其范围内的各变量将生效；注意其中文件夹名需要完整并且&quot;&#x2F;&quot;是必须的； 12[includeIf &quot;gitdir:Git_mine/&quot;] path = .gitconfig_github"},{"title":"webpack项目自动代码检查与格式化的实现","date":"2019-11-26T10:09:38.000Z","path":"handbook/webpack项目自动代码检查与格式化的实现.html","tags":[{"name":"webpack","slug":"webpack","permalink":"https://congzhou09.github.io/tags/webpack/"}],"text":"当前解决方案● 使用 editorconfig 控制书写代码期间的基本风格统一。● 使用 eslint 做代码语法检查，实现代码质量控制。● 使用 prettier 做代码格式化，实现统一风格。● git commit 之前执行自动修复，无法自动修复的地方手动修改。 ps: 由于 eslint 也包含了代码格式化功能，所以 prettier 仅做非 js 类代码(js&#x2F;ts&#x2F;tsx&#x2F;jsx)的格式化。 VSCode 环境配置(IDE 的配置此处只以 VSCode 为例)○ 目的是让 IDE 插件的格式化与命令行执行命令的格式化统一使用 prettier。○ 安装如下插件：EditorConfig for VS Code、ESLint、Vetur、Prettier-Code formatter。○ 由于跟 Prettier 重复与键位冲突，如果有 Beautify 插件则删掉。○ 打开 VSCode 的 setting.json 文件，增加如下配置内容： 123456789101112131415161718192021222324252627282930313233/*************vetur相关*****************/&quot;vetur.format.defaultFormatter.html&quot;: &quot;prettier&quot;,&quot;vetur.validation.template&quot;: false,&quot;vetur.validation.script&quot;: false,&quot;[vue]&quot;: &#123; &quot;editor.defaultFormatter&quot;: &quot;octref.vetur&quot;&#125;,/*************eslint相关*****************/&quot;eslint.format.enable&quot;: true,&quot;eslint.validate&quot;: [ &#123; &quot;language&quot;: &quot;javascript&quot;, &quot;autoFix&quot;: true &#125;, &quot;javascriptreact&quot;, &#123; &quot;language&quot;: &quot;vue&quot;, &quot;autoFix&quot;: true &#125;],/*************prettier相关*****************/&quot;[javascript]&quot;: &#123; &quot;editor.defaultFormatter&quot;: &quot;esbenp.prettier-vscode&quot;&#125;,&quot;[html]&quot;: &#123; &quot;editor.defaultFormatter&quot;: &quot;esbenp.prettier-vscode&quot;&#125;,&quot;[sass]&quot;: &#123; &quot;editor.defaultFormatter&quot;: &quot;esbenp.prettier-vscode&quot;&#125;,&quot;[typescriptreact]&quot;: &#123; &quot;editor.defaultFormatter&quot;: &quot;esbenp.prettier-vscode&quot;&#125;, 本机环境配置◇ 考虑版本兼容不推荐全局安装 eslint，通过全局安装 eslint-cli 以实现对全局 eslint 命令的支持。 项目内配置◆ 根目录下的&quot;.editorconfig&quot; 文件内容如下(此处以空 2 格作为标准)： 123456789# EditorConfig is awesome: https://EditorConfig.org# top-most EditorConfig fileroot = true[*]charset = utf-8indent_style = spaceindent_size = 2end_of_line = lfinsert_final_newline = true ◆ 运行如下命令以安装 eslint、babel-eslint、prettier、eslint-config-google、eslint-config-prettier、eslint-plugin-prettier 1yarn add -D eslint babel-eslint prettier eslint-config-google eslint-config-prettier eslint-plugin-prettier ◆ 根目录下的&quot;.prettierrc&quot;文件内容： 123456&#123; &quot;singleQuote&quot;: true, &quot;trailingComma&quot;: &quot;all&quot;, &quot;printWidth&quot;: 140, &quot;endOfLine&quot;: &quot;lf&quot;&#125; ◆ 根目录下的&quot;package.json&quot; 文件中增加名为&quot;codecheck&quot;的 script： 1&quot;codecheck&quot;: &quot;eslint --ext .jsx,.js,.vue,.ts,.tsx --fix src &amp;&amp; prettier --write src/**/*.(css,scss,less) --log-level warn&quot; vue 项目◇ 安装 eslint-plugin-vue（使 eslint 支持 vue 语法的官方插件）◇ 根目录下的&quot;.eslintrc.js&quot;文件： 1234567891011121314module.exports = &#123; root: true, extends: [&#x27;google&#x27;, &#x27;plugin:vue/essential&#x27;, &#x27;plugin:prettier/recommended&#x27;], env: &#123; &quot;browser&quot;: true, &quot;commonjs&quot;: true, &quot;es6&quot;: true, &quot;node&quot;: true &#125;, parserOptions: &#123; parser: &#x27;babel-eslint&#x27;, sourceType: &#x27;module&#x27; //配置JS文件加载模式: script--script标签方式 module--es6的import方式 &#125;&#125; react 项目● 安装 eslint-plugin-react● 根目录下的&quot;.eslintrc.js&quot;文件： 12345678910111213141516171819module.exports = &#123; root: true, extends: [&#x27;google&#x27;, &#x27;plugin:react/recommended&#x27;, &#x27;plugin:prettier/recommended&#x27;], env: &#123; &quot;browser&quot;: true, &quot;commonjs&quot;: true, &quot;es6&quot;: true, &quot;node&quot;: true &#125;, parser: &#x27;babel-eslint&#x27;, parserOptions: &#123; sourceType: &#x27;module&#x27; &#125;, settings:&#123; react: &#123; version: &#x27;detect&#x27; &#125; &#125;&#125; 如果使用了 babel-eslint 无法识别的 typescript 特性○ eslint 的 parser 改用“@typescript-eslint&#x2F;parser”，并安装“@typescript-eslint&#x2F;eslint-plugin”插件： 12yarn remove babel-eslintyarn add -D @typescript-eslint/parser @typescript-eslint/eslint-plugin ○ “.eslint.js”文件修改如下部分： 1234&#123; plugins: [&quot;@typescript-eslint&quot;], parser: &#x27;@typescript-eslint/parser&#x27;,&#125; 手动进行代码检查○ 命令行运行：npm run codecheck 强制进行 git 提交前的代码检查△ 预备知识：（1）通过在 git hooks 里配置各种预处理脚本，比如代码检查或者跑单元测试之类的事情，如果我们的代码没有通过代码检查或者测试用例覆盖率不够，我们的 push 甚至 commit 会直接被拒绝。（2）预处理脚本位于 git 项目下隐藏文件夹“.git”的“hooks”文件夹中。△husky 可用于自动完成上述动作，使用方法：（1）安装 husky。（2）执行&quot;npx husky install&quot;打开 git hooks 支持。（3）为使项目每次 install 之后默认执行（2）中命令，在 package.json 的“scripts“中添加如下内容： 1234&quot;script&quot;: &#123; &quot;prepare&quot;: &quot;husky install&quot;, ... ...&#125; （4）将代码检查命令添加为 hook，执行：npx husky add .husky&#x2F;pre-commit &quot;npm run codecheck&quot;，此命令将创建文件&quot;.husky&#x2F;pre-commit&quot;，文件内容如下。 1234#!/usr/bin/env sh. &quot;$(dirname -- &quot;$0&quot;)/_/husky.sh&quot;npm run codecheck △ 以上操作之后，项目 commit 前将自动执行代码检查脚本，结果将在执行 commit 的窗口中输出。 △ 对 codecheck 的改进（1）当前 codecheck 脚本对指定范围的代码做全量处理，当代码量大时会拖慢速度。此时可使用&quot;lint-staged&quot;将范围限定在处于 staged 状态的文件(即文件被执行过 git add)。（2）安装 lint-staged，将如下 lint-staged 的配置增加到 package.json 文件的第一级字段，lint-staged 也支持其他配置方式，参考官方文档： 1234&quot;lint-staged&quot;: &#123; &quot;./src/!(**/node_modules)/*.&#123;ts,tsx,js,jsx,vue&#125;&quot;: &quot;eslint --fix&quot;, &quot;./src/!(**/node_modules)/*.&#123;css,scss,less&#125;&quot;: &quot;prettier --write&quot;&#125; （3）将 husky 的 pre-commit 内容改为: yarn lint-staged。 常见问题◇ 某些必须违背规则的地方（如服务器接口的参数），通过如下 eslint 专用注释忽略对其做自动化检查与格式化，例： 12345678910axios(&#123; method: &#x27;get&#x27;, url: &#x27;oneUrl&#x27;, data: &#123; /* eslint-disable */ para_first: 1, para_second: 2 /* eslint-enable */ &#125;&#125;) ◇ prettier 命令中的 file pattern 之前使用的是&quot;src&#x2F;**&#x2F;*.{css,scss,less}&quot;，当查找不到任何文件时候会报“No files matching the pattern”错误，改成&quot;src&#x2F;**&#x2F;*.(css,scss,less)&quot;就没有这个问题了。 ◇ lint-staged 默认以并发方式执行任务，内容较多时可能导致内存不足而被强制退出，添加 --concurrent &lt;number | false&gt; 参数以限制并发数量或关闭并发。 参考文献●prettier 官方文档●file pattern 语法●husky 官方文档●ESLint + VSCode: How to Format Your Code Using .eslintrc"},{"title":"浏览器组成与JS运行时环境","date":"2019-11-05T04:00:01.000Z","path":"knowledge/浏览器组成与JS运行时环境.html","tags":[{"name":"浏览器","slug":"浏览器","permalink":"https://congzhou09.github.io/tags/%E6%B5%8F%E8%A7%88%E5%99%A8/"}],"text":"从浏览器组成到 JS 运行时环境◆ 浏览器组成相关内容整理到了这篇浏览器中的进程与线程。◆ 浏览器内核实例中的以下几项内容被称为“JS 运行时环境（JS Runtime Environment）”：（1）JS 引擎。（2）事件循环(Event Loop)。（3）任务队列(Task Queue)。（4）Web&#x2F;DOM API，包括如 setTimeout 等定时器函数、Ajax 等网络请求、DOM 操作与事件监听，这些 API 对运行时环境可见，具体的线程级实现由浏览器提供。 ◆ 事件循环相关规范不属于 ECMA 范畴，它们约定于HTML Living Standard。◆ JS 运行时环境举例：Chrome 和 Node.js 使用了相同的 JS 引擎 V8，但具有不同的 JS 运行时环境。 JS 引擎○ JS 引擎中除了执行代码的解释器（Interpreter）之外，主要包含上图左侧黑框中的两部分：内存堆（Memory Heap）、调用栈（Call Stack）。○ V8 引擎中还会有个即时编译器（Just-In-Time, JIT compiler）作为解释器的辅助，解释器单纯按行解释和执行源代码，JIT 编译器则会发现并编译优化被频繁执行的代码块。○ 内存堆用于存储代码执行期间的变量和函数。○ 调用栈用于记录代码执行位置及相关状态信息，每个栈帧对应一个执行上下文，执行上下文的前置知识整理在这篇。○ 使用浏览器开发工具处理异常抛出的栈追踪(stack trace)正是异常发生时的调用栈状态。○ JS 引擎执行 JS 代码的过程： 解释器创建全局执行上下文并作为栈帧添加到调用栈，然后在这个上下文环境执行代码。 执行期间如果遇到函数调用或 eval 表达式就创建一个新的执行上下文作为栈帧添加到调用栈栈顶并切换到新的栈帧执行其中代码。 执行期间如果再遇到函数调用或 eval 表达式重复步骤 2。 在当前栈帧执行完代码后，解释器将当前栈帧从调用栈弹出和销毁，然后切换到前一个栈帧继续执行。 重复步骤 2, 3, 4 直到调用栈清空。 ○ 以下面代码段为例，随着代码执行，调用栈变化过程如下图。 12345678function multiply(x, y) &#123; return x * y;&#125;function printSquare(x) &#123; var s = multiply(x, x); console.log(s);&#125;printSquare(5); ○ JS 引擎运行在 Render 线程，单线程优势是不需要处理死锁之类的多线程问题，缺陷是耗时的 JS 执行会阻塞 Render 线程引起页面更新渲染与交互事件得不到及时处理，导致页面卡顿甚至卡死，Chrome 浏览器当阻塞持续超过一定时间会出现如下弹窗。 事件循环与任务队列○ 浏览器内核中维护了多个任务队列，Render 线程要执行的任务（其中包括 JS 引擎要执行的代码段及 Event、Timer、网络请求、数据访问等 JS 回调）会先被存入任务队列，之后按照类型优先级等因素在最合适的时机被执行，维护任务队列与决定任务执行时机的主体称为 Event Loop。○ HTML Standard 中定义了多种 Event Loop，此处的 Event Loop 是其中的“window event loop”(web worker 环境对应的是 worker event loop)。○ 每个 Event Loop 对应一个或多个任务队列(task queue)与一个微任务队列(microtask queue)，不同种类任务源的任务进入相应的任务队列，不同任务源任务有不同的优先级权重，属于同一个任务源的多个任务不会乱序执行。○ task 在 V8 中被称为宏任务(macrotask)，而 microtask 在 ECMAScript 中被称为 job。○ 微任务队列中的微任务在当前调用栈为空而还未将控制权还给 Event Loop 的时候被执行，可用于在当前一轮 Event Loop 之内做任务的推迟执行。○ 执行微任务阶段会将当前微任务队列内的所有微任务都执行完，从而保证这些微任务执行期间所处的环境状态是基本一致的，没有“经过了一次更新渲染”、“处理过定时器回调或事件回调”或“接收到了网络数据更新”等方面的差异。○ 微任务的任务源如下 123Promise的then|catch|finally处理函数以及与其等价的await的返回值处理MutationObserver的处理函数queueMicrotask注册的函数 ○ 其他方式如 setTimeout、requestIdleCallback、MessageChannel 等注册的回调函数都属于宏任务。有个例外的 requestAnimationFrame，它的回调函数不在宏任务或微任务队列，而被存放在渲染引擎内部的帧回调队列里。○ 目前(20210104)不同类型任务优先级策略未在 HTML Living Standard 中指定，不同浏览器中表现可能不一致，如下例 MessageChannel 与 setTimeout 在不同浏览器的优先级差异导致的表现不一致。 12345678910111213141516171819202122232425setTimeout(function() &#123; console.log(&#x27;setTimeout1&#x27;);&#125;, 0);setTimeout(function() &#123; console.log(&#x27;setTimeout2&#x27;);&#125;, 1);var channel = new MessageChannel();channel.port1.onmessage = function(event) &#123; console.log(&#x27;postMessage&#x27; + event.data);&#125;;channel.port2.postMessage(0);channel.port2.postMessage(1);channel.port2.postMessage(2);setTimeout(function() &#123; console.log(&#x27;setTimeout3&#x27;);&#125;, 0);setTimeout(function() &#123; console.log(&#x27;setTimeout4&#x27;);&#125;, 0);setTimeout(function() &#123; console.log(&#x27;setTimeout5&#x27;);&#125;, 0);// Chrome输出：postMessage0 setTimeout1 setTimeout3 setTimeout4 setTimeout5 setTimeout2 postMessage1 postMessage2，由于setTimeout的最小4ms节流限制所以postMessage0在setTimeout1之前，但从优先级上setTimeout高于MessageChannel。// Firefox输出：postMessage0 postMessage1 postMessage2 setTimeout1 setTimeout3 setTimeout4 setTimeout5 setTimeout2，可见Firefox中MessageChannel优先级高于setTimeout。 ○ Event Loop 不断按照以下处理模型(event loop processing model)执行任务： 从某个（具体选择策略由浏览器决定）宏任务队列取出最老的 runnable task 交给 JS 引擎执行至调用栈为空（关于 runnable：同一个 Event Loop 可以被多个 Document 共用，某些 Document 可能当前并不处于 active 状态，从属于这种 Document 的任务就不是 runnable 的）。 不断从微任务队列获取最老的 microtask 交给 JS 引擎执行，直至微任务队列清空。 处理更新渲染，浏览器收集当前 Event Loop 关联的所有 Document，并排除据其“当前刷新帧率”还未到达下一帧时间的 Document，然后进一步排除“肯定没必要生成新的页面帧”的 Document，然后对筛选后的每个 Document 依次执行如下类型任务。(1)判断与标识 autofocus 候选元素(2)判断与触发 resize 事件(3)判断与触发 scroll 事件(4)判断与触发 media query 类事件(5)判断与触发 css animation 类事件(6)判断与触发 fullscreen 类事件(7)执行 animation callbacks (也就是通过 requestAnimationFrame 注册的回调函数)(8)更新 intersection observations(9)渲染生成新的页面帧(详细过程整理在这篇网页渲染过程) 如果以上三步都没有要执行的任务则进入 idle 阶段，将当前注册于 idle 阶段（通过 requestIdleCallback 注册）的所有回调函数添加到任务源为 idle-task 的宏任务队列。 JS 运行时环境的动态运行过程♂ JS 引擎运行的代码均来自于任务队列(包括最初的 html 文档中&lt;script&gt;标签内的全局作用域代码)，队列中任务的执行顺序由 Event Loop 控制。♂ JS 执行代码期间遇到的事件监听、Ajax 请求、定时器等 Web&#x2F;DOM API 调用由 API 实现层执行。♂ Web API 完成时的回调函数被作为新任务添加到相应任务队列，不会立即影响当前正在执行的代码，也无须等待。♂ Event Loop 会在合适时机( JS 引擎的调用栈当前为空是其必要条件)将回调函数从任务队列取出并交给 JS 引擎执行。 同步与异步、阻塞与非阻塞♀ 结合上述 JS 运行时环境运行 JS 代码的两个特性：同步与异步、阻塞与非阻塞（1）同步和阻塞指的是 JS 引擎是单线程执行代码的并且运行在 Render 线程，在 JS 引擎执行代码至其调用栈清空之前， Render 线程负责的更新渲染交互事件处理等其他任务是被阻塞的。（2）异步和非阻塞指的是 JS 代码执行期间调用的浏览器所提供 Web&#x2F;DOM API 不在当前线程同步执行，而是继续向下执行后面的代码，Web&#x2F;DOM API 的执行结果是通过之后回调函数得到的，Event Loop 与任务队列是实现非阻塞特性的关键机制。 知识应用■ 关于 requestAnimationFrame 的理解Q: 在当前轮 Event Loop 调用 requestAnimationFrame 注册的回调函数执行时机是在下一轮 Event Loop 之前吗？A: 不一定，根据以上 Event Loop 处理模型第 3 条，下一轮 Event Loop 达到当前刷新帧率的下一帧时间才会被执行，否则就是在之后满足时间条件的那一轮 Event Loop 中执行。Q: 调用 requestAnimationFrame 及执行其回调函数所处的 Event Loop 中如果没有新 Frame 生成，requestAnimationFrame 的回调函数还会执行吗？A: 会执行，根据以上 Event Loop 处理模型第 3 条第(7)(9)小条，执行回调函数与更新渲染是两个独立的处理阶段，回调函数仍然将在满足帧率时间的那一轮 Event Loop 执行，此行为与 MDN 中对 requestAnimationFrame 函数的说明(告诉浏览器接下来将执行一个引起更新渲染的操作，而在更新渲染新帧之前要先执行所注册的回调函数)不冲突。■ 实现页面内可见的数字快速增长，由于更新渲染只可能发生在 task 执行完毕，所以将增长作为 task 添加到任务队列，代码示例与运行效果如下： 123456789101112131415&lt;p style=&quot;will-change: contents&quot; id=&quot;counter&quot;&gt;0&lt;/p&gt;&lt;button onclick=&quot;startCount();&quot;&gt;start&lt;/button&gt;&lt;script&gt; var pElem = document.querySelector(&#x27;#counter&#x27;); function startCount() &#123; var curNum = 0; function count() &#123; pElem.innerHTML = ++curNum; if (curNum &lt; 200) &#123; setTimeout(count, 0); &#125; &#125; count(); &#125;&lt;/script&gt; 0 start var pElem = document.querySelector('#counter'); function startCount() { var curNum = 0; function count() { pElem.innerHTML = ++curNum; if (curNum < 200) { setTimeout(count, 0); } } count(); } 参考文献● How JavaScript Works 系列● requestAnimationFrame Scheduling For Nerds● Task scheduling in Blink● HTML Living Standard● The JavaScript Call Stack - What It Is and Why It&#39;s Necessary● Using microtasks in JavaScript with queueMicrotask()● In depth: Microtasks and the JavaScript runtime environment● Tasks, microtasks, queues and schedules● When will requestAnimationFrame be executed● Understanding Event Loop● Is there a faster way to yield to Javascript event loop than setTimeout(0)● Concurrency model and the event loop● Event loop: microtasks and macrotasks"},{"title":"React Native工程增加Expo支持","date":"2019-08-14T12:21:11.000Z","path":"practice/React-Native工程增加Expo支持.html","tags":[{"name":"React Native","slug":"React-Native","permalink":"https://congzhou09.github.io/tags/React-Native/"},{"name":"Expo","slug":"Expo","permalink":"https://congzhou09.github.io/tags/Expo/"}],"text":"行动前的考虑◆原有的React Native工程是在Windows下安装完Android开发环境后使用命令&quot;react-native init&quot;生成的，看到存储Android SDK所需的30G+的硬盘和Android模拟器运行所需的8G+内存预算，想在自己的便携机上搞一套相同环境负担实在太重； ◆看到Expo时被其简练的开发流程所吸引，而环境轻量太多了，也同样支持代码修改保存后自动刷新内容。设想利于Expo能随时随地用便携机开发APP，到构建发布时候再使用笨重的Android环境，很美好； ◆React Native中文官网警告Expo大量依赖于国外网络环境，只用于学习、演示、试验等，不建议国内使用。我的目的就是用于开发过程方便看效果，实践后发现仅仅在安装Expo环境和创建工程的时候才需要国外网络环境； 尝试基础的React Native项目步骤总结如下：◆安装Expo环境，使用“react-native init”命令创建个新的React Native工程；◆进入React Native工程目录下创建可运行的Expo的工程：expo init demo ；◆进入demo目录，为“app.json”文件增加如下packagerOpts配置内容，以指定使用自定义的metro配置文件； 123456789101112&#123; &quot;expo&quot;: &#123; &quot;name&quot;: &quot;demo&quot;, &quot;slug&quot;: &quot;demo&quot;, &quot;privacy&quot;: &quot;public&quot;, &quot;sdkVersion&quot;: &quot;33.0.0&quot;, &quot;packagerOpts&quot;: &#123; &quot;projectRoots&quot;: &quot;&quot;, &quot;config&quot;: &quot;metro.config.js&quot; &#125;, ... ...&#125; ◆新建“metro.config.js”文件，内容如下。其中的blacklistRE配置了一个正则，打包时会忽略掉正则匹配到的路径。因为在根目录下的node_modules中会存在与demo目录下node_modules中相同的库，例如react-native, react, prop-types，如果不忽略就会使得providesModule在解析时产生重名，从而导致jest-haste-map报错。 123456789101112131415161718192021222324const path = require(&#x27;path&#x27;);const blacklist = require(&#x27;metro-config/src/defaults/blacklist&#x27;);const escapeRegexString = require(&#x27;escape-regex-string&#x27;);module.exports = &#123; resolver: &#123; blacklistRE: blacklist([ new RegExp( `^$&#123;escapeRegexString(path.resolve(__dirname, &#x27;..&#x27;, &#x27;node_modules&#x27;))&#125;\\\\/.*$`, ), ]), providesModuleNodeModules: [ &#x27;react-native&#x27;, &#x27;react&#x27; ], extraNodeModules: &#123; &#x27;@babel/runtime&#x27;: path.resolve(__dirname, &#x27;node_modules/@babel/runtime&#x27;), &#125;, &#125;, projectRoot: path.resolve(__dirname), watchFolders: [ path.resolve(__dirname, &#x27;..&#x27;), ],&#125;; ◆安装“metro.config.js”文件中用到的escape-regex-string，执行：yarn add escape-regex-string ；◆修改App.js将原React Native的App作为组件引入，如下： 1234567import App from &#x27;../App&#x27;;export default function Demo() &#123; return ( &lt;App /&gt; );&#125; ◆回到上一级的React Native工程目录，修改&quot;metro.config.js&quot;文件，内容如下，目的是忽略demo文件夹下的node_modules中的库； 123456789101112131415161718192021const path = require(&#x27;path&#x27;);const blacklist = require(&#x27;metro-config/src/defaults/blacklist&#x27;);const escapeRegexString = require(&#x27;escape-regex-string&#x27;);module.exports = &#123; resolver: &#123; blacklistRE: blacklist([ new RegExp( `$&#123;escapeRegexString(path.resolve(__dirname, &#x27;./demo&#x27;, &#x27;node_modules&#x27;))&#125;`, ) ]) &#125;, transformer: &#123; getTransformOptions: async () =&gt; (&#123; transform: &#123; experimentalImportSupport: false, inlineRequires: false, &#125;, &#125;), &#125;&#125;; ◆安装“metro.config.js”文件中用到的escape-regex-string，执行：yarn add escape-regex-string ；◆以上即创建了支持Expo的最基础React Native项目的开发环境，直观上的修改是：（1）增加了demo文件夹；（2）增加了escape-regex-string的依赖；（3）metro配置中增加了忽略文件夹；◆项目需要安装新的npm依赖的步骤：（1）React Native项目中安装依赖；（2）Expo项目中安装依赖；（3）Expo的metro配置中增加依赖对应的extraNodeModules项，如增加“react-navigation”后，修改为如下样子： 1234extraNodeModules: &#123; &#x27;@babel/runtime&#x27;: path.resolve(__dirname, &#x27;node_modules/@babel/runtime&#x27;), &#x27;react-navigation&#x27;: path.resolve(__dirname, &#x27;node_modules/react-navigation&#x27;), &#125;, ◆之后就可在demo目录下使用expo开发上一层目录的React Native工程了，运行“npm start”即可开始；◆参考项目地址，查看git log可看到大致改造过程； 尝试真实的React Native项目基础React Native项目尝试成功之后对于真实项目的改造也比较有信心了，按照总结的思路步骤对一个真实项目做尝试，遇到了如下几个坑：◇Icons（1）React Native通常使用的图标库是“react-native-vector-icons”，Expo使用的图标库是“@expo&#x2F;vector-icons”，它对“react-native-vector-icons”增加了一层兼容之后的库，默认是包含在Expo中的；（2）React Native引入图标的语法如：import MaterialIcon from &quot;react-native-vector-icons&#x2F;MaterialIcons，而Expo引入图标的语法如：import { MaterialIcons } from &#39;@expo&#x2F;vector-icons&#39;；（3）原项目中的__import MaterialIcon from &quot;react-native-vector-icons&#x2F;MaterialIcons&quot;语句在Expo运行环境下会被自动解析成__import MaterialIcon from &quot;@expo&#x2F;vector-icons&#x2F;MaterialIcons，这在Expo中会引起报错；（4）按照Expo引入图标的语法，将原项目的__import MaterialIcon from &quot;react-native-vector-icons&#x2F;MaterialIcons&quot;__语句改为__import {MaterialIcons} from &quot;react-native-vector-icons&quot;__才能通过编译，但这样就影响了原项目的代码内容和正常编译；（5）目前未发现Expo环境中控制自动解析的metro配置项；◇SplashScreen（1）原项目中使用了“react-native-splash-screen”实现启动页，虽然使用上一步中的方法引入h和指定了“react-native-splash-screen”，但在调用SplashScreen函数时还是会报如下找不到splash库的错误； （2）“react-native-splash-screen”官方文档指出在Android和iOS环境下分别需要执行link和增加配置才可正常工作，而在Expo环境该如何配置暂时没有找到；（3）Expo官方文档暂未找到关于如何link lib的说明； 结论以上，得出结论：目前在保持原React Native代码正常的前提下，为工程增加Expo开发方式支持的想法无法实现。"},{"title":"Taro使用与开发钉钉小程序","date":"2019-08-02T07:02:50.000Z","path":"practice/Taro使用与开发钉钉小程序.html","tags":[{"name":"Taro","slug":"Taro","permalink":"https://congzhou09.github.io/tags/Taro/"},{"name":"小程序框架","slug":"小程序框架","permalink":"https://congzhou09.github.io/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F%E6%A1%86%E6%9E%B6/"},{"name":"E应用","slug":"E应用","permalink":"https://congzhou09.github.io/tags/E%E5%BA%94%E7%94%A8/"},{"name":"钉钉小程序","slug":"钉钉小程序","permalink":"https://congzhou09.github.io/tags/%E9%92%89%E9%92%89%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}],"text":"选择Taro前的考虑■钉钉于2019年6月中旬升级原“E应用”为“小程序”，同时升级了小程序开发者工具，可以兼容阿里巴巴旗下手淘、支付宝等不同产品的运行环境钉钉小程序； ■根据官方说明，E应用和支付宝小程序使用相同的小程序通用框架，支持通用组件和API，然后分别有自己扩展的组件和API，如下图； ■Taro支持开发支付宝小程序，进而可以支持钉钉小程序的开发； Taro通用使用方法●环境安装：npm install -g @tarojs&#x2F;cli ； ●创建项目：taro init myApp ； ●基础要点：https://nervjs.github.io/taro/docs/tutorial.html ●组件手册：https://nervjs.github.io/taro/docs/components-desc.html ●添加redux支持： （1）安装redux，redux-thunk(需要支持异步action的话)； （2）安装@tarojs&#x2F;redux，相当于react项目中的&quot;react-redux&quot;，对应的用法如“import { Provider } from &#39;@tarojs&#x2F;redux&#39;”； 开发钉钉小程序步骤◆进入项目目录，根据要构建的小程序类型运行相应的dev或build命令，如：npm run dev:alipay，将在根目录下生成dist目录 ； ◆使用钉钉小程序开发者工具打开dist目录将自动识别小程序类型，并监测dist目录内的变化自动编译和显示预览； ◆dev模式下Taro会监测src的变化自动将修改编译到dist目录； ◆钉钉基础要点与组件手册：https://open-doc.dingtalk.com/microapp/dev/framework-overview ◆小程序官方Demo：在小程序开发者工具中新建项目，选择“模板选取”创建即可； 开发钉钉小程序过坑记录□Taro.request不支持钉钉小程序，需使用钉钉提供的&quot;dd.httpRequest&quot;发送Ajax请求； □项目总入口文件app.jsx中&quot;Taro.render(, document.getElementById(&#39;app&#39;));&quot;语句其实是一直都执行的，即使删掉也会正常渲染小程序，所以想确切地在小程序渲染之前dosomething是做不到的； □不要在项目总入口文件app.jsx中调用钉钉的&quot;dd.alert、dd.showToast&quot;等交互UI类API，语句并不生效； □&quot;通讯录选人&quot;功能在PC端小程序开发者工具中不可用，在手机端预览功能正常。其中的&quot;responseUserOnly&quot;参数取值为true时在手机端选择部门会引起钉钉闪退； □Taro未实现完整的React语法（1）不支持“props.children”，导致不支持需要传递子孙组件的组件封装；（2）export通过connect包装的组件，被包装组件必须在同一个文件内定义而不能是import引入的组件，否则报错“未找到 Taro.Component 的类定义”；"},{"title":"Apollo前端本地开发环境搭建","date":"2019-06-07T08:48:09.000Z","path":"handbook/Apollo前端本地开发环境搭建.html","tags":[{"name":"apollo","slug":"apollo","permalink":"https://congzhou09.github.io/tags/apollo/"},{"name":"前端","slug":"前端","permalink":"https://congzhou09.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"开发环境","slug":"开发环境","permalink":"https://congzhou09.github.io/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"}],"text":"分析○Apollo项目中前端代码位于“Apollo\\apollo-portal\\src\\main\\resources\\static”目录下。 ○前端使用的框架和库是jQuery+bootstrap+早期AngularJS，没有webpack配置和前端开发服务器。然后其中的API请求使用的都是相对路径，没有统一配置API请求前缀的地方。另外存在非ajax方式的API请求，也存在服务器API返回值是html页面相对路径的情况，所以它并未实现完全的前后端分离。 ○为实现前后端分离开发，需要开发环境下的http服务器，它做两个事情：（1）前端代码的http访问（2）代码中访问服务器API相对地址的转发。 环境搭建●开发环境http服务器使用nginx完成，nginx的安装与基础配置此处略。 ●为Apollo创建一份nginx配置，示例如下： 1234567891011121314server &#123; listen 80; #注意端口占用，可以使用其他端口 expires -1; #防止缓存 location ~* \\.(html|js|css) &#123; root &quot;H:\\\\Project_work\\\\apollo\\\\apollo-portal\\\\src\\\\main\\\\resources\\\\static&quot;; #Apollo前端代码路径 &#125; location / &#123; proxy_set_header HOST $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://172.16.1.119:8088; #要连接的测试Apollo服务器地址 &#125;&#125; ●启用nginx并应用如上配置，访问地址 http:&#x2F;&#x2F;本地IP 就可以开始Apollo前端的本地调试开发了。"},{"title":"superset前端本地开发环境搭建","date":"2019-05-10T11:07:51.000Z","path":"handbook/superset前端本地开发环境搭建.html","tags":[{"name":"前端","slug":"前端","permalink":"https://congzhou09.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"开发环境","slug":"开发环境","permalink":"https://congzhou09.github.io/tags/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/"},{"name":"superset","slug":"superset","permalink":"https://congzhou09.github.io/tags/superset/"}],"text":"项目结构superset项目包含前端后台部分，前端部分位于路径“&#x2F;superset&#x2F;assets”下。 安装npm依赖包命令行进入assets目录下，执行npm install(或更快的yarn install)。 修改webpack配置修改webpack配置文件“superset&#x2F;assets&#x2F;webpack.config.js”，其中的proxy改为联调后台服务器的地址，例如服务器ip地址为172.16.2.249，则写为如下形式： 12345proxy: &#123; context: () =&gt; true, &#x27;/&#x27;: `http://172.16.1.119:$&#123;supersetPort&#125;`, target: `http://172.16.1.119:$&#123;supersetPort&#125;`, &#125;, 启动本地调试在assets目录下命令行执行：npm run dev-server windows环境下webpack打包windows下执行“npm run build”报错&quot;无法识别NODE_ENV&quot;，解决办法：安装&quot;cross-env&quot;之后，重新执行“npm run build”，即可正常生成打包文件在dist文件夹中 2020年9月补充●后来开发中发现这样配置之后前端收到的网页内容仍然是从服务器返回的，此方式未被使用；●superset项目新版本已经明确前后端分离并在文档中给出了前端独立调试的方法；"},{"title":"ajax获取与操作图片二进制流并显示","date":"2019-03-21T11:48:19.000Z","path":"practice/ajax获取与操作图片二进制流并显示.html","tags":[{"name":"二进制流","slug":"二进制流","permalink":"https://congzhou09.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%B5%81/"},{"name":"位操作","slug":"位操作","permalink":"https://congzhou09.github.io/tags/%E4%BD%8D%E6%93%8D%E4%BD%9C/"}],"text":"场景为保护用户隐私，图片上传至服务器后服务器做了按位异或处理，达到无法直接通过图片链接或图片文件查看用户所上传图片内容的目的。如此就要求前端展示时对图片二进制流做相反的位操作才能展示图片内容。 关键代码与注释此处用原生方式书写，实际应用时根据所使用 ajax 库的语法修改 123456789101112131415161718192021const request = new XMLHttpRequest();//构造get方法用于异步请求图片链接request.open(&#x27;get&#x27;, &quot;/img/encripted.jpg&quot;, true);//以arraybuffer的类型解析服务器返回数据request.responseType = &#x27;arraybuffer&#x27;;//得到服务器数据后的回调函数request.onload = function()&#123; const data = request.response; //使用DataView遍历与操作二进制流 let bufferReader = new DataView(data); let bufferStr = &#x27;&#x27;; //以每8位为一组，每组按照无符号整数解析成字符串 for(let i=0;i&lt;bufferReader.byteLength;i++) &#123; //假设服务器做的是按位与100做异或处理，则此处再做一次异或处理即可将数据恢复 bufferStr += String.fromCharCode(bufferReader.getUint8(i) ^ 100); &#125; //将字符串转为Base64编码格式，使用Base64图片格式展示图片数据内容 $(&#x27;#the-img&#x27;).attr(&#x27;src&#x27;, `data:image/png;base64, $&#123;window.btoa(bufferStr)&#125;`);&#125;;request.send(); 关键技术点解析指定 ajax 请求的返回数据类型◎ ajax 请求的 responseType 参数指定将以哪种数据类型的数据结构解析服务器返回数据，进而使用数据类型提供的对应函数对数据进行读取或写入操作，可取值及含义可参考MDN web doc 之 XMLHttpRequest.responseType。 处理二进制数据◎ 处理二进制数据需要先将原始二进制数据存放在一段连续的内存区域中，ArrayBuffer 对象就是用来映射一段通用的、固定长度的内存缓冲区的，通过 ArrayBuffer 的 byteLength 属性可得到缓冲区的字节数，但它未提供直接按字节操作缓冲区的函数，按字节操作需要通过 类型数组对象 或 DataView 对象 进行。 使用“类型数组对象”◎ 类型数组对象包含以下几种类型 以 Int8Array 为例，基础用法如下： 123456789101112//arraybuffer缓冲区let buffer = new ArrayBuffer(8);//以int8Array类型解析缓冲区，即以每8位作为一个单位，每个单位用8位二进制有符号整数解析let int8Array1 = new Int8Array(buffer);//输出字节长度8，这个字节长度不会随着解析类型不同而变化console.log(int8Array2.byteLength);//以30的有符号整数的二进制(即二进制序列:00011110)填充缓冲区的前8位int8Array1[0] = 30;//int8Array2解析同样的缓冲区let int8Array2 = new Int8Array(buffer);// 输出30 说明缓冲区已经被int8Array1修改console.log(int8Array2[0]); 使用“DataView 对象”◎ DataView 通过一系列 get 和 set 方法（set 和 get 后接类型数组对象的类型名，如 setUint8）读取或写入缓冲区。基础用法如下： 12345678910//arraybuffer缓冲区let buffer = new ArrayBuffer(8);//以DataView解析缓冲区let bufferReader = new DataView(buffer);//输出字节长度8，这个字节长度不会随着解析类型不同而变化console.log(bufferReader.byteLength);//以30的有符号整数的二进制(即二进制序列:00011110)填充缓冲区的前8位bufferReader.setInt8(0, 30);// 输出30 缓冲区已经被bufferReader修改console.log(bufferReader.getInt8(0)); 对二进制数据的字符编码◎ String 的静态方法&quot;fromCharCode&quot;接受一个 Unicode 值参数，返回这个 Unicode 值对应的字符。◎ Base64 是一种基于 64 个可打印字符表示二进制数据的方法，转换过程中每 6 位为一组，详情整理在这篇。◎ WindowOrWorkerGlobalScope.btoa()用于从 String 对象创建一个 Base64 编码的 ASCII 字符串，转换过程中字符串里的每个字符都被视为一个二进制数据字节。"},{"title":"Docker部署前端项目","date":"2019-03-01T11:25:56.000Z","path":"practice/Docker部署前端项目.html","tags":[{"name":"Docker","slug":"Docker","permalink":"https://congzhou09.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"https://congzhou09.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"前端项目","slug":"前端项目","permalink":"https://congzhou09.github.io/tags/%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE/"},{"name":"web","slug":"web","permalink":"https://congzhou09.github.io/tags/web/"}],"text":"对于“通过 nginx 访问网站资源文件”形式的前端项目，有以下三种方式将项目部署到 Docker 容器。 资源文件拷贝到容器方式◊ 假设前端发布压缩包&quot;dist.tar.gz&quot;内部结构是 dist 文件夹-&gt;index.htnl&amp;static 文件夹。◊ 发布包同目录下创建 nginx 配置文件&quot;default.conf&quot;，例： 123456789101112131415server &#123; listen 80 default_server; location / &#123; root /usr/share/nginx/html/dist; index index.html; try_files $uri $uri/ /index.html = 404; &#125; location ~* \\.(js|css|ttf|png)$ &#123; root /usr/share/nginx/html/dist; add_header Cache-Control &quot;public, max-age=31536000, immutable&quot;; add_header Vary Accept-Encoding; &#125;&#125; ◊ 发布包同目录下创建 Dockerfile，内容示例如下，其中的 dist.tar.gz 文件 Docker 会自动做解压，如果是文件夹 dist，注意 Docker 将只拷贝 dist 文件夹内部的内容。 12345FROM nginx:latestLABEL maintainer &quot;Congzhou&quot;ADD dist.tar.gz /usr/share/nginx/htmlADD default.conf /etc/nginx/conf.dEXPOSE 80 ◊ 构建镜像：docker build -t imageName . 。◊ 运行测试镜像：docker run -p 4000:80 imageName --name containerName ;◊ 浏览器访问 ip:4000; 本地目录挂载到容器方式● 运行测试镜像：docker run -p 4000:80 -v &#x2F;home&#x2F;docker_congzhou&#x2F;my_project&#x2F;nginx_conf:&#x2F;etc&#x2F;nginx&#x2F;conf.d -v &#x2F;home&#x2F;docker_congzhou&#x2F;my_project&#x2F;nginx_file:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html nginx --name containerName ;● 浏览器访问 ip:4000;● 通过 docker 的卷(volume)机制实现将宿主机上的本地目录挂载到容器，这样所做的修改不会随着容器重启而丢失，且在宿主机对应的 Volume 挂载目录下做修改将在容器中生效。 使用数据容器的方式◆ 创建包含指定目录挂载的数据容器 1docker create -v /home/docker_congzhou/my_project/nginx_conf:/etc/nginx/conf.d -v /home/docker_congzhou/my_project/nginx_file:/usr/share/nginx/html --name project_data nginx ◆ docker run --rm -p 80:80 --volumes-from project_data nginx 三种方式比较◇ 资源文件拷贝到容器方式 缺点（1）运行多个 container 时每个 container 内都有一份资源。（2）由于 docker 容器每次重启都是一个新的环境，在 docker 容器内做的修改将被还原，当需要修改 nginx 配置文件或静态资源时需要重新构建镜像。 优点（1）通过命令行自动化操作，利于集成到 CI&#x2F;CD 流程，更方便地完成滚动更新、服务器迁移、回滚等操作。 ◇ 本地目录挂载到容器和使用数据容器的方式优缺点与以上相反。"},{"title":"Docker常用命令","date":"2019-02-02T02:05:12.000Z","path":"handbook/Docker常用命令.html","tags":[{"name":"Docker","slug":"Docker","permalink":"https://congzhou09.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"https://congzhou09.github.io/tags/%E5%AE%B9%E5%99%A8/"}],"text":"● 查看 docker 版本：docker --version● 查看 docker 详细状态：docker info● 查看本地 image（1）查看可用的：docker image ls（2）查看所有的：docker image ls -a● 运行 image：docker run options imageName（1）其中的 options 可取值如下 123456◇ 后台运行（detached mode），添加“-d”参数，将返回容器ID。◇ 通过“-p”参数实现端口映射，例：“-p 4000:80”将容器的80端口映射到主机的4000端口，省略参数默认将容器的80端口映射到主机随机端口。◇ -i: 以交互模式运行容器，通常与 -t 同时使用。◇ -t: 为容器重新分配一个伪输入终端，通常与 -i 同时使用。◇ --name： 为容器指定一个名字。◇ --rm：容器退出时自动删除容器及其文件系统，注意不能与-d同时使用，即只能自动清理foreground容器，注意：如果Dockerfile中包含VOLUME语句则一定要带上此参数。 ● 进入 container 环境 1sudo docker exec -it containerID /bin/bash ● 退出 container 环境：按&quot;ctrl+q&quot;快捷键。● 删除 image（1）删除某个：docker image rm imageID（2）删除本机所有 image：docker image rm $(docker image ls -a -q)（3）删除未被使用的 image（dangling image）：docker image prune● 查看正在运行的 container 实例及状态：（1）docker container ls 或 docker ps。（2）同时列举未在运行的实例则增加&quot;--all&quot;(可简写为“-a”)参数。（3）添加“-q”参数则只列出 container 的 ID。● 优雅地结束正在运行的 image：docker conatiner stop ContainerName_or_ContainerID● 强制结束正在运行的 image：docker conatiner kill ContainerName_or_ContainerID● 删除容器：（1）删除某个：docker container rm ContainerName_or_ContainerID（2）删除本机所有容器：docker container rm $(docker container ls -a -q)（3）删除本机所有未运行的容器：docker container prune● 组建 swarm（1）为当前机器开启 swarm 模式将其设置为 swarm manager：docker swarm init（2）将其他机器加入 swarmdocker swarm join● 进入容器的 bash 命令行：docker exec -it containerName_or_conatinerID bash● 查看所有 service 的状态（1）docker service ls ，输出示例如下 （2）docker stack services stackName ，输出与 stackname 关联的所有 service 的状态。● 查看 service 中的所有 task：docker service ps serviceName 。● 查看 task 中的所有 task：docker stack ps stackName 。● 停止应用(stack)：docker stack rm stackName 。"},{"title":"Docker知识整理","date":"2018-12-21T03:18:08.000Z","path":"knowledge/Docker知识整理.html","tags":[{"name":"Docker","slug":"Docker","permalink":"https://congzhou09.github.io/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"https://congzhou09.github.io/tags/%E5%AE%B9%E5%99%A8/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://congzhou09.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}],"text":"通识○ 容器与虚拟机的区别（1）虚拟机在 Hypervisior 之上虚拟出一套完整操作系统，提供的资源通常超过大部分应用所需。（2）容器在 Docker Engine 之上仅虚拟出一个应用程序运行所需的基础操作系统环境，这个环境以独立原生进程的方式运行在 Linux，有自己隔离的运行环境，但又与其他进程和容器共享主机内核，除了运行应用程序之外基本不消耗额外的系统资源，比虚拟机方式更轻量。 ○ Docker CE，即 Docker Community Edition，用于开发人员和小团队熟悉 Docker 和试验基于容器的 app。○Docker EE，即 Docker Enterprise Edition，面向企业级关键应用。○EE 是 CE 的超集，代码仓库层面，CE 位于 EE 的上游，CE 在发布后提供 7 个月支持，EE 提供 24 个月。○ 三种类型的 release 包：stable(稳定版，版本号如 stable-18.09)、test(稳定版发布前的测试版，版本号如 test-18.09)、nightly(又名 edge 版，是当前最新版，版本号如 0.0.0-20180720214833-f61e0f7)，每次稳定版同时发布 CE 和 EE。○Docker 是个用于通过容器技术开发、部署和运行应用的平台，Linux 中的容器是之前已有的概念，使用容器部署应用是新的东西，使用 Linux 的容器部署应用称为“容器化”。○ 容器化优点：（1）容器是互相隔离的进程，直接运行在 Linux 之上，并不比普通进程占用更多内存，是轻量的，多个容器可共享主机资源。（2）支持热更新部署。（3）根据需要灵活增减容器的数量。○ 镜像(image)是包含运行一个应用的所有必需内容(包括库、环境、配置文件)的 package。○ 镜像通过 Dockerfile 来定义。○ 容器(container)是镜像的运行实例，通过命令“docker ps”查看正在运行的容器。○Docker 模式运行的应用在架构上自底向上包含三层：Swarm(非必须)、Container、Services、Stack（1）运行 Docker 应用的主机集群(cluster)称为“swarm”，通过在机器上运行 Docker 并(可以是物理机或虚拟机)加入 swarm，一个 docker 应用可部署在 swarm 集群上，运行于多台机器。swarm 中的一台机器称为一个节点(node)。（2）swarm 集群中有一台机器作为 swarm manager，在 swarm manager 执行运行于 swarm 上的 docker 命令或授权其他机器作为 worker 加入当前 swarm。（3）container 是一个运行的 image。（4）分布式应用的不同组成部分称为 service，Docker 模式下，每个 service 包含运行自同一个 image 的一个或多个 container，service 同时定义了如何编排这些 container 以实现 service 的整体行为表现，service 内每个 container 称为 task。（5）stack 用于定义多个 service 的行为。（6）service 通过 compose 文件编排 container 的行为，而同一个 compose 文件中可以配置多个 service，这几个 service 组成一个 stack，这个 compose 文件也就成了编排 stack 行为的文件。○ 一个 Docker 应用运行所需环境无须安装到宿主系统，只需要引入所需环境的镜像。○repository 和 registry（1）repository：是镜像的集合，类似项目代码已经被编译好的 GitHub 项目。（2）registry：是 repository 的集合。registry 上的每个账号可以创建多个 repository，docker 命令行默认使用 public registry（3）DTR(Docker Trusted Registry)：是支持安装在防火墙之后的企业级 registry，可以作为持续集成的一部分，提供 web 访问的方式管理镜像。 Dockerfile●Dockfile 是一种被 Docker 程序解释的脚本，Dockerfile 由一条一条的指令组成，每条指令对应 Linux 下面的一条命令。●Dockerfile 有自己书写格式和支持的命令，Docker 程序解决这些命令间的依赖关系，类似于 Makefile，根据指令生成定制的 image。● 指令忽略大小写，建议使用大写。每一行只支持一条指令，每条指令可以携带多个参数。● 指令分为两种：构建指令和设置指令。●构建指令用于构建镜像，其指定的操作不会在容器上执行。（1）ADD 与 COPY 用于把文件拷贝到容器，区别是：ADD 指令包含类似 tar 的解压功能，而 COPY 只是单纯复制文件。●设置指令用于设置 image 的属性，其指定的操作将在容器上执行。● 实例： 12345678# FROM 指令用于指定基础镜像FROM nginx:latest# LABEL 指令为构建的镜像设置作者信息LABEL maintainer &quot;Congzhou&quot;VOLUME [&quot;/home/docker_congzhou/my_project/agt_jinzhong/nginx_conf&quot;,&quot;/etc/nginx/conf.d&quot;]VOLUME [&quot;/home/docker_congzhou/my_project/agt_jinzhong/nginx_file/&quot;,&quot;/usr/share/nginx/html&quot;]# EXPOSE 指令声明运行时容器提供的服务端口。EXPOSE 80 Volume○Docker 的文件系统称为 Union File System(联合文件系统)，自底向上包括只读层和读写层，当在运行中的容器修改一个文件时，会将文件从只读层复制读写层，只读层的文件仍然存在且是未修改状态。○ 默认情况下容器内的数据只存在于容器的生命周期内，随着容器的删除而删除。○Volume 的目的是为了能够保存（持久化）数据以及共享容器间的数据，从而删除容器时不会自动删除容器对应的 volume 数据。○Volume 是绕过默认联合文件系统的目录或者文件，以正常的文件或者目录的形式存在于宿主机上，宿主机和容器访问的是同一个文件夹，宿主或容器内做的修改也将在对面生效。○ 设置 Volume 有两种方式：（1）运行时使用&quot;-v&quot;参数（2）在 Dockerfile 中通过使用 VOLUME 指令。○ 运行时使用-v 参数（1）将 docker 某目录挂载到宿主机，例： 123docker run -p 80:80 -v /data nginx:latest #将容器的&quot;/data&quot;目录挂载到宿主机某目录(具体目录由docker分配)#具体宿主机目录使用如下命令查看，输出结果中的Mounts-&gt;Source和Mounts-&gt;Destination列举了目录映射关系docker inspect containerName #可见其中将容器的“/data”目录挂载代理宿主机“/var/lib/docker/volumes/4e..../_data”目录 （2）将 docker 某目录挂载到宿主机的指定某目录，例： 1docker run -p 80:80 -v /home/docker_data:/data nginx:latest #将宿主机的&quot;/home/docker_data&quot;目录挂载到docker的&quot;/data&quot;目录 ○Dockerfile 中使用 VOLUME 指令，示例如下，此方式不支持将 docker 目录挂载到宿主机的指定目录。这种方式不推荐，容易启动 image 时忘记添加&quot;-rm&quot;参数导致 container 退出后在宿主机上对应的 volume 目录未做销毁处理，进而随着多次启动产生大量垃圾文件。 12FROM nginx:latestVOLUME /data ○ 查看所有的 volume： docker volume ls○ 批量删除孤单 volume： docker volume rm $(docker volume ls -qf dangling&#x3D;true)○ 常见的使用场景是使用纯数据容器（data container）来持久化数据库、配置文件或者数据文件等（1）创建数据容器，例：docker create -v &#x2F;data --name data_container ubuntu ，从 ubuntu（用与应用数据的容器相同的 image）创建名为 data 的数据容器，将宿主机的某目录(具体目录由 docker 分配)挂载在到容器中的&#x2F;data 目录。（2）通过 docker run 的“--volumes-from”参数使用数据容器的配置完成目录的挂载，例：docker run --name work_container --volumes-from data_container ubuntu。"},{"title":"虚拟机技术知识整理","date":"2018-12-11T10:49:56.000Z","path":"knowledge/虚拟机技术知识整理.html","tags":[{"name":"虚拟化","slug":"虚拟化","permalink":"https://congzhou09.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"虚拟机","slug":"虚拟机","permalink":"https://congzhou09.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"}],"text":"概念● 虚拟化技术目前分为“基于虚拟机”和“基于容器”两种，前者已经有数十年成熟历史，本文讨论前者。● 虚拟机又分为两种，一种是直接安装在裸机上，另一种是安装在操作系统上。（1）裸机上的虚拟机，虚拟化层（图中的虚拟化软件）直接运行在系统硬件上，创建硬件全仿真实例，被称为“裸机”，也称为“裸金属架构”，如下图。 （2）操作系统上的虚拟机，虚拟化层（图中的虚拟化软件）运行在传统操作系统之上，同样创建的是硬件全仿真实例，被称为“托管”，也称为“宿主架构”，如下图。虚拟机中应用程序调用硬件资源时需要经过：虚拟机操作系统内核-&gt;虚拟化软件的 Hypervisor-&gt;宿主机操作系统内核 ，导致性能是三种虚拟化技术中最差的。 ● 虚拟化软件的核心是 Hypervisor，也叫虚拟机监视器（Virtual Machine Monitor，简称 VMM），它是运行在硬件(物理硬件或虚拟硬件)和操作系统之间的中间软件层，可允许多个操作系统和应用共享一套基础硬件，可以将其看作是虚拟环境中的“元操作系统”，由它协调虚拟机访问所有硬件。 常见示例◆ 常见的裸金属型（裸机型）（1）VMware vSphere，其核心是 ESX（新产品称 ESXi），ESX 的 hypervisor 组件称为 VMKernel，VMkernel 会从 LinuxKernel 完全接管对硬件的控制权，而该 Linux Kernel 作为 VMkernel 的首个虚拟机，用于承载 ESX 的 serviceConsole，实现本地的一些管理功能。vSphere 虚拟机与物理机架构对比如下： 物理机架构 vSphere 虚拟机架构 ESX 架构 （2）Microsoft Hyper-V，有独立版(如 Hyper-V Server 2008)和内嵌版(如 Windows Server 2008)两种发布版本。（3）Xen，由剑桥大学开发，开放源代码的虚拟机，支持更广泛的 CPU 架构，前两者只支持 CISC 的 X86&#x2F;X86_64 CPU 架构，XEN 除此之外还支持 RISC CPU 架构，如 IA64、ARM 等。（4）KVM（Kernel-based Virtual Machine），字面意思是基于内核的虚拟机，它利用了 CPU 的硬件辅助虚拟化能力，并重用了 Linux 内核的诸多功能，使得 KVM 本身是非常瘦小，从严格意义来说，KVM 本身并不是 Hypervisor，它仅是 Linux 内核中的一个可装载模块，其功能是将 Linux 内核转换成一个裸金属的 Hypervisor。这相对于其它裸金属架构来说是非常特别的，有些类似于宿主架构，有人称其是“半裸金属架构”。一个普通的 linux 进程有两种运行模式：内核和用户， KVM 增加了第三 种模式：客户模式（有自己的内核模式和用户模式），这使得 Linux 内核可以将主机进程和虚拟机进行统一的管理和调度。KVM 与 Xen 一样支持非 X86 CPU 架构。 ◆ 常见的宿主型（主机型）：（1）VMware Server，可运行在 Windows 和 Linux 上。（2）VMware Workstation，运行在 Windows 和 Linux 上。（3）Fusion，只能运行在苹果的 Mac OS 上。"},{"title":"真正实现elment.ui的按需引入","date":"2018-09-14T02:03:24.000Z","path":"practice/真正实现elment-ui的按需引入.html","tags":[{"name":"webpack","slug":"webpack","permalink":"https://congzhou09.github.io/tags/webpack/"},{"name":"按需加载","slug":"按需加载","permalink":"https://congzhou09.github.io/tags/%E6%8C%89%E9%9C%80%E5%8A%A0%E8%BD%BD/"},{"name":"vue","slug":"vue","permalink":"https://congzhou09.github.io/tags/vue/"},{"name":"elment.ui","slug":"elment-ui","permalink":"https://congzhou09.github.io/tags/elment-ui/"}],"text":"element.ui官网文档给出的按需引入组件的说明，属于是在main.js中为Vue注册全局组件的方式，某页面即使不使用某组件也会在打包代码中包含它，如果希望某个组件仅仅在单独页面里按需引入，则可以使用本文方法。 官方方法官方方法分两步：（1）安装babel-plugin-component，修改“.babelrc”文件内容；（经验证此步骤不再需要，环境：webpack-4.18.0、vue-2.5.17，由于webpack2之后import原生支持ES6所以未使用babel）（2）在 main.js 中单独import组件并注册为全局组件，示例如下： 12345678910111213141516/****************main.js******************/import Vue from &#x27;vue&#x27;;import &#123; Button, Select &#125; from &#x27;element-ui&#x27;;import App from &#x27;./App.vue&#x27;;Vue.component(Button.name, Button);Vue.component(Select.name, Select);/* 或写为 * Vue.use(Button) * Vue.use(Select) */new Vue(&#123; el: &#x27;#app&#x27;, render: h =&gt; h(App)&#125;); 真正按需引入的方法思路就是把引用和注册组件的操作转在vue页面内进行，以局部注册Button为例： 1234567891011121314151617181920212223/****************onePage.vue******************/&lt;template&gt; &lt;div class=&quot;container&quot;&gt; &lt;el-button&gt;默认按钮&lt;/el-button&gt; &lt;/div&gt;&lt;/template&gt;&lt;script type=&quot;text/ecmascript-6&quot;&gt; import &#123; Button &#125; from &#x27;element-ui&#x27;; export default&#123; data()&#123; return &#123; //balaba &#125;; &#125;, components:&#123; ElButton: Button &#125; &#125;&lt;/script&gt;&lt;style rel=&quot;stylesheet/scss&quot; lang=&quot;scss&quot; scoped&gt;&lt;/style&gt; 注意components那里不要简写成“Button”，因为组件名字是“ElButton”而不是同名的“Button”所以不能简写。这里的“ElButton”其实就是官网方法中的“Button.name”的值，我是通过调试知道的。目前用过的组件name都是前面加上“El”前缀，如果某个组件注册失败则需要调试或element-ui源码中查找其真实的name值。或者使用如下通用但不美观的写法： 1234567891011121314&lt;script type=&quot;text/ecmascript-6&quot;&gt; import &#123; Button &#125; from &#x27;element-ui&#x27;; let exportObj = &#123; data()&#123; return &#123; //balaba &#125;; &#125; &#125;; exportObj.components = &#123;&#125;; exportObj.components[Button.name] = Button; export default exportObj;&lt;/script&gt;"},{"title":"钉钉微应用开发环境搭建","date":"2018-08-21T03:11:05.000Z","path":"handbook/钉钉微应用开发环境搭建.html","tags":[{"name":"钉钉","slug":"钉钉","permalink":"https://congzhou09.github.io/tags/%E9%92%89%E9%92%89/"}],"text":"创建微应用◇在钉钉开放平台中创建微应用，服务器出口IP填写为当前所用网络的公网出口IP；◇如果微应用要支持PC端访问则也填写&quot;PC端首页地址&quot;； 配置首页地址●启动本地开发环境服务器，以地址 &quot;http://192.168.1.10:8080&quot; 为例；●首页地址有使用穿透工具与不使用穿透工具两种方式； 使用穿透工具●使用钉钉提供的内网穿透工具执行如下格式的命令： 1ding -config=./ding.cfg -subdomain=congzhou 8080 ●以上命令执行后打印信息示例如下，表示将将公网域映射到本地成功； 12345678910ngrokTunnel Status onlineVersion 1.7/1.7Forwarding http://congzhou.vaiwan.com:8081 -&gt; 127.0.0.1:8080Forwarding https://congzhou.vaiwan.com:8081 -&gt; 127.0.0.1:8080Web Interface 127.0.0.1:4040# Conn 434Avg Conn Time 47277.91ms ●此时通过控制台中显示的网址 &quot;http://congzhou.vaiwan.com&quot; （注意不要带端口号）就可以访问到本地的 &quot;http://192.168.1.10:8080&quot; ，将网址配置到&quot;首页地址&quot;项即可在微应用中访问； 不使用穿透工具□后来发现不使用穿透工具而直接填写本地地址 &quot;http://192.168.1.10:8080&quot; 也是可以访问的(今天2020年10月21日仍可以)，只要访问终端与开发环境处于同一个局域网； 调试■安装钉钉RC版客户端，并在OA工作台打开微应用页面，然后在浏览器中访问 &quot;http://localhost:16888&quot; ，即可调试当前打开的微应用页面；■上述调试方式目前已不可用(今天2020年10月21日仍不可用)，浏览器控制台报错“inspector.js:2978 document.registerElement is not a function”，只好改用VConsole与Eruda之类调试面板了，推荐一个更方便地隐藏与显示调试面板的工具库：click-password；"},{"title":"使用talkingdata在web项目中采集数据","date":"2018-08-02T02:52:54.000Z","path":"handbook/使用talkingdata在web项目中采集数据.html","tags":[{"name":"talkingdata","slug":"talkingdata","permalink":"https://congzhou09.github.io/tags/talkingdata/"}],"text":"Web项目中使用talkingdata的&quot;游戏运营分析&quot;步骤如下：◆登录系统，进入“GameAnalytics游戏运营分析”； 图1 \"游戏运营分析\"入口 ◆创建产品，得到App Id ； 图2 填写产品信息完成创建，得到App Id ◆web页面中添加script标签； 1234//对于普通的http连接网站，使用的调用地址：&lt;script src=&quot;http://sdk.talkingdata.com/g/h5/v1/您的APPID&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;//如果您的网站使用https连接，请使用以下地址：&lt;script src=&quot;https://h5.talkingdata.com/g/h5/v1/您的APPID&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; ◆调用如下两个函数，完成调试与数据统计； 12345678//标识账户TDGA.Account(&#123; accountId: 标识账户的ID&#125;);//标识事件TDGA.onEvent(&#x27;事件名称&#x27;, &#123; 事件参数: 事件参数值&#125;);"},{"title":"JS的继承","date":"2018-05-09T01:42:09.000Z","path":"knowledge/js的继承.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://congzhou09.github.io/tags/javascript/"}],"text":"要点● 在 ES6 之前，类以及类的继承机制没有明确定义，通过模仿来实现，以下内容针对 ES6 之前场景。● 从 ES6 开始，类和继承有了定义，分别通过 class 和 extends 实现。● Babel 对于 class 和 extends 向 ES6 之前的转译，使用的就是以下内容中“寄生组合式继承”的方式。 对象冒充(object masquerading)■&quot;对象冒充&quot;也称为&quot;借用构造函数&quot;，通过以子类构造函数的上下文执行父类构造函数来实现，例： 1234567891011121314function ClassA(color) &#123; this.color = color; this.sayColor = function () &#123; alert(this.color); &#125;;&#125;function ClassB(color, name) &#123; ClassA.call(this, color); this.name = name; this.sayName = function () &#123; alert(this.name); &#125;;&#125; ■ 缺点：（1）只能继承父类构造函数中的定义。（2）父类构造函数中定义的方法在每次子类实例化的时候也会被创建一遍。 原型链(prototype chaining)■ 原型链方式通过将父类实例赋值给子类构造函数的 prototype 实现。■ 实例： 123456789101112131415161718192021222324function ClassA(color) &#123; this.color = color; this.colorArr = [color];&#125;ClassA.prototype.sayColor = function () &#123; alert(this.color);&#125;;function ClassB() &#123; this.name = &quot;&quot;;&#125;ClassB.prototype = new ClassA(&#x27;white&#x27;); // 所有ClassB实例的__proto__都指向这个ClassA的实例ClassB.prototype.constructor = ClassB; // 手动指定constructor属性值ClassB.prototype.sayName = function () &#123; alert(this.name);&#125;;var objOne = new ClassB();var objTwo = new ClassB();objOne.color = &#x27;red&#x27;; // 将创建objOne自己的‘color’属性而不会改变原型链中的colorobjOne.colorArr.push(&#x27;red&#x27;);console.log(`color: $&#123;objOne.color&#125;, colorArr: $&#123;objOne.colorArr&#125;`);// 打印 color: red, colorArr: white,redconsole.log(`color: $&#123;objTwo.color&#125;, colorArr: $&#123;objTwo.colorArr&#125;`);// 打印 color: white, colorArr: white,red ■ 缺点：（1）在子类实例化的时候无法给父类构造函数传递参数。（2）由于所有子类实例的[[Prototype]]共享同一个父类实例，改写父类中引用类型的成员变量将造成相互污染（非引用类型变量没有这个问题，因为会在子类实例上创建新属性）。 组合继承（对象冒充 + 原型链）■ 组合继承是对象冒充方法与原型链方法的结合，融合了两种方法的优点：（1）通过原型链继承原型的属性和方法，实现方法与共享属性的复用。（2）通过对象冒充继承实例的属性，保证每个实例都有自己的属性。■ 例： 1234567891011121314151617function ClassA(color) &#123; this.color = color; this.colorArr = [color];&#125;ClassA.prototype.sayColor = function () &#123; alert(this.color);&#125;;function ClassB(color, name) &#123; ClassA.call(this, color); this.name = name;&#125;ClassB.prototype = new ClassA();ClassB.prototype.constructor = ClassB;ClassB.prototype.sayName = function () &#123; alert(this.name);&#125;; ■ 一点瑕疵：父类的构造函数被调用了两次。但不能直接&quot;ClassB.prototype &#x3D; ClassA.prototype&quot;，因为会导致子类修改 prototype 也修改了父类的 prototype;■ 解决构造函数被调用两次的问题之前先了解“原型式继承”与“寄生式继承”。■ 原型式继承和寄生继承由道格拉斯·克罗克福德(Douglas Crockford，也是 JSON 的提出人)于 2006 年左右提出和推广。■ 原型式继承和寄生继承没有使用严格意义上的构造函数，也没有创建子类，而是借助原型链基于已有的一个父类实例来直接创建子类实例，提供了一种有别于传统 new 方式创建子类实例的思路。 原型式继承■ 原型式继承与原型链继承一样利用的是设置子类原型链，区别是没有显式创建子类而是直接创建子类实例并设置子类实例的[[Prototype]]为父类实例，具体体现在如下的 createObj 函数。■ 不关心父类实例是如何被创建的，通过直接将父类实例放在子类实例的原型链上的方式达到父类也处于子类实例的原型链上的目的，例： 1234567891011121314151617181920212223function ClassA(color) &#123; this.color = color; this.colorArr = [color];&#125;ClassA.prototype.sayColor = function () &#123; alert(this.color);&#125;;var oneObjA = new ClassA(&#x27;white&#x27;);function createObj(o) &#123; //此过程被ES5新增的Object.create()方法实现 function F()&#123;&#125; F.prototype = o; // 相当于原型链继承中的“ClassB.prototype = new ClassA()” return new F();&#125;var oneObjB = createObj(oneObjA);var anotherObjB = Object.create(oneObjA);console.log(oneObjB instanceof ClassA);// trueconsole.log(anotherObjB instanceof ClassA);// trueoneObjB.colorArr.push(&#x27;red&#x27;);console.log(anotherObjB.colorArr); // [&quot;white&quot;, &quot;red&quot;]，原型链上的共享属性 寄生式(parasitic)继承■ 寄生式继承是对原型式继承的进一步封装与扩展。思路是实现一个函数，在函数内通过原型式继承创建新对象，并对这个新对象进行增强(增加自定义属性)，最后返回这个新对象，实例： 1234567function createObj2 (o) &#123; var clone = createObj(o); // 创建新对象继承父类 clone.sayName = function () &#123; // 增强新对象 console.log(&#x27;hi&#x27;); &#125; return clone; // 返回这个新对象&#125; 寄生组合式继承（对象冒充 + 寄生）■ 将父类的 prototype 作为被继承实例，通过寄生式继承实现子类 prototype 仅对父类 prototype 的继承，解决组合继承方式构造函数被调用两次的问题，例： 123456789101112131415161718192021222324252627function ClassA(color) &#123; this.color = color; this.colorArr = [color];&#125;ClassA.prototype.sayColor = function () &#123; alert(this.color);&#125;;function ClassB(color, name) &#123; ClassA.call(this, color); this.name = name;&#125;inheritClass(ClassB, ClassA);function inheritClass(subType, superType) &#123; var onePrototype = Object.create(superType.prototype); // 创建新对象继承父类 onePrototype.constructor = subType; // 增强新对象 subType.prototype = onePrototype;// 指定新对象&#125;;ClassB.prototype.sayName = function () &#123; alert(this.name);&#125;;var oneObjB = new ClassB(&#x27;red&#x27;, &#x27;rose&#x27;);oneObjB.sayName();oneObjB.sayColor();"},{"title":"通过babel搭建可使用async/await的Node.js运行环境","date":"2018-03-22T08:03:06.000Z","path":"practice/通过babel搭建可使用async、await的Node.js运行环境.html","tags":[{"name":"Node.js","slug":"Node-js","permalink":"https://congzhou09.github.io/tags/Node-js/"}],"text":"Node.js 版本7以下 原生不支持ES6的async&#x2F;await写法，通过bebel的runtime实时翻译实现async&#x2F;await写法的支持，在Node.js-v6.11.0的express项目下亲测可用。 ps: koa官网首页&quot;Async Functions with Babel&quot;小节也有介绍 具体步骤如下： ●安装&quot;babel-core&quot; 1npm install --save babel-core ●安装&quot;babel-preset-env&quot;、&quot;babel-runtime&quot; 12npm install --save babel-preset-envnpm install --save babel-runtime ●项目根目录下创建&quot;.babelrc&quot;文件，内容如下 123456789101112131415161718192021&#123; &quot;presets&quot;: [ [ &quot;env&quot;, &#123; &quot;target&quot;: &#123; &quot;node&quot;: &quot;current&quot; &#125; &#125; ] ], &quot;plugins&quot;: [ [ &quot;transform-runtime&quot;, &#123; &quot;polyfill&quot;: false, &quot;regenerator&quot;: true &#125; ] ] &#125; ●项目根目录下创建启动文件&quot;index.js&quot;，内容如下，其中的&quot;app.js&quot;是项目本来的启动文件 12345require(&#x27;babel-core/register&#x27;);require(&#x27;./app.js&#x27;);require(&quot;babel-core&quot;).transform(&quot;code&quot;, &#123; plugins: [&quot;transform-runtime&quot;]&#125;);"},{"title":"JS的原型链、new、constructor、instanceof","date":"2018-03-07T11:51:05.000Z","path":"knowledge/js的原型链、new、constructor、instanceof.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://congzhou09.github.io/tags/javascript/"}],"text":"原型链□ JS 中，每个对象（包括内部对象、宿主对象、自定义对象，以及原始类型值自动转成的包装对象）都有一个[[Prototype]]内部属性，为了表示特性是内部值，用两个方括号加以区分。当访问一个对象的属性时，如果这个属性不存在，则会去对象的[[Prototype]]中找这个属性，而这个[[Prototype]]的取值也可以是个对象并也拥有[[Prototype]]属性，可以继续在其中查找属性，此机制称为原型链(prototype chain)。□ Firefox、Safari、Chrome 目前都支持通过__proto__属性得到[[Prototype]]的取值，此非标准方式不被推荐于生产环境，标准方式是通过调用函数 Object.getPrototypeOf() 得到。□ 要讨论[[Prototype]]属性的取值，需要先提到 prototype 属性 ↓。 prototype 和 constructor● JS 中，每个函数不仅有[[Prototype]]属性，还都有一个 prototype 属性。● prototype 属性的取值（1）取值通常是个对象，此对象不仅有[[Prototype]]属性，还有一个 constructor 属性，constructor 的默认值是这个函数本身。（2）取值的特殊情况：Function.prototype 的取值实际也是个对象，它也有[[Prototype]]属性，也有 constructor 属性且默认值依然是 Function 函数本身但它不能作为构造函数使用，但没有 prototype 属性（即 Function.prototype.prototype &#x3D;&#x3D;&#x3D; undefined）。这个对象还特殊在它也具有函数类型的特征（如下图），这一点官方给的原因是对早期版本的兼容。 Function.prototype的特殊取值 [[Prototype]] 属性的取值◆ [[Prototype]]属性的取值通常是其所属类型的 prototype 属性值。（1）本地对象类型（如 Array、Object、Date、Function）的[[Prototype]]取值都是 Function.prototype 的值。（2）对于通过 new 构造出来的自定义对象，其所属类型就是对应的自定义类，所以其[[Prototype]]的值就是自定义类的构造函数的 prototype 属性值。 ◆ 取值的特殊情况：（1）Object.prototype.__proto__ 的值是 null，它是原型链在 [[Prototype]] 属性上的终点。（2）通过 Object.create()创建的对象，其__proto__值由传入参数决定。 1234var oneObj = Object.create(&#123;a:1&#125;);console.log(oneObj.__proto__); // &#123;a:1&#125;oneObj = Object.create(null);console.log(oneObj.__proto__); // 打印undefined 而不是null 理解实例♂ 理解实例 1 123456789101112131415161718192021var A= 19;console.log(A.__proto__);//打印Number.prototype的值，见下图1console.log(A.__proto__ === Number.prototype);//打印truevar B= &#123;&#125;;console.log(B.__proto__ === Object.prototype);//打印trueconsole.log(Array.prototype.__proto__ === Object.prototype);//打印trueconsole.log(Object.prototype.__proto__ === Object.prototype);//打印falseconsole.log(Object.prototype.__proto__);//打印nullconsole.log(Array.__proto__ === Function.prototype);//打印trueconsole.log(Object.__proto__ === Function.prototype);//打印trueconsole.log(Function.__proto__ === Function.prototype);//打印truefunction C()&#123; console.log(&quot;I am cc&quot;);&#125;console.log(C.__proto__===Function.prototype);//打印true 图1 A的__proto__属性值 ♂ 理解实例 2 1234567var Person = function () &#123; &#125;;var Programmer = function () &#123; &#125;;Programmer.prototype = new Person();var p = new Programmer();console.log(p.__proto__.__proto__ === Person.prototype); // 打印true ♂ 理解实例 3 123456789function foo()&#123; return 0;&#125;console.log(foo.prototype);//打印一个对象，对象值包含两个属性：consoturctor与__proto__，如下图2console.log(foo.prototype.constructor===foo);//打印trueconsole.log(foo.prototype.__proto__===Object.prototype)//打印trueconsole.log(foo.prototype.constructor.__proto__===Function.prototype);//打印true 图2 foo的prototype属性的取值 new○ JS 中 new 的过程分为以下三步(以语句“var obj&#x3D; new Base()”为例)：（1）var obj&#x3D;{}; &#x2F;&#x2F;创建空对象。（2）obj 的[[Prototype]]属性赋值为 Base.prototype。（3）Base.call(obj); &#x2F;&#x2F; 以 obj 作为上下文调用 Base 函数（即 Base 类的构造函数） instanceof★ &quot;A instanceof B&quot;用于判断 A 是否是 B 的实例，运算过程：首先确定 A 不是原始类型字面值（原始类型字面值的 instanceof 运算结果都是 false），然后判断 B 的 prototype 属性是否处于 A 的原型链上。★ 实例理解： 1234567891011121314151617181920212223242526272829303132333435Object instanceof Object; //true/*解析：Object.__proto__===Function.prototype，而Function.prototype.__proto__===Object.prototype，因此Object.prototype在Object的原型链上*/Function instanceof Function; //true/*解析：Function.__proto__===Function.prototype，因此Function.prototype在Function的原型链上*/Function instanceof Object; //true/*解析：Function.__proto__===Function.prototype，而Function.prototype.__proto__===Object.prototype，因此Object.prototype在Function的原型链上*/String instanceof String; //false/*解析：String.__proto__===Function.protype，而Function.prototype.__proto__===Object.prototype，然后Object.prototype.__proto__===null，因此String.prototype不在String的原型链上*/var oneNumber= 19;oneNumber instanceof Number; //falseoneNumber instanceof Object; //false/*解析：虽然oneNumber.__proto__===Number.prototype，但是原始类型字面值的instanceof返回都是false */Number.MAX_VALUE instanceof Number; //falseNaN instanceof Number; //falsevar oneString= &quot;Haha&quot;;oneString instanceof String; //false/*解析：以上都是原始类型字面值*/[2,3] instanceof Array; //true(&#123;a:2&#125;) instanceof Object; //true/*解析：非原始类型的字面值*/"},{"title":"JS对象属性的可枚举性(enumerable)","date":"2018-03-06T15:49:35.000Z","path":"knowledge/js对象属性的可枚举性.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://congzhou09.github.io/tags/javascript/"}],"text":"基本规则★ JS 对象属性的可枚举性将影响枚举(enumeration)的结果，如果属性的 enumerable 为 false，枚举时就不会取这个属性。★ 枚举方式列举：for...in、Object.entries()、Object.keys()、Object.values()、JSON.stringify()、Object.assign()、展开运算符。★ 通过常规赋值添加的属性都是可枚举的、可修改的、可删除的。★ 内部属性和内部方法（如 constructor、[[Prototype]]）默认都是不可枚举的。 分类与比较♂ Object.assign() 与 展开运算符 的枚举特性一致，取对象自身的可枚举属性，包含 Symbol 类型属性。♂ 下面的枚举方式都不包含 Symbol 类型属性。Object.getOwnPropertySymbols()用于枚举对象自身的仅 Symbol 类型属性。♂ Object.entries()、Object.values() 与 Object.keys()的枚举特性一致。♂ for...in 与 Object.keys() 的区别是：前者包含对象 继承自原型对象的 可枚举属性，而后者只包括 对象自身的 可枚举属性。♂ JSON.stringify() 读取对象自身的可枚举属性，并忽略其中类型为 Undefined、Function、Symbol 的属性，并将属性和值序列化为 JSON 字符串。♂ Object.getOwnPropertyNames() 获取对象自身的所有（包括可枚举和不可枚举）属性的名称。 配置与操作♀ Object.defineProperty()（1）用于为对象添加新属性或修改已有属性。（2）函数用法 Object.defineProperty(obj , prop , descriptor )，其中 obj 是待添加或修改属性的对象，prop 是待添加或修改的属性名称，descriptor 是一个包含对属性描述的对象。descriptor 必然是&quot;data descriptor&quot;和&quot;access descriptor&quot;两种形式中的一种。（3）&quot;data descriptor&quot;独有的属性：value（属性的值，默认为 undefined），writable（是否可写，默认为 false。不影响属性是否可被 delete。）（4）&quot;access descriptor&quot;独有的属性：get（函数返回值作为属性的值，默认为 undefined）和 set（通过调用此函数改变 get 函数的返回值，默认为 undefined）（5）&quot;data descriptor&quot;和&quot;access descriptor&quot;公有的属性：enumerable（可枚举性，默认为 false），configurable（descriptor 的类型是否可变并且属性是否可被 delete，默认为 false）。（6）使用 Object.defineProperty 配置对象已有属性的同类 descriptor 时，支持增量。♀ Object.getOwnPropertyDescriptor() 和 Object.getOwnPropertyDescriptors() 用于获取 descriptor 的内容。♀ Object.preventExtensions() 阻止对象添加新的属性，对象也不再能改变[[Prototype]]的指向。♀ Object.seal() 在 preventExtensions 的同时，也使对象所有已有属性的 configurable 为 false。♀ Object.freeze() 在 preventExtensions 的同时，也使对象所有已有属性的 configurable 和 writable 为 false。但通过&quot;access descriptor&quot;定义的属性仍然可赋值。 实例 11234567891011121314151617181920212223242526272829303132333435363738394041424344function A()&#123; this.va=1; &#125; A.prototype.vb=2; var a= new A(); Object.defineProperty(a, &quot;vc&quot;, &#123;value:3&#125;); var inArr= []; for(var para in a) &#123; inArr.push(para); &#125; console.log(Object.keys(a)); // [&quot;va&quot;] console.log(Object.getOwnPropertyNames(a)); // [&quot;va&quot;, &quot;vc&quot;] console.log(JSON.stringify(a)); // &#123;&quot;va&quot;:1&#125; console.log(inArr); // [&quot;va&quot;, &quot;vb&quot;]a[&quot;vc&quot;]= 8;console.log(a[&quot;vc&quot;]); // 3delete a[&quot;vc&quot;]; // delete将返回falseconsole.log(a[&quot;vc&quot;]); // 3Object.defineProperty(a, &quot;vd&quot;, &#123;value:4, writable: true&#125;);a[&quot;vd&quot;]= 8;console.log(a[&quot;vd&quot;]); // 8delete a[&quot;vd&quot;]; // delete将返回falseconsole.log(a[&quot;vd&quot;]); // 8Object.defineProperty(a, &quot;ve&quot;, &#123;value:4, configurable: true&#125;);a[&quot;ve&quot;] = 2;console.log(a[&quot;ve&quot;]); // 4Object.defineProperty(a, &quot;ve&quot;, &#123;writable:true&#125;);console.log(a[&quot;ve&quot;]); // 4a[&quot;ve&quot;] = 2;console.log(a[&quot;ve&quot;]); // 2delete a[&quot;ve&quot;]; // delete将返回trueconsole.log(a[&quot;ve&quot;]); // undefined 实例 2123456789101112131415function Person(name)&#123; this.name = name;&#125;Person.prototype.getName = function()&#123; return this.name ;&#125;;function Stuff1(name, id)&#123; this.name = name; this.id = id;&#125;for(var fn in Person.prototype)&#123; Stuff1.prototype[fn] = Person.prototype[fn];&#125;var piupiu1 = new Stuff1(&quot;piupiu1&quot;,&quot;008&quot;);console.log(piupiu1.constructor === Stuff1);//打印true 解析:Person.prototype的三个属性(constructor, getName, [[Prototype]])，仅有getName属性可枚举，于是Stuff1.prototype仅仅继承了“getName”属性，打印的constructor仍是自己的。"},{"title":"nginx限制请求频率","date":"2018-01-04T11:00:06.000Z","path":"practice/nginx限制请求频率.html","tags":[{"name":"nginx","slug":"nginx","permalink":"https://congzhou09.github.io/tags/nginx/"}],"text":"nginx可以通过ngx_http_limit_req_module和ngx_http_limit_conn_module这两个模块的配置来限制请求频率。 ngx_http_limit_req_module模块◇ngx_http_limit_req_module针对自定义的key来限制请求的处理速度，尤其是来源于同一个IP地址的请求，速度限制通过__漏桶算法(leaky bucket)__实现。◇主要使用limit_req_zone和limit_req指令。 配置实例: 1234567891011http &#123; limit_req_zone $binary_remote_addr zone=gameend:50m rate=10r/s; ... server &#123; ... location /api/ &#123; limit_req zone=gameend burst=50 nodelay; limit_req_status 503; #默认503，此行可省略 &#125; &#125;&#125; ★“limit_req_zone”那一行定义了名称为“gameend”的区域（区域可定义多个，在之后的引用处生效），使用“$binary_remote_addr”键表示对各个不同的IP起作用，分配50M共享存储空间用来保存键的状态参数，平均处理的请求频率不超过每秒10次（rate&#x3D;10r&#x2F;s）。这里使用“$binary_remote_addr”而不是“$remote_addr”是因为使用“$binary_remote_addr”所占用存储空间是固定的（状态参数在32位机和64位机上分别占用64字节和128字节，于是1M空间在32位机和64位机上分别能存储16000个和8000个状态。当域的存储空间耗尽，对于后续所有请求，服务器都会返回 503；★“limit_req”那一行引用上面定义的区域，对请求路径&quot;&#x2F;api&#x2F;&quot;生效，同时通过“burst”允许延时处理一定数量的请求（burst默认值为0），当请求速度超过每秒10次但超过的请求数量又没超过50（burst&#x3D;50）时，会延迟处理请求，而不是被立即返回503（limit_req_status 503），增加“nodelay”参数则以上情形下的请求立即被处理，不会被延迟； ngx_http_limit_conn_module模块◇ngx_http_limit_conn_module针对自定义的key来限制连接数，尤其是来自于同一个ip地址的连接，此处一个连接的定义是有一个服务器正在处理的请求并且请求头已经被读取。◇主要使用limit_conn_zone和limit_conn指令。 配置实例: 12345678910http &#123; limit_conn_zone $binary_remote_addr zone=gameend:10m; ... server &#123; ... location /download/ &#123; limit_conn gameend 1; &#125; &#125;&#125; ★“limit_conn_zone ”那一行定义了名称为“gameend”的区域（区域可定义多个，在之后的引用处生效）,分配10M共享存储空间用来保存键的状态参数，当域的存储空间耗尽，对于后续所有请求，服务器都会返回 503；★“limit_conn”那一行引用上面定义的区域，对请求路径&quot;&#x2F;download&#x2F;&quot;生效，同时将最大允许连接数设置为1，当连接数超过1，服务器返回 503错误； 参考: [官方文档](http://nginx.org/en/docs/)"},{"title":"JS的闭包","date":"2017-11-13T09:11:50.000Z","path":"knowledge/js的闭包.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://congzhou09.github.io/tags/javascript/"}],"text":"闭包的定义○ 从概念上讲，闭包是“包含上层作用域变量的函数”与“函数相关引用环境”两者组成的实体。其中的“函数相关引用环境”就是函数的词法环境链，是所有函数被执行前都会被创建的。因此在广义上只要函数内部引用了外部变量就构成闭包。词法环境相关内容整理在这篇。○ 经常讨论的闭包出现在“局部作用域中内嵌函数”的场景，且同时满足两个要点：（1）内嵌函数引用了上层作用域的变量（2）内嵌函数被传递到所在作用域的外面○ 对于函数作用域构成的局部作用域来说，也就是函数内嵌函数的场景，当内嵌函数引用了外部函数作用域内的变量，内嵌函数又通过 return 或赋值方式传递到外面，就可以达到“外部函数执行结束后仍可访问外部函数作用域内变量”的效果，如此就构成了一个闭包。○ 在块级作用域中的内嵌函数，使用同样思路也可以构成闭包，如下例： 12345678910var things = &#123;&#125;;for (let i = 0; i &lt; 3; i++) &#123; things[&#x27;fun&#x27; + i] = function() &#123; console.log(i); &#125;;&#125;things[&#x27;fun0&#x27;](); // 0things[&#x27;fun1&#x27;](); // 1things[&#x27;fun2&#x27;](); // 2 ☆解析：根据 MDN 的说明，for括号中使用var声明的变量存在于for循环体外面，而使用let声明的变量存在于for循环体之内的块级作用域。 闭包的用途◆ 从外部访问局部作用域内的内容。◆ 将局部内容保持在内存中。 理解实例实例 112345678function f1()&#123; var f1v = 2; return function()&#123; return f1v; &#125;&#125;var getF1vFun = f1();console.log(getF1vFun()); // 打印f1v的值2 ☆说明：“函数内嵌函数”的经典场景。当函数f1执行完毕，其中被闭包引用的局部变量f1v不会被垃圾回收机制回收。 实例 212345678var oneArr=[1,2,3];for(var i=0;i&lt;oneArr.length;i++)&#123; setTimeout(function()&#123; var oneElem= oneArr[i]; console.log(oneElem); &#125;, 1000*i); // 3秒内每隔1秒打印一次undefined&#125; ☆解析：传入setTimeout的函数中引用了外部变量i构成广义闭包，但var声明的i变量存在于循环体外面的全局作用域，闭包中保留的i也是全局作用域中的变量i，setTimeout的回调函数执行的时候，i值已经是for循环执行完毕后的值3，将打印三次oneArr[3]。 实例 31234567891011var oneArr=[1,2,3];for(var i=0;i&lt;oneArr.length;i++)&#123; setTimeout((function(index)&#123; return function()&#123; var oneElem= oneArr[index]; console.log(oneElem); &#125;; &#125;)(i), 1000*i); // 3秒内每隔1秒依次打印1,2,3&#125; ☆解析：在为setTimeout传入回调函数的位置，通过构造“函数内嵌函数的闭包”将局部作用域参数index保持在了内存中。 实例 412345678var oneArr=[1,2,3];for(let i=0;i&lt;oneArr.length;i++)&#123; setTimeout(function()&#123; var oneElem= oneArr[i]; console.log(oneElem); &#125;, 1000*i); // 3秒内每隔1秒依次打印1,2,3&#125; ☆解析：“块级作用域内嵌函数的闭包”场景，内嵌函数引用局部作用域的变量i，又将内嵌函数以传入setTimeout注册回调函数的方式传出。"},{"title":"JS的作用域与上下文与执行上下文","date":"2017-11-12T12:02:56.000Z","path":"knowledge/js的作用域与上下文与执行上下文.html","tags":[{"name":"javascript","slug":"javascript","permalink":"https://congzhou09.github.io/tags/javascript/"}],"text":"作用域○ 作用域(scope)是代码层面的概念，是代码被划分成的一个个区域，用来约定位于不同区域变量的可访问特性。根据所在位置，作用域可分为全局作用域和局部作用域（如函数作用域、块级作用域）。○ 块级作用域通过在{}里使用 let 或 const 声明变量实现。○ 函数作用域通过函数体划分。○ 全局作用域是不在任何函数作用域或块级作用域中的区域。 作用域链● 由于块和函数体可以嵌套，使作用域也可以存在上下层嵌套关系，上下层关系具有称为“作用域链(scope chain)”的机制。JS 约定作用域链有如下特性：（1）在每个局部作用域内可以向上访问上层局部作用域直到全局作用域中的变量，但不能向下访问嵌套函数或嵌套块内的变量。（2）若在局部作用域使用一个变量在局部不存在，则不断向上层查找直至找到或在全局作用域创建（非严格模式且找不到时）。（3）若在局部作用域声明一个与上层变量同名的变量，则在局部作用域内变量值为作用域内的值，而在上层作用域同名变量仍是上层作用域内的值。● 练习： 123456789var value = 1;function foo() &#123; console.log(value);// foo()函数声明在全局作用域，向上查找到value在全局作用域&#125;function bar() &#123; var value = 2; // 局部同名value变量，不影响全局value变量值 foo(); // 向上查找到foo()函数在全局作用域&#125;bar(); // 打印 1 ● Chrome 开发者工具可以查看作用域链。以上述“练习”为例，当调用栈(Call Stack)执行到 foo()函数内部时，能看到 foo()的作用域链如下图 1。如果将 foo()的定义移动在 bar()内部，作用域链将变成图 2 的样子。 图 1 图 2 词法环境◆ 词法环境(lexical environment)机制实现了作用域的特性。◆ 每个作用域都对应一个词法环境，词法环境在相应作用域的代码被评估(evalute)的时候就被创建，就是下文会提到的“执行上下文的创建阶段”。◆ 词法环境中除了存储当前作用域声明的变量和函数，还有个“外部词法环境”取值为上层作用域的词法环境的引用，由此实现作用域链的建立。 执行上下文□ 执行上下文(execution context)是 JS 代码执行涉及的状态信息的统称。□ 根据代码段的位置，可将执行上下文可分为三种类型：（1）全局执行上下文，在所有代码还未执行前创建（2）函数执行上下文，函数调用时创建（3）eval 执行上下文，执行 eval 语句时创建。□ “块级执行上下文”是不存在的(stackoverflow 问答)，执行块级代码时仍然在当前的执行上下文进行。□ 所有的执行上下文存储在执行上下文栈(execution context stack)，也称执行栈，也称为调用栈。随着代码从全局入口执行到调用函数到函数返回，新的执行上下文也不断被创建、入栈、切换执行、出栈、销毁，当前正在执行的代码段对应的执行上下文永远在栈顶。此过程可以借助代码执行可视化工具直观了解。□ 每个执行上下文都包含创建阶段(creation phase)与执行阶段(execution phase)，执行阶段才真正执行代码。□ 创建阶段会做如下事情：（1）创建执行上下文，创建词法环境并与执行上下文关联。（2）代码段区域中声明的变量，为其分配空间，如果是 var 声明则赋值 undefined，否则不赋值。（3）代码段区域中声明的函数，将其载入内存。（4）将变量和函数记录到词法环境。□ 创建阶段对声明变量与函数的处理实现了“声明提前(hoisting)”。let 和 const 声明的变量也实现了声明提前，只是不能提前使用，这一点可以通过提前访问变量产生的报错信息差异验证。□ 练习： 123456var v = &quot;yoyo&quot;;(function()&#123; console.log(v); // 输出“undefined”，局部变量v声明提前，与上层同名变量使用局部值 var v = &quot;check now&quot;; console.log(v); // 输出“check now”&#125;)(); □ 另一个代码执行可视化工具(支持 ES6)，支持 Python、C 等其他语言。 上下文■ 上下文(context)通常说的就是 this 。■ this 存在于所有的执行上下文中，this 的取值取决于其所处的执行上下文，具体规则如下：（1）在全局执行上下文，this 值指向全局对象（非 strict 模式下，在浏览器环境就是 window ）。（2）在函数执行上下文，this 值指向调用当前函数的对象。（3）eval 执行上下文的 this 值还与是 direct eval 还是 indirect eval有关，对于 direct eval，this 值与 eval 语句所在执行上下文的 this 一致；对于 indirect eval，等同于 eval 语句在全局执行上下文，此时 this 值指向全局对象。■ 练习 1 123456789101112131415161718192021222324252627282930var a = 20;var obj = &#123; a: 10, c: this.a + 20, fn: function () &#123; return this.a; &#125;&#125;class A &#123; constructor() &#123; this.a = 10; &#125; fn() &#123; return this.a; &#125; fn2 = () =&gt; &#123; return this.a; &#125;&#125;var objA = new A();console.log(obj.c); // 40，c属性的值在执行完赋值语句之后就确定了，计算其值时处于全局执行上下文console.log(obj.fn()); // 10var oneFun = obj.fn; // oneFun的值是obj.fn的函数体console.log(oneFun()); // 20oneFun = objA.fn;console.log(oneFun()); // Uncaught TypeError: Cannot read properties of undefined。oneFun = objA.fn2;console.log(oneFun()); // 10 其中“objA.fn”在全局执行上下文中执行时 this 取值为 undefined，原因是 class 的 body 强制在 strict 模式下执行，无论是否显式指定&quot;use strict&quot;。 ■ 练习 2 1234567891011121314var value = 1;var foo = &#123; value: 2, bar: function() &#123; return this.value; &#125;,&#125;;/* 表达式结果是foo.bar的函数体，函数体在全局执行上下文执行 */console.log((foo.bar = foo.bar)()); // 1console.log((false || foo.bar)()); // 1console.log((foo.bar, foo.bar)()); // 1 参考文献◇ JavaScript Execution Context and Hoisting◇ Understanding Execution Context in JavaScript◇ Understanding Scope and Context in JavaScript◇ What is the Difference Between Scope and Context in JavaScript◇ Javascript: Execution Context and Call Stack◇ ECMA262 标准◇ (1, eval)(&#39;this&#39;) vs eval(&#39;this&#39;) in JavaScript"}]